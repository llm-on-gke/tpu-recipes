KUBERNETES_SERVICE_PORT_HTTPS=443
PYTHON_SHA256=ae665bc678abd9ab6a6e1573d2481625a53719bc517e9a634ed2b9fefae3817f
KUBERNETES_SERVICE_PORT=443
TPU_TOPOLOGY=4x4
TPU_WORKER_ID=0
HOSTNAME=gke-tpu-b009a016-sjnl
PYTHON_VERSION=3.10
TF_CPP_MIN_LOG_LEVEL=0
TPU_SKIP_MDS_QUERY=true
ALT=false
TPU_TOPOLOGY_WRAP=false,false,false
COMMIT_HASH=9f1820b4
PWD=/deps
JOB_COMPLETION_INDEX=0
TPU_CHIPS_PER_HOST_BOUNDS=2,2,1
JOBSET_NAME=maxtext-vlp16-default
HOME=/root
LANG=C.UTF-8
KUBERNETES_PORT_443_TCP=tcp://34.118.224.1:443
TPU_ACCELERATOR_TYPE=v6e-16
GPG_KEY=A035C8C19219BA821ECEA86B64E628F8D684696D
TPU_RUNTIME_METRICS_PORTS=8431,8432,8433,8434
TPU_TOPOLOGY_ALT=false
WRAP=false,false,false
LIBTPU_INIT_ARGS=--xla_enable_async_all_gather=true TPU_MEGACORE=MEGACORE_DENSE
HOST_BOUNDS=2,2,1
TPU_HOST_BOUNDS=2,2,1
SHLVL=1
KUBERNETES_PORT_443_TCP_PROTO=tcp
VBAR_CONTROL_SERVICE_URL=10.128.0.132:8353
TPU_MIN_LOG_LEVEL=0
KUBERNETES_PORT_443_TCP_ADDR=34.118.224.1
CLOUD_SDK_VERSION=latest
PIP_ROOT_USER_ACTION=ignore
DEVICE=tpu
CHIPS_PER_HOST_BOUNDS=2,2,1
TPU_WORKER_HOSTNAMES=maxtext-vlp16-default-slice-0-0.maxtext-vlp16-default,maxtext-vlp16-default-slice-0-1.maxtext-vlp16-default,maxtext-vlp16-default-slice-0-2.maxtext-vlp16-default,maxtext-vlp16-default-slice-0-3.maxtext-vlp16-default
KUBERNETES_SERVICE_HOST=34.118.224.1
KUBERNETES_PORT=tcp://34.118.224.1:443
KUBERNETES_PORT_443_TCP_PORT=443
PATH=/usr/local/bin:/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/bin
PIP_NO_CACHE_DIR=1
DEBIAN_FRONTEND=noninteractive
TPU_STDERR_LOG_LEVEL=0
_=/usr/bin/printenv
Obtaining file:///deps
  Installing build dependencies: started
  Installing build dependencies: finished with status 'done'
  Checking if build backend supports build_editable: started
  Checking if build backend supports build_editable: finished with status 'done'
  Getting requirements to build editable: started
  Getting requirements to build editable: finished with status 'done'
  Preparing editable metadata (pyproject.toml): started
  Preparing editable metadata (pyproject.toml): finished with status 'done'
Requirement already satisfied: jax>=0.4.30 in /usr/local/lib/python3.10/site-packages (from MaxText==0.1.0) (0.6.1)
Requirement already satisfied: jaxlib>=0.4.30 in /usr/local/lib/python3.10/site-packages (from MaxText==0.1.0) (0.6.1)
Requirement already satisfied: orbax-checkpoint>=0.5.12 in /usr/local/lib/python3.10/site-packages (from MaxText==0.1.0) (0.11.13)
Requirement already satisfied: absl-py in /usr/local/lib/python3.10/site-packages (from MaxText==0.1.0) (2.3.0)
Requirement already satisfied: array-record in /usr/local/lib/python3.10/site-packages (from MaxText==0.1.0) (0.7.2)
Requirement already satisfied: aqtp in /usr/local/lib/python3.10/site-packages (from MaxText==0.1.0) (0.8.4)
Requirement already satisfied: cloud-accelerator-diagnostics in /usr/local/lib/python3.10/site-packages (from MaxText==0.1.0) (0.1.1)
Requirement already satisfied: cloud-tpu-diagnostics in /usr/local/lib/python3.10/site-packages (from MaxText==0.1.0) (0.1.5)
Requirement already satisfied: datasets in /usr/local/lib/python3.10/site-packages (from MaxText==0.1.0) (4.0.0)
Requirement already satisfied: gcsfs in /usr/local/lib/python3.10/site-packages (from MaxText==0.1.0) (2025.5.1)
Collecting google-cloud-aiplatform==1.61.0 (from MaxText==0.1.0)
  Downloading google_cloud_aiplatform-1.61.0-py2.py3-none-any.whl.metadata (31 kB)
Requirement already satisfied: google-cloud-storage in /usr/local/lib/python3.10/site-packages (from MaxText==0.1.0) (2.19.0)
Requirement already satisfied: google-cloud-monitoring in /usr/local/lib/python3.10/site-packages (from MaxText==0.1.0) (2.27.1)
Requirement already satisfied: google-api-core in /usr/local/lib/python3.10/site-packages (from MaxText==0.1.0) (2.25.0)
Requirement already satisfied: google-api-python-client in /usr/local/lib/python3.10/site-packages (from MaxText==0.1.0) (2.181.0)
Requirement already satisfied: grain>=0.2.6 in /usr/local/lib/python3.10/site-packages (from grain[parquet]>=0.2.6->MaxText==0.1.0) (0.2.11)
Requirement already satisfied: huggingface_hub in /usr/local/lib/python3.10/site-packages (from MaxText==0.1.0) (0.34.4)
Requirement already satisfied: flax>=0.10.6 in /usr/local/lib/python3.10/site-packages (from MaxText==0.1.0) (0.10.6)
Requirement already satisfied: jaxtyping in /usr/local/lib/python3.10/site-packages (from MaxText==0.1.0) (0.3.2)
Requirement already satisfied: ml-collections in /usr/local/lib/python3.10/site-packages (from MaxText==0.1.0) (1.1.0)
Requirement already satisfied: ml-goodput-measurement==0.0.10 in /usr/local/lib/python3.10/site-packages (from MaxText==0.1.0) (0.0.10)
Requirement already satisfied: numpy in /usr/local/lib/python3.10/site-packages (from MaxText==0.1.0) (2.1.3)
Requirement already satisfied: optax in /usr/local/lib/python3.10/site-packages (from MaxText==0.1.0) (0.2.4)
Requirement already satisfied: protobuf==3.20.3 in /usr/local/lib/python3.10/site-packages (from MaxText==0.1.0) (3.20.3)
Requirement already satisfied: pylint in /usr/local/lib/python3.10/site-packages (from MaxText==0.1.0) (3.3.8)
Requirement already satisfied: pytest in /usr/local/lib/python3.10/site-packages (from MaxText==0.1.0) (8.4.2)
Requirement already satisfied: pyink in /usr/local/lib/python3.10/site-packages (from MaxText==0.1.0) (24.10.1)
Requirement already satisfied: pre-commit in /usr/local/lib/python3.10/site-packages (from MaxText==0.1.0) (4.3.0)
Requirement already satisfied: pytype in /usr/local/lib/python3.10/site-packages (from MaxText==0.1.0) (2024.10.11)
Requirement already satisfied: pillow>=11.1.0 in /usr/local/lib/python3.10/site-packages (from MaxText==0.1.0) (11.3.0)
Collecting sentencepiece==0.2.0 (from MaxText==0.1.0)
  Downloading sentencepiece-0.2.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (7.7 kB)
Requirement already satisfied: tensorflow-text>=2.13.0 in /usr/local/lib/python3.10/site-packages (from MaxText==0.1.0) (2.19.0)
Requirement already satisfied: tensorflow>=2.13.0 in /usr/local/lib/python3.10/site-packages (from MaxText==0.1.0) (2.19.0)
Requirement already satisfied: tensorflow-datasets in /usr/local/lib/python3.10/site-packages (from MaxText==0.1.0) (4.9.9)
Requirement already satisfied: tensorboardx>=2.6.2.2 in /usr/local/lib/python3.10/site-packages (from MaxText==0.1.0) (2.6.2.2)
Requirement already satisfied: tensorboard-plugin-profile in /usr/local/lib/python3.10/site-packages (from MaxText==0.1.0) (2.13.0)
Requirement already satisfied: tiktoken in /usr/local/lib/python3.10/site-packages (from MaxText==0.1.0) (0.11.0)
Requirement already satisfied: transformers in /usr/local/lib/python3.10/site-packages (from MaxText==0.1.0) (4.56.1)
Collecting mlperf-logging@ git+https://github.com/mlperf/logging.git (from MaxText==0.1.0)
  Cloning https://github.com/mlperf/logging.git to /tmp/pip-install-92befv4g/mlperf-logging_782191978be84dd29ed83518f322bf8d
  Running command git clone --filter=blob:none --quiet https://github.com/mlperf/logging.git /tmp/pip-install-92befv4g/mlperf-logging_782191978be84dd29ed83518f322bf8d
  Resolved https://github.com/mlperf/logging.git to commit bfe32681d483396d0bba9a7a55c720e24a9d1d68
  Preparing metadata (setup.py): started
  Preparing metadata (setup.py): finished with status 'done'
Collecting google-jetstream@ git+https://github.com/AI-Hypercomputer/JetStream.git (from MaxText==0.1.0)
  Cloning https://github.com/AI-Hypercomputer/JetStream.git to /tmp/pip-install-92befv4g/google-jetstream_b3e4a9145c2d43ceb48ed3f127c693cc
  Running command git clone --filter=blob:none --quiet https://github.com/AI-Hypercomputer/JetStream.git /tmp/pip-install-92befv4g/google-jetstream_b3e4a9145c2d43ceb48ed3f127c693cc
  Resolved https://github.com/AI-Hypercomputer/JetStream.git to commit 29329e8e73820993f77cfc8efe34eb2a73f5de98
  Preparing metadata (setup.py): started
  Preparing metadata (setup.py): finished with status 'done'
Requirement already satisfied: jsonlines in /usr/local/lib/python3.10/site-packages (from MaxText==0.1.0) (4.0.0)
Requirement already satisfied: pathwaysutils==0.1.1 in /usr/local/lib/python3.10/site-packages (from MaxText==0.1.0) (0.1.1)
Requirement already satisfied: omegaconf in /usr/local/lib/python3.10/site-packages (from MaxText==0.1.0) (2.3.0)
Requirement already satisfied: coverage in /usr/local/lib/python3.10/site-packages (from google-jetstream@ git+https://github.com/AI-Hypercomputer/JetStream.git->MaxText==0.1.0) (7.10.6)
Requirement already satisfied: grpcio in /usr/local/lib/python3.10/site-packages (from google-jetstream@ git+https://github.com/AI-Hypercomputer/JetStream.git->MaxText==0.1.0) (1.72.1)
Requirement already satisfied: portpicker in /usr/local/lib/python3.10/site-packages (from google-jetstream@ git+https://github.com/AI-Hypercomputer/JetStream.git->MaxText==0.1.0) (1.6.0)
Requirement already satisfied: prometheus-client in /usr/local/lib/python3.10/site-packages (from google-jetstream@ git+https://github.com/AI-Hypercomputer/JetStream.git->MaxText==0.1.0) (0.22.1)
Requirement already satisfied: seqio in /usr/local/lib/python3.10/site-packages (from google-jetstream@ git+https://github.com/AI-Hypercomputer/JetStream.git->MaxText==0.1.0) (0.0.19)
Requirement already satisfied: blobfile in /usr/local/lib/python3.10/site-packages (from google-jetstream@ git+https://github.com/AI-Hypercomputer/JetStream.git->MaxText==0.1.0) (3.1.0)
Requirement already satisfied: parameterized in /usr/local/lib/python3.10/site-packages (from google-jetstream@ git+https://github.com/AI-Hypercomputer/JetStream.git->MaxText==0.1.0) (0.9.0)
Requirement already satisfied: shortuuid in /usr/local/lib/python3.10/site-packages (from google-jetstream@ git+https://github.com/AI-Hypercomputer/JetStream.git->MaxText==0.1.0) (1.0.13)
Requirement already satisfied: fastapi in /usr/local/lib/python3.10/site-packages (from google-jetstream@ git+https://github.com/AI-Hypercomputer/JetStream.git->MaxText==0.1.0) (0.116.1)
Requirement already satisfied: uvicorn in /usr/local/lib/python3.10/site-packages (from google-jetstream@ git+https://github.com/AI-Hypercomputer/JetStream.git->MaxText==0.1.0) (0.35.0)
Requirement already satisfied: sympy in /usr/local/lib/python3.10/site-packages (from google-jetstream@ git+https://github.com/AI-Hypercomputer/JetStream.git->MaxText==0.1.0) (1.14.0)
Requirement already satisfied: nltk in /usr/local/lib/python3.10/site-packages (from google-jetstream@ git+https://github.com/AI-Hypercomputer/JetStream.git->MaxText==0.1.0) (3.9.1)
Requirement already satisfied: evaluate in /usr/local/lib/python3.10/site-packages (from google-jetstream@ git+https://github.com/AI-Hypercomputer/JetStream.git->MaxText==0.1.0) (0.4.5)
Requirement already satisfied: pandas>=1.0 in /usr/local/lib/python3.10/site-packages (from mlperf-logging@ git+https://github.com/mlperf/logging.git->MaxText==0.1.0) (2.3.2)
Requirement already satisfied: pyyaml>=5.4.1 in /usr/local/lib/python3.10/site-packages (from mlperf-logging@ git+https://github.com/mlperf/logging.git->MaxText==0.1.0) (6.0.2)
Requirement already satisfied: scipy>=1.4.1 in /usr/local/lib/python3.10/site-packages (from mlperf-logging@ git+https://github.com/mlperf/logging.git->MaxText==0.1.0) (1.15.3)
Requirement already satisfied: google-auth<3.0.0dev,>=2.14.1 in /usr/local/lib/python3.10/site-packages (from google-cloud-aiplatform==1.61.0->MaxText==0.1.0) (2.40.3)
Requirement already satisfied: proto-plus<2.0.0dev,>=1.22.3 in /usr/local/lib/python3.10/site-packages (from google-cloud-aiplatform==1.61.0->MaxText==0.1.0) (1.26.1)
Requirement already satisfied: packaging>=14.3 in /usr/local/lib/python3.10/site-packages (from google-cloud-aiplatform==1.61.0->MaxText==0.1.0) (25.0)
Requirement already satisfied: google-cloud-bigquery!=3.20.0,<4.0.0dev,>=1.15.0 in /usr/local/lib/python3.10/site-packages (from google-cloud-aiplatform==1.61.0->MaxText==0.1.0) (3.34.0)
Requirement already satisfied: google-cloud-resource-manager<3.0.0dev,>=1.3.3 in /usr/local/lib/python3.10/site-packages (from google-cloud-aiplatform==1.61.0->MaxText==0.1.0) (1.14.2)
Requirement already satisfied: shapely<3.0.0dev in /usr/local/lib/python3.10/site-packages (from google-cloud-aiplatform==1.61.0->MaxText==0.1.0) (2.1.1)
Requirement already satisfied: pydantic<3 in /usr/local/lib/python3.10/site-packages (from google-cloud-aiplatform==1.61.0->MaxText==0.1.0) (2.11.5)
Requirement already satisfied: docstring-parser<1 in /usr/local/lib/python3.10/site-packages (from google-cloud-aiplatform==1.61.0->MaxText==0.1.0) (0.16)
Requirement already satisfied: google-cloud-logging>=3.5.0 in /usr/local/lib/python3.10/site-packages (from ml-goodput-measurement==0.0.10->MaxText==0.1.0) (3.12.1)
Requirement already satisfied: requests in /usr/local/lib/python3.10/site-packages (from ml-goodput-measurement==0.0.10->MaxText==0.1.0) (2.32.3)
Requirement already satisfied: urllib3 in /usr/local/lib/python3.10/site-packages (from ml-goodput-measurement==0.0.10->MaxText==0.1.0) (2.4.0)
Requirement already satisfied: googleapis-common-protos<2.0.0,>=1.56.2 in /usr/local/lib/python3.10/site-packages (from google-api-core->MaxText==0.1.0) (1.70.0)
Requirement already satisfied: grpcio-status<2.0.0,>=1.33.2 in /usr/local/lib/python3.10/site-packages (from google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,<3.0.0dev,>=1.34.1->google-cloud-aiplatform==1.61.0->MaxText==0.1.0) (1.71.0)
Requirement already satisfied: cachetools<6.0,>=2.0.0 in /usr/local/lib/python3.10/site-packages (from google-auth<3.0.0dev,>=2.14.1->google-cloud-aiplatform==1.61.0->MaxText==0.1.0) (5.5.2)
Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.10/site-packages (from google-auth<3.0.0dev,>=2.14.1->google-cloud-aiplatform==1.61.0->MaxText==0.1.0) (0.4.2)
Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.10/site-packages (from google-auth<3.0.0dev,>=2.14.1->google-cloud-aiplatform==1.61.0->MaxText==0.1.0) (4.9.1)
Requirement already satisfied: google-cloud-core<3.0.0,>=2.4.1 in /usr/local/lib/python3.10/site-packages (from google-cloud-bigquery!=3.20.0,<4.0.0dev,>=1.15.0->google-cloud-aiplatform==1.61.0->MaxText==0.1.0) (2.4.3)
Requirement already satisfied: google-resumable-media<3.0.0,>=2.0.0 in /usr/local/lib/python3.10/site-packages (from google-cloud-bigquery!=3.20.0,<4.0.0dev,>=1.15.0->google-cloud-aiplatform==1.61.0->MaxText==0.1.0) (2.7.2)
Requirement already satisfied: python-dateutil<3.0.0,>=2.8.2 in /usr/local/lib/python3.10/site-packages (from google-cloud-bigquery!=3.20.0,<4.0.0dev,>=1.15.0->google-cloud-aiplatform==1.61.0->MaxText==0.1.0) (2.9.0.post0)
Requirement already satisfied: grpc-google-iam-v1<1.0.0,>=0.14.0 in /usr/local/lib/python3.10/site-packages (from google-cloud-resource-manager<3.0.0dev,>=1.3.3->google-cloud-aiplatform==1.61.0->MaxText==0.1.0) (0.14.2)
Requirement already satisfied: google-crc32c<2.0dev,>=1.0 in /usr/local/lib/python3.10/site-packages (from google-cloud-storage->MaxText==0.1.0) (1.7.1)
INFO: pip is looking at multiple versions of grpcio-status to determine which version is compatible with other requirements. This could take a while.
Collecting grpcio-status<2.0.0,>=1.33.2 (from google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,<3.0.0dev,>=1.34.1->google-cloud-aiplatform==1.61.0->MaxText==0.1.0)
  Downloading grpcio_status-1.74.0-py3-none-any.whl.metadata (1.1 kB)
  Downloading grpcio_status-1.73.1-py3-none-any.whl.metadata (1.1 kB)
  Downloading grpcio_status-1.73.0-py3-none-any.whl.metadata (1.1 kB)
  Downloading grpcio_status-1.72.2-py3-none-any.whl.metadata (1.1 kB)
  Downloading grpcio_status-1.72.1-py3-none-any.whl.metadata (1.1 kB)
  Downloading grpcio_status-1.71.2-py3-none-any.whl.metadata (1.1 kB)
  Downloading grpcio_status-1.70.0-py3-none-any.whl.metadata (1.1 kB)
INFO: pip is still looking at multiple versions of grpcio-status to determine which version is compatible with other requirements. This could take a while.
  Downloading grpcio_status-1.69.0-py3-none-any.whl.metadata (1.1 kB)
  Downloading grpcio_status-1.68.1-py3-none-any.whl.metadata (1.1 kB)
  Downloading grpcio_status-1.68.0-py3-none-any.whl.metadata (1.1 kB)
  Downloading grpcio_status-1.67.1-py3-none-any.whl.metadata (1.1 kB)
  Downloading grpcio_status-1.67.0-py3-none-any.whl.metadata (1.1 kB)
INFO: This is taking longer than usual. You might need to provide the dependency resolver with stricter constraints to reduce runtime. See https://pip.pypa.io/warnings/backtracking for guidance. If you want to abort this run, press Ctrl + C.
  Downloading grpcio_status-1.66.2-py3-none-any.whl.metadata (1.1 kB)
  Downloading grpcio_status-1.66.1-py3-none-any.whl.metadata (1.1 kB)
  Downloading grpcio_status-1.66.0-py3-none-any.whl.metadata (1.1 kB)
  Downloading grpcio_status-1.65.5-py3-none-any.whl.metadata (1.1 kB)
  Downloading grpcio_status-1.65.4-py3-none-any.whl.metadata (1.1 kB)
  Downloading grpcio_status-1.65.2-py3-none-any.whl.metadata (1.1 kB)
  Downloading grpcio_status-1.65.1-py3-none-any.whl.metadata (1.1 kB)
  Downloading grpcio_status-1.64.3-py3-none-any.whl.metadata (1.1 kB)
  Downloading grpcio_status-1.64.1-py3-none-any.whl.metadata (1.1 kB)
  Downloading grpcio_status-1.64.0-py3-none-any.whl.metadata (1.1 kB)
  Downloading grpcio_status-1.63.2-py3-none-any.whl.metadata (1.1 kB)
  Downloading grpcio_status-1.63.0-py3-none-any.whl.metadata (1.1 kB)
  Downloading grpcio_status-1.62.3-py3-none-any.whl.metadata (1.3 kB)
  Downloading grpcio_status-1.62.2-py3-none-any.whl.metadata (1.3 kB)
  Downloading grpcio_status-1.62.1-py3-none-any.whl.metadata (1.3 kB)
  Downloading grpcio_status-1.62.0-py3-none-any.whl.metadata (1.3 kB)
  Downloading grpcio_status-1.61.3-py3-none-any.whl.metadata (1.3 kB)
  Downloading grpcio_status-1.60.2-py3-none-any.whl.metadata (1.3 kB)
  Downloading grpcio_status-1.60.1-py3-none-any.whl.metadata (1.3 kB)
  Downloading grpcio_status-1.60.0-py3-none-any.whl.metadata (1.3 kB)
  Downloading grpcio_status-1.59.5-py3-none-any.whl.metadata (1.3 kB)
  Downloading grpcio_status-1.59.3-py3-none-any.whl.metadata (1.3 kB)
  Downloading grpcio_status-1.59.2-py3-none-any.whl.metadata (1.3 kB)
  Downloading grpcio_status-1.59.0-py3-none-any.whl.metadata (1.3 kB)
  Downloading grpcio_status-1.58.3-py3-none-any.whl.metadata (1.3 kB)
  Downloading grpcio_status-1.58.0-py3-none-any.whl.metadata (1.3 kB)
  Downloading grpcio_status-1.57.0-py3-none-any.whl.metadata (1.2 kB)
  Downloading grpcio_status-1.56.2-py3-none-any.whl.metadata (1.3 kB)
  Downloading grpcio_status-1.56.0-py3-none-any.whl.metadata (1.3 kB)
  Downloading grpcio_status-1.55.3-py3-none-any.whl.metadata (1.3 kB)
  Downloading grpcio_status-1.54.3-py3-none-any.whl.metadata (1.3 kB)
  Downloading grpcio_status-1.54.2-py3-none-any.whl.metadata (1.3 kB)
  Downloading grpcio_status-1.54.0-py3-none-any.whl.metadata (1.3 kB)
  Downloading grpcio_status-1.53.2-py3-none-any.whl.metadata (1.3 kB)
  Downloading grpcio_status-1.53.1-py3-none-any.whl.metadata (1.3 kB)
  Downloading grpcio_status-1.53.0-py3-none-any.whl.metadata (1.3 kB)
  Downloading grpcio_status-1.51.3-py3-none-any.whl.metadata (1.3 kB)
  Downloading grpcio_status-1.51.1-py3-none-any.whl.metadata (1.3 kB)
  Downloading grpcio_status-1.50.0-py3-none-any.whl.metadata (1.3 kB)
  Downloading grpcio_status-1.49.1-py3-none-any.whl.metadata (1.3 kB)
  Downloading grpcio_status-1.48.2-py3-none-any.whl.metadata (1.2 kB)
Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.10/site-packages (from pydantic<3->google-cloud-aiplatform==1.61.0->MaxText==0.1.0) (0.7.0)
Requirement already satisfied: pydantic-core==2.33.2 in /usr/local/lib/python3.10/site-packages (from pydantic<3->google-cloud-aiplatform==1.61.0->MaxText==0.1.0) (2.33.2)
Requirement already satisfied: typing-extensions>=4.12.2 in /usr/local/lib/python3.10/site-packages (from pydantic<3->google-cloud-aiplatform==1.61.0->MaxText==0.1.0) (4.14.0)
Requirement already satisfied: typing-inspection>=0.4.0 in /usr/local/lib/python3.10/site-packages (from pydantic<3->google-cloud-aiplatform==1.61.0->MaxText==0.1.0) (0.4.1)
Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/site-packages (from python-dateutil<3.0.0,>=2.8.2->google-cloud-bigquery!=3.20.0,<4.0.0dev,>=1.15.0->google-cloud-aiplatform==1.61.0->MaxText==0.1.0) (1.17.0)
Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/site-packages (from requests->ml-goodput-measurement==0.0.10->MaxText==0.1.0) (3.4.2)
Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/site-packages (from requests->ml-goodput-measurement==0.0.10->MaxText==0.1.0) (3.10)
Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/site-packages (from requests->ml-goodput-measurement==0.0.10->MaxText==0.1.0) (2025.4.26)
Requirement already satisfied: pyasn1>=0.1.3 in /usr/local/lib/python3.10/site-packages (from rsa<5,>=3.1.4->google-auth<3.0.0dev,>=2.14.1->google-cloud-aiplatform==1.61.0->MaxText==0.1.0) (0.6.1)
Requirement already satisfied: msgpack in /usr/local/lib/python3.10/site-packages (from flax>=0.10.6->MaxText==0.1.0) (1.1.0)
Requirement already satisfied: tensorstore in /usr/local/lib/python3.10/site-packages (from flax>=0.10.6->MaxText==0.1.0) (0.1.75)
Requirement already satisfied: rich>=11.1 in /usr/local/lib/python3.10/site-packages (from flax>=0.10.6->MaxText==0.1.0) (14.0.0)
Requirement already satisfied: treescope>=0.1.7 in /usr/local/lib/python3.10/site-packages (from flax>=0.10.6->MaxText==0.1.0) (0.1.9)
Requirement already satisfied: google-cloud-appengine-logging<2.0.0,>=0.1.3 in /usr/local/lib/python3.10/site-packages (from google-cloud-logging>=3.5.0->ml-goodput-measurement==0.0.10->MaxText==0.1.0) (1.6.1)
Requirement already satisfied: google-cloud-audit-log<1.0.0,>=0.3.1 in /usr/local/lib/python3.10/site-packages (from google-cloud-logging>=3.5.0->ml-goodput-measurement==0.0.10->MaxText==0.1.0) (0.3.2)
Requirement already satisfied: opentelemetry-api>=1.9.0 in /usr/local/lib/python3.10/site-packages (from google-cloud-logging>=3.5.0->ml-goodput-measurement==0.0.10->MaxText==0.1.0) (1.34.0)
Requirement already satisfied: cloudpickle in /usr/local/lib/python3.10/site-packages (from grain>=0.2.6->grain[parquet]>=0.2.6->MaxText==0.1.0) (3.1.1)
Requirement already satisfied: dm-tree in /usr/local/lib/python3.10/site-packages (from grain>=0.2.6->grain[parquet]>=0.2.6->MaxText==0.1.0) (0.1.9)
Requirement already satisfied: etils[epath,epy] in /usr/local/lib/python3.10/site-packages (from grain>=0.2.6->grain[parquet]>=0.2.6->MaxText==0.1.0) (1.12.2)
Requirement already satisfied: more-itertools>=9.1.0 in /usr/local/lib/python3.10/site-packages (from grain>=0.2.6->grain[parquet]>=0.2.6->MaxText==0.1.0) (10.7.0)
Requirement already satisfied: pyarrow in /usr/local/lib/python3.10/site-packages (from grain[parquet]>=0.2.6->MaxText==0.1.0) (21.0.0)
Requirement already satisfied: ml_dtypes>=0.5.0 in /usr/local/lib/python3.10/site-packages (from jax>=0.4.30->MaxText==0.1.0) (0.5.1)
Requirement already satisfied: opt_einsum in /usr/local/lib/python3.10/site-packages (from jax>=0.4.30->MaxText==0.1.0) (3.4.0)
Requirement already satisfied: importlib-metadata<8.8.0,>=6.0 in /usr/local/lib/python3.10/site-packages (from opentelemetry-api>=1.9.0->google-cloud-logging>=3.5.0->ml-goodput-measurement==0.0.10->MaxText==0.1.0) (8.7.0)
Requirement already satisfied: zipp>=3.20 in /usr/local/lib/python3.10/site-packages (from importlib-metadata<8.8.0,>=6.0->opentelemetry-api>=1.9.0->google-cloud-logging>=3.5.0->ml-goodput-measurement==0.0.10->MaxText==0.1.0) (3.22.0)
Requirement already satisfied: nest_asyncio in /usr/local/lib/python3.10/site-packages (from orbax-checkpoint>=0.5.12->MaxText==0.1.0) (1.6.0)
Requirement already satisfied: humanize in /usr/local/lib/python3.10/site-packages (from orbax-checkpoint>=0.5.12->MaxText==0.1.0) (4.12.3)
Requirement already satisfied: simplejson>=3.16.0 in /usr/local/lib/python3.10/site-packages (from orbax-checkpoint>=0.5.12->MaxText==0.1.0) (3.20.1)
Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/site-packages (from pandas>=1.0->mlperf-logging@ git+https://github.com/mlperf/logging.git->MaxText==0.1.0) (2025.2)
Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.10/site-packages (from pandas>=1.0->mlperf-logging@ git+https://github.com/mlperf/logging.git->MaxText==0.1.0) (2025.2)
Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.10/site-packages (from rich>=11.1->flax>=0.10.6->MaxText==0.1.0) (3.0.0)
Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.10/site-packages (from rich>=11.1->flax>=0.10.6->MaxText==0.1.0) (2.19.1)
Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.10/site-packages (from markdown-it-py>=2.2.0->rich>=11.1->flax>=0.10.6->MaxText==0.1.0) (0.1.2)
Requirement already satisfied: astunparse>=1.6.0 in /usr/local/lib/python3.10/site-packages (from tensorflow>=2.13.0->MaxText==0.1.0) (1.6.3)
Requirement already satisfied: flatbuffers>=24.3.25 in /usr/local/lib/python3.10/site-packages (from tensorflow>=2.13.0->MaxText==0.1.0) (25.2.10)
Requirement already satisfied: gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 in /usr/local/lib/python3.10/site-packages (from tensorflow>=2.13.0->MaxText==0.1.0) (0.6.0)
Requirement already satisfied: google-pasta>=0.1.1 in /usr/local/lib/python3.10/site-packages (from tensorflow>=2.13.0->MaxText==0.1.0) (0.2.0)
Requirement already satisfied: libclang>=13.0.0 in /usr/local/lib/python3.10/site-packages (from tensorflow>=2.13.0->MaxText==0.1.0) (18.1.1)
Requirement already satisfied: setuptools in /usr/local/lib/python3.10/site-packages (from tensorflow>=2.13.0->MaxText==0.1.0) (65.5.1)
Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.10/site-packages (from tensorflow>=2.13.0->MaxText==0.1.0) (3.1.0)
Requirement already satisfied: wrapt>=1.11.0 in /usr/local/lib/python3.10/site-packages (from tensorflow>=2.13.0->MaxText==0.1.0) (1.17.2)
Requirement already satisfied: tensorboard~=2.19.0 in /usr/local/lib/python3.10/site-packages (from tensorflow>=2.13.0->MaxText==0.1.0) (2.19.0)
Requirement already satisfied: keras>=3.5.0 in /usr/local/lib/python3.10/site-packages (from tensorflow>=2.13.0->MaxText==0.1.0) (3.10.0)
Requirement already satisfied: h5py>=3.11.0 in /usr/local/lib/python3.10/site-packages (from tensorflow>=2.13.0->MaxText==0.1.0) (3.13.0)
Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /usr/local/lib/python3.10/site-packages (from tensorflow>=2.13.0->MaxText==0.1.0) (0.37.1)
Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.10/site-packages (from tensorboard~=2.19.0->tensorflow>=2.13.0->MaxText==0.1.0) (3.8)
Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /usr/local/lib/python3.10/site-packages (from tensorboard~=2.19.0->tensorflow>=2.13.0->MaxText==0.1.0) (0.7.2)
Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.10/site-packages (from tensorboard~=2.19.0->tensorflow>=2.13.0->MaxText==0.1.0) (3.1.3)
Requirement already satisfied: wheel<1.0,>=0.23.0 in /usr/local/lib/python3.10/site-packages (from astunparse>=1.6.0->tensorflow>=2.13.0->MaxText==0.1.0) (0.45.1)
Requirement already satisfied: namex in /usr/local/lib/python3.10/site-packages (from keras>=3.5.0->tensorflow>=2.13.0->MaxText==0.1.0) (0.1.0)
Requirement already satisfied: optree in /usr/local/lib/python3.10/site-packages (from keras>=3.5.0->tensorflow>=2.13.0->MaxText==0.1.0) (0.16.0)
Requirement already satisfied: MarkupSafe>=2.1.1 in /usr/local/lib/python3.10/site-packages (from werkzeug>=1.0.1->tensorboard~=2.19.0->tensorflow>=2.13.0->MaxText==0.1.0) (3.0.2)
Requirement already satisfied: pycryptodomex>=3.8 in /usr/local/lib/python3.10/site-packages (from blobfile->google-jetstream@ git+https://github.com/AI-Hypercomputer/JetStream.git->MaxText==0.1.0) (3.23.0)
Requirement already satisfied: lxml>=4.9 in /usr/local/lib/python3.10/site-packages (from blobfile->google-jetstream@ git+https://github.com/AI-Hypercomputer/JetStream.git->MaxText==0.1.0) (6.0.1)
Requirement already satisfied: filelock>=3.0 in /usr/local/lib/python3.10/site-packages (from blobfile->google-jetstream@ git+https://github.com/AI-Hypercomputer/JetStream.git->MaxText==0.1.0) (3.19.1)
Requirement already satisfied: dill<0.3.9,>=0.3.0 in /usr/local/lib/python3.10/site-packages (from datasets->MaxText==0.1.0) (0.3.8)
Requirement already satisfied: tqdm>=4.66.3 in /usr/local/lib/python3.10/site-packages (from datasets->MaxText==0.1.0) (4.67.1)
Requirement already satisfied: xxhash in /usr/local/lib/python3.10/site-packages (from datasets->MaxText==0.1.0) (3.5.0)
Requirement already satisfied: multiprocess<0.70.17 in /usr/local/lib/python3.10/site-packages (from datasets->MaxText==0.1.0) (0.70.16)
Requirement already satisfied: fsspec<=2025.3.0,>=2023.1.0 in /usr/local/lib/python3.10/site-packages (from fsspec[http]<=2025.3.0,>=2023.1.0->datasets->MaxText==0.1.0) (2025.3.0)
Requirement already satisfied: aiohttp!=4.0.0a0,!=4.0.0a1 in /usr/local/lib/python3.10/site-packages (from fsspec[http]<=2025.3.0,>=2023.1.0->datasets->MaxText==0.1.0) (3.12.9)
Requirement already satisfied: aiohappyeyeballs>=2.5.0 in /usr/local/lib/python3.10/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets->MaxText==0.1.0) (2.6.1)
Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets->MaxText==0.1.0) (1.3.2)
Requirement already satisfied: async-timeout<6.0,>=4.0 in /usr/local/lib/python3.10/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets->MaxText==0.1.0) (5.0.1)
Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets->MaxText==0.1.0) (25.3.0)
Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets->MaxText==0.1.0) (1.6.2)
Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets->MaxText==0.1.0) (6.4.4)
Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.10/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets->MaxText==0.1.0) (0.3.1)
Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.10/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets->MaxText==0.1.0) (1.20.0)
Requirement already satisfied: hf-xet<2.0.0,>=1.1.3 in /usr/local/lib/python3.10/site-packages (from huggingface_hub->MaxText==0.1.0) (1.1.9)
Requirement already satisfied: importlib_resources in /usr/local/lib/python3.10/site-packages (from etils[epath,epy]->grain>=0.2.6->grain[parquet]>=0.2.6->MaxText==0.1.0) (6.5.2)
Requirement already satisfied: starlette<0.48.0,>=0.40.0 in /usr/local/lib/python3.10/site-packages (from fastapi->google-jetstream@ git+https://github.com/AI-Hypercomputer/JetStream.git->MaxText==0.1.0) (0.47.3)
Requirement already satisfied: anyio<5,>=3.6.2 in /usr/local/lib/python3.10/site-packages (from starlette<0.48.0,>=0.40.0->fastapi->google-jetstream@ git+https://github.com/AI-Hypercomputer/JetStream.git->MaxText==0.1.0) (4.9.0)
Requirement already satisfied: exceptiongroup>=1.0.2 in /usr/local/lib/python3.10/site-packages (from anyio<5,>=3.6.2->starlette<0.48.0,>=0.40.0->fastapi->google-jetstream@ git+https://github.com/AI-Hypercomputer/JetStream.git->MaxText==0.1.0) (1.3.0)
Requirement already satisfied: sniffio>=1.1 in /usr/local/lib/python3.10/site-packages (from anyio<5,>=3.6.2->starlette<0.48.0,>=0.40.0->fastapi->google-jetstream@ git+https://github.com/AI-Hypercomputer/JetStream.git->MaxText==0.1.0) (1.3.1)
Requirement already satisfied: decorator>4.1.2 in /usr/local/lib/python3.10/site-packages (from gcsfs->MaxText==0.1.0) (5.2.1)
INFO: pip is looking at multiple versions of gcsfs to determine which version is compatible with other requirements. This could take a while.
Collecting gcsfs (from MaxText==0.1.0)
  Downloading gcsfs-2025.9.0-py2.py3-none-any.whl.metadata (2.1 kB)
  Downloading gcsfs-2025.7.0-py2.py3-none-any.whl.metadata (2.1 kB)
  Downloading gcsfs-2025.5.0.post1-py2.py3-none-any.whl.metadata (1.9 kB)
  Downloading gcsfs-2025.5.0-py2.py3-none-any.whl.metadata (1.9 kB)
  Downloading gcsfs-2025.3.2-py2.py3-none-any.whl.metadata (1.9 kB)
  Downloading gcsfs-2025.3.1-py2.py3-none-any.whl.metadata (1.9 kB)
  Downloading gcsfs-2025.3.0-py2.py3-none-any.whl.metadata (1.9 kB)
Requirement already satisfied: google-auth-oauthlib in /usr/local/lib/python3.10/site-packages (from gcsfs->MaxText==0.1.0) (1.2.2)
Requirement already satisfied: httplib2<1.0.0,>=0.19.0 in /usr/local/lib/python3.10/site-packages (from google-api-python-client->MaxText==0.1.0) (0.30.0)
Requirement already satisfied: google-auth-httplib2<1.0.0,>=0.2.0 in /usr/local/lib/python3.10/site-packages (from google-api-python-client->MaxText==0.1.0) (0.2.0)
Requirement already satisfied: uritemplate<5,>=3.0.1 in /usr/local/lib/python3.10/site-packages (from google-api-python-client->MaxText==0.1.0) (4.2.0)
Requirement already satisfied: pyparsing<4,>=3.0.4 in /usr/local/lib/python3.10/site-packages (from httplib2<1.0.0,>=0.19.0->google-api-python-client->MaxText==0.1.0) (3.2.3)
Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.10/site-packages (from google-auth-oauthlib->gcsfs->MaxText==0.1.0) (2.0.0)
Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.10/site-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib->gcsfs->MaxText==0.1.0) (3.2.2)
Collecting werkzeug>=1.0.1 (from tensorboard~=2.19.0->tensorflow>=2.13.0->MaxText==0.1.0)
  Downloading Werkzeug-2.0.3-py3-none-any.whl.metadata (4.5 kB)
Requirement already satisfied: gviz-api>=1.9.0 in /usr/local/lib/python3.10/site-packages (from tensorboard-plugin-profile->MaxText==0.1.0) (1.10.0)
Requirement already satisfied: wadler-lindig>=0.1.3 in /usr/local/lib/python3.10/site-packages (from jaxtyping->MaxText==0.1.0) (0.1.7)
Requirement already satisfied: click in /usr/local/lib/python3.10/site-packages (from nltk->google-jetstream@ git+https://github.com/AI-Hypercomputer/JetStream.git->MaxText==0.1.0) (8.2.1)
Requirement already satisfied: joblib in /usr/local/lib/python3.10/site-packages (from nltk->google-jetstream@ git+https://github.com/AI-Hypercomputer/JetStream.git->MaxText==0.1.0) (1.5.2)
Requirement already satisfied: regex>=2021.8.3 in /usr/local/lib/python3.10/site-packages (from nltk->google-jetstream@ git+https://github.com/AI-Hypercomputer/JetStream.git->MaxText==0.1.0) (2025.9.1)
Requirement already satisfied: antlr4-python3-runtime==4.9.* in /usr/local/lib/python3.10/site-packages (from omegaconf->MaxText==0.1.0) (4.9.3)
Requirement already satisfied: chex>=0.1.87 in /usr/local/lib/python3.10/site-packages (from optax->MaxText==0.1.0) (0.1.89)
Requirement already satisfied: toolz>=0.9.0 in /usr/local/lib/python3.10/site-packages (from chex>=0.1.87->optax->MaxText==0.1.0) (1.0.0)
Requirement already satisfied: psutil in /usr/local/lib/python3.10/site-packages (from portpicker->google-jetstream@ git+https://github.com/AI-Hypercomputer/JetStream.git->MaxText==0.1.0) (7.0.0)
Requirement already satisfied: cfgv>=2.0.0 in /usr/local/lib/python3.10/site-packages (from pre-commit->MaxText==0.1.0) (3.4.0)
Requirement already satisfied: identify>=1.0.0 in /usr/local/lib/python3.10/site-packages (from pre-commit->MaxText==0.1.0) (2.6.14)
Requirement already satisfied: nodeenv>=0.11.1 in /usr/local/lib/python3.10/site-packages (from pre-commit->MaxText==0.1.0) (1.9.1)
Requirement already satisfied: virtualenv>=20.10.0 in /usr/local/lib/python3.10/site-packages (from pre-commit->MaxText==0.1.0) (20.34.0)
Requirement already satisfied: distlib<1,>=0.3.7 in /usr/local/lib/python3.10/site-packages (from virtualenv>=20.10.0->pre-commit->MaxText==0.1.0) (0.4.0)
Requirement already satisfied: platformdirs<5,>=3.9.1 in /usr/local/lib/python3.10/site-packages (from virtualenv>=20.10.0->pre-commit->MaxText==0.1.0) (4.4.0)
Requirement already satisfied: black==24.10.0 in /usr/local/lib/python3.10/site-packages (from pyink->MaxText==0.1.0) (24.10.0)
Requirement already satisfied: mypy-extensions>=0.4.3 in /usr/local/lib/python3.10/site-packages (from pyink->MaxText==0.1.0) (1.1.0)
Requirement already satisfied: pathspec>=0.9.0 in /usr/local/lib/python3.10/site-packages (from pyink->MaxText==0.1.0) (0.12.1)
Requirement already satisfied: tomli>=1.1.0 in /usr/local/lib/python3.10/site-packages (from pyink->MaxText==0.1.0) (2.2.1)
Requirement already satisfied: astroid<=3.4.0.dev0,>=3.3.8 in /usr/local/lib/python3.10/site-packages (from pylint->MaxText==0.1.0) (3.3.11)
Requirement already satisfied: isort!=5.13,<7,>=4.2.5 in /usr/local/lib/python3.10/site-packages (from pylint->MaxText==0.1.0) (6.0.1)
Requirement already satisfied: mccabe<0.8,>=0.6 in /usr/local/lib/python3.10/site-packages (from pylint->MaxText==0.1.0) (0.7.0)
Requirement already satisfied: tomlkit>=0.10.1 in /usr/local/lib/python3.10/site-packages (from pylint->MaxText==0.1.0) (0.13.3)
Requirement already satisfied: iniconfig>=1 in /usr/local/lib/python3.10/site-packages (from pytest->MaxText==0.1.0) (2.1.0)
Requirement already satisfied: pluggy<2,>=1.5 in /usr/local/lib/python3.10/site-packages (from pytest->MaxText==0.1.0) (1.6.0)
Requirement already satisfied: importlab>=0.8 in /usr/local/lib/python3.10/site-packages (from pytype->MaxText==0.1.0) (0.8.1)
Requirement already satisfied: immutabledict>=4.1.0 in /usr/local/lib/python3.10/site-packages (from pytype->MaxText==0.1.0) (4.2.1)
Requirement already satisfied: jinja2>=3.1.2 in /usr/local/lib/python3.10/site-packages (from pytype->MaxText==0.1.0) (3.1.6)
Requirement already satisfied: libcst>=1.0.1 in /usr/local/lib/python3.10/site-packages (from pytype->MaxText==0.1.0) (1.8.0)
Requirement already satisfied: msgspec>=0.18.6 in /usr/local/lib/python3.10/site-packages (from pytype->MaxText==0.1.0) (0.19.0)
Requirement already satisfied: networkx>=2.8 in /usr/local/lib/python3.10/site-packages (from pytype->MaxText==0.1.0) (3.4.2)
Requirement already satisfied: ninja>=1.10.0.post2 in /usr/local/lib/python3.10/site-packages (from pytype->MaxText==0.1.0) (1.13.0)
Requirement already satisfied: pycnite>=2024.07.31 in /usr/local/lib/python3.10/site-packages (from pytype->MaxText==0.1.0) (2024.7.31)
Requirement already satisfied: pydot>=1.4.2 in /usr/local/lib/python3.10/site-packages (from pytype->MaxText==0.1.0) (4.0.1)
Requirement already satisfied: tabulate>=0.8.10 in /usr/local/lib/python3.10/site-packages (from pytype->MaxText==0.1.0) (0.9.0)
Requirement already satisfied: toml>=0.10.2 in /usr/local/lib/python3.10/site-packages (from pytype->MaxText==0.1.0) (0.10.2)
Requirement already satisfied: clu in /usr/local/lib/python3.10/site-packages (from seqio->google-jetstream@ git+https://github.com/AI-Hypercomputer/JetStream.git->MaxText==0.1.0) (0.0.12)
Requirement already satisfied: editdistance in /usr/local/lib/python3.10/site-packages (from seqio->google-jetstream@ git+https://github.com/AI-Hypercomputer/JetStream.git->MaxText==0.1.0) (0.8.1)
Requirement already satisfied: pyglove in /usr/local/lib/python3.10/site-packages (from seqio->google-jetstream@ git+https://github.com/AI-Hypercomputer/JetStream.git->MaxText==0.1.0) (0.4.5)
Requirement already satisfied: tfds-nightly==4.9.2.dev202308090034 in /usr/local/lib/python3.10/site-packages (from seqio->google-jetstream@ git+https://github.com/AI-Hypercomputer/JetStream.git->MaxText==0.1.0) (4.9.2.dev202308090034)
Requirement already satisfied: promise in /usr/local/lib/python3.10/site-packages (from tfds-nightly==4.9.2.dev202308090034->seqio->google-jetstream@ git+https://github.com/AI-Hypercomputer/JetStream.git->MaxText==0.1.0) (2.3)
Requirement already satisfied: tensorflow-metadata in /usr/local/lib/python3.10/site-packages (from tfds-nightly==4.9.2.dev202308090034->seqio->google-jetstream@ git+https://github.com/AI-Hypercomputer/JetStream.git->MaxText==0.1.0) (1.16.1)
Requirement already satisfied: einops in /usr/local/lib/python3.10/site-packages (from etils[epath,epy]->grain>=0.2.6->grain[parquet]>=0.2.6->MaxText==0.1.0) (0.8.1)
Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.10/site-packages (from sympy->google-jetstream@ git+https://github.com/AI-Hypercomputer/JetStream.git->MaxText==0.1.0) (1.3.0)
Requirement already satisfied: simple_parsing in /usr/local/lib/python3.10/site-packages (from tensorflow-datasets->MaxText==0.1.0) (0.1.7)
Requirement already satisfied: tokenizers<=0.23.0,>=0.22.0 in /usr/local/lib/python3.10/site-packages (from transformers->MaxText==0.1.0) (0.22.0)
Requirement already satisfied: safetensors>=0.4.3 in /usr/local/lib/python3.10/site-packages (from transformers->MaxText==0.1.0) (0.6.2)
Requirement already satisfied: h11>=0.8 in /usr/local/lib/python3.10/site-packages (from uvicorn->google-jetstream@ git+https://github.com/AI-Hypercomputer/JetStream.git->MaxText==0.1.0) (0.16.0)
Downloading google_cloud_aiplatform-1.61.0-py2.py3-none-any.whl (5.1 MB)
   ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 5.1/5.1 MB 54.3 MB/s eta 0:00:00
Downloading sentencepiece-0.2.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.3 MB)
   ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 1.3/1.3 MB 109.0 MB/s eta 0:00:00
Downloading grpcio_status-1.48.2-py3-none-any.whl (14 kB)
Downloading gcsfs-2025.3.0-py2.py3-none-any.whl (36 kB)
Downloading Werkzeug-2.0.3-py3-none-any.whl (289 kB)
Building wheels for collected packages: MaxText, mlperf-logging
  Building editable for MaxText (pyproject.toml): started
  Building editable for MaxText (pyproject.toml): finished with status 'done'
  Created wheel for MaxText: filename=maxtext-0.1.0-0.editable-py3-none-any.whl size=16154 sha256=3867b543f328ad7bbfbbe588cd79fbb1a2024cb84a2216b5576a9a3ca2759125
  Stored in directory: /tmp/pip-ephem-wheel-cache-6lsb2ne1/wheels/b0/94/18/64145773cc64cf64aab6973c09d2ce4267b05f11c29e2a867a
  DEPRECATION: Building 'mlperf-logging' using the legacy setup.py bdist_wheel mechanism, which will be removed in a future version. pip 25.3 will enforce this behaviour change. A possible replacement is to use the standardized build interface by setting the `--use-pep517` option, (possibly combined with `--no-build-isolation`), or adding a `pyproject.toml` file to the source tree of 'mlperf-logging'. Discussion can be found at https://github.com/pypa/pip/issues/6334
  Building wheel for mlperf-logging (setup.py): started
  Building wheel for mlperf-logging (setup.py): finished with status 'done'
  Created wheel for mlperf-logging: filename=mlperf_logging-4.1.29-py3-none-any.whl size=323438 sha256=fc8ea24b379443f60da312c17725dbbaba9821070dbf6c0b1ca7134bf9dea426
  Stored in directory: /tmp/pip-ephem-wheel-cache-6lsb2ne1/wheels/ea/97/a5/dba40e48eed6cd8d04441e08d98517fbe0b4063e3798d13629
Successfully built MaxText mlperf-logging
Installing collected packages: sentencepiece, werkzeug, grpcio-status, mlperf-logging, google-cloud-aiplatform, gcsfs, MaxText
  Attempting uninstall: sentencepiece
    Found existing installation: sentencepiece 0.1.97
    Uninstalling sentencepiece-0.1.97:
      Successfully uninstalled sentencepiece-0.1.97
  Attempting uninstall: werkzeug
    Found existing installation: Werkzeug 3.1.3
    Uninstalling Werkzeug-3.1.3:
      Successfully uninstalled Werkzeug-3.1.3
  Attempting uninstall: grpcio-status
    Found existing installation: grpcio-status 1.71.0
    Uninstalling grpcio-status-1.71.0:
      Successfully uninstalled grpcio-status-1.71.0
  Attempting uninstall: mlperf-logging
    Found existing installation: mlperf-logging 4.1.28
    Uninstalling mlperf-logging-4.1.28:
      Successfully uninstalled mlperf-logging-4.1.28
  Attempting uninstall: google-cloud-aiplatform
    Found existing installation: google-cloud-aiplatform 1.96.0
    Uninstalling google-cloud-aiplatform-1.96.0:
      Successfully uninstalled google-cloud-aiplatform-1.96.0
  Attempting uninstall: gcsfs
    Found existing installation: gcsfs 2025.5.1
    Uninstalling gcsfs-2025.5.1:
      Successfully uninstalled gcsfs-2025.5.1

Successfully installed MaxText-0.1.0 gcsfs-2025.3.0 google-cloud-aiplatform-1.61.0 grpcio-status-1.48.2 mlperf-logging-4.1.29 sentencepiece-0.2.0 werkzeug-2.0.3

[notice] A new release of pip is available: 25.1.1 -> 25.2
[notice] To update, run: pip install --upgrade pip
Collecting tensorflow-datasets==4.9.7
  Downloading tensorflow_datasets-4.9.7-py3-none-any.whl.metadata (9.6 kB)
Requirement already satisfied: absl-py in /usr/local/lib/python3.10/site-packages (from tensorflow-datasets==4.9.7) (2.3.0)
Requirement already satisfied: click in /usr/local/lib/python3.10/site-packages (from tensorflow-datasets==4.9.7) (8.2.1)
Requirement already satisfied: dm-tree in /usr/local/lib/python3.10/site-packages (from tensorflow-datasets==4.9.7) (0.1.9)
Requirement already satisfied: immutabledict in /usr/local/lib/python3.10/site-packages (from tensorflow-datasets==4.9.7) (4.2.1)
Requirement already satisfied: numpy in /usr/local/lib/python3.10/site-packages (from tensorflow-datasets==4.9.7) (2.1.3)
Requirement already satisfied: promise in /usr/local/lib/python3.10/site-packages (from tensorflow-datasets==4.9.7) (2.3)
Requirement already satisfied: protobuf>=3.20 in /usr/local/lib/python3.10/site-packages (from tensorflow-datasets==4.9.7) (3.20.3)
Requirement already satisfied: psutil in /usr/local/lib/python3.10/site-packages (from tensorflow-datasets==4.9.7) (7.0.0)
Requirement already satisfied: pyarrow in /usr/local/lib/python3.10/site-packages (from tensorflow-datasets==4.9.7) (21.0.0)
Requirement already satisfied: requests>=2.19.0 in /usr/local/lib/python3.10/site-packages (from tensorflow-datasets==4.9.7) (2.32.3)
Requirement already satisfied: simple-parsing in /usr/local/lib/python3.10/site-packages (from tensorflow-datasets==4.9.7) (0.1.7)
Requirement already satisfied: tensorflow-metadata in /usr/local/lib/python3.10/site-packages (from tensorflow-datasets==4.9.7) (1.16.1)
Requirement already satisfied: termcolor in /usr/local/lib/python3.10/site-packages (from tensorflow-datasets==4.9.7) (3.1.0)
Requirement already satisfied: toml in /usr/local/lib/python3.10/site-packages (from tensorflow-datasets==4.9.7) (0.10.2)
Requirement already satisfied: tqdm in /usr/local/lib/python3.10/site-packages (from tensorflow-datasets==4.9.7) (4.67.1)
Requirement already satisfied: wrapt in /usr/local/lib/python3.10/site-packages (from tensorflow-datasets==4.9.7) (1.17.2)
Requirement already satisfied: array-record>=0.5.0 in /usr/local/lib/python3.10/site-packages (from tensorflow-datasets==4.9.7) (0.7.2)
Requirement already satisfied: etils>=1.6.0 in /usr/local/lib/python3.10/site-packages (from etils[edc,enp,epath,epy,etree]>=1.6.0; python_version < "3.11"->tensorflow-datasets==4.9.7) (1.12.2)
Requirement already satisfied: einops in /usr/local/lib/python3.10/site-packages (from etils[edc,enp,epath,epy,etree]>=1.6.0; python_version < "3.11"->tensorflow-datasets==4.9.7) (0.8.1)
Requirement already satisfied: fsspec in /usr/local/lib/python3.10/site-packages (from etils[edc,enp,epath,epy,etree]>=1.6.0; python_version < "3.11"->tensorflow-datasets==4.9.7) (2025.3.0)
Requirement already satisfied: importlib_resources in /usr/local/lib/python3.10/site-packages (from etils[edc,enp,epath,epy,etree]>=1.6.0; python_version < "3.11"->tensorflow-datasets==4.9.7) (6.5.2)
Requirement already satisfied: typing_extensions in /usr/local/lib/python3.10/site-packages (from etils[edc,enp,epath,epy,etree]>=1.6.0; python_version < "3.11"->tensorflow-datasets==4.9.7) (4.14.0)
Requirement already satisfied: zipp in /usr/local/lib/python3.10/site-packages (from etils[edc,enp,epath,epy,etree]>=1.6.0; python_version < "3.11"->tensorflow-datasets==4.9.7) (3.22.0)
Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/site-packages (from requests>=2.19.0->tensorflow-datasets==4.9.7) (3.4.2)
Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/site-packages (from requests>=2.19.0->tensorflow-datasets==4.9.7) (3.10)
Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/site-packages (from requests>=2.19.0->tensorflow-datasets==4.9.7) (2.4.0)
Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/site-packages (from requests>=2.19.0->tensorflow-datasets==4.9.7) (2025.4.26)
Requirement already satisfied: attrs>=18.2.0 in /usr/local/lib/python3.10/site-packages (from dm-tree->tensorflow-datasets==4.9.7) (25.3.0)
Requirement already satisfied: six in /usr/local/lib/python3.10/site-packages (from promise->tensorflow-datasets==4.9.7) (1.17.0)
Requirement already satisfied: docstring-parser<1.0,>=0.15 in /usr/local/lib/python3.10/site-packages (from simple-parsing->tensorflow-datasets==4.9.7) (0.16)
Downloading tensorflow_datasets-4.9.7-py3-none-any.whl (5.3 MB)
   ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 5.3/5.3 MB 92.5 MB/s eta 0:00:00
Installing collected packages: tensorflow-datasets
  Attempting uninstall: tensorflow-datasets
    Found existing installation: tensorflow-datasets 4.9.9
    Uninstalling tensorflow-datasets-4.9.9:
      Successfully uninstalled tensorflow-datasets-4.9.9
Successfully installed tensorflow-datasets-4.9.7

[notice] A new release of pip is available: 25.1.1 -> 25.2
[notice] To update, run: pip install --upgrade pip
2025-09-13 01:11:05.232677: I tensorflow/core/util/port.cc:153] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.
2025-09-13 01:11:05.233910: I external/local_xla/xla/tsl/cuda/cudart_stub.cc:32] Could not find cuda drivers on your machine, GPU will not be used.
2025-09-13 01:11:05.236565: I external/local_xla/xla/tsl/cuda/cudart_stub.cc:32] Could not find cuda drivers on your machine, GPU will not be used.
2025-09-13 01:11:05.243467: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:467] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered
WARNING: All log messages before absl::InitializeLog() is called are written to STDERR
E0000 00:00:1757725865.255337     141 cuda_dnn.cc:8579] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered
E0000 00:00:1757725865.258767     141 cuda_blas.cc:1407] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered
W0000 00:00:1757725865.269246     141 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.
W0000 00:00:1757725865.269262     141 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.
W0000 00:00:1757725865.269264     141 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.
W0000 00:00:1757725865.269266     141 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.
2025-09-13 01:11:05.272220: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.
To enable the following instructions: AVX2 AVX512F AVX512_VNNI AVX512_BF16 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.
2025-09-13 01:11:08.064954: E external/local_xla/xla/stream_executor/cuda/cuda_platform.cc:51] failed call to cuInit: INTERNAL: CUDA error: Failed call to cuInit: UNKNOWN ERROR (303)
Updating keys from env and command line: ['run_name', 'model_name', 'load_parameters_path', 'checkpoint_period', 'base_output_directory', 'ici_fsdp_parallelism', 'tokenizer_path', 'tokenizer_type', 'per_device_batch_size', 'dataset_path', 'steps', 'use_vertex_tensorboard']
Running Model: llama3.1-8b
Updating following parameters in config

base_emb_dim: 4096
base_num_query_heads: 32
base_num_kv_heads: 8
base_num_decoder_layers: 32
base_mlp_dim: 14336
head_dim: 128
mlp_activations: ['silu', 'linear']
vocab_size: 128256
enable_dropout: False
logits_via_embedding: False
normalization_layer_epsilon: 1e-05
rope_max_timescale: 500000
decoder_block: llama2
Updating keys from model: ['base_emb_dim', 'base_num_query_heads', 'base_num_kv_heads', 'base_num_decoder_layers', 'base_mlp_dim', 'head_dim', 'mlp_activations', 'vocab_size', 'enable_dropout', 'logits_via_embedding', 'normalization_layer_epsilon', 'rope_max_timescale', 'decoder_block']
Attempting to initialize the jax distributed system...
INFO:2025-09-13 01:11:18,009:jax._src.distributed:132: Starting JAX distributed service on [::]:8476
I0913 01:11:18.009263 140416767584064 distributed.py:132] Starting JAX distributed service on [::]:8476
2025-09-13 01:11:18.009696: I external/xla/xla/tsl/platform/default/grpc_credentials.cc:38] gRPC insecure server credentials are used.
2025-09-13 01:11:18.009759: I external/xla/xla/tsl/distributed_runtime/coordination/coordination_service.cc:224] Initializing CoordinationService
2025-09-13 01:11:18.010679: I external/xla/xla/pjrt/distributed/service.cc:75] Coordination service is enabled.
2025-09-13 01:11:18.010845: I external/xla/xla/pjrt/distributed/service.cc:105] Jax service listening on [::]:8476
2025-09-13 01:11:18.010859: I external/xla/xla/tsl/platform/default/grpc_credentials.cc:30] gRPC insecure client credentials are used.
INFO:2025-09-13 01:11:18,010:jax._src.distributed:149: Connecting to JAX distributed service on maxtext-vlp16-default-slice-0-0.maxtext-vlp16-default:8476
I0913 01:11:18.010941 140416767584064 distributed.py:149] Connecting to JAX distributed service on maxtext-vlp16-default-slice-0-0.maxtext-vlp16-default:8476
2025-09-13 01:11:19.166645: I external/xla/xla/tsl/distributed_runtime/coordination/coordination_service.h:519] /job:jax_worker/replica:0/task:1 has connected to coordination service. Incarnation: 8899723496565090845
2025-09-13 01:11:19.166745: I external/xla/xla/tsl/distributed_runtime/coordination/coordination_service.h:519] /job:jax_worker/replica:0/task:2 has connected to coordination service. Incarnation: 13175584618007710174
2025-09-13 01:11:19.166765: I external/xla/xla/tsl/distributed_runtime/coordination/coordination_service.h:519] /job:jax_worker/replica:0/task:3 has connected to coordination service. Incarnation: 9063468921575044126
2025-09-13 01:11:19.166790: I external/xla/xla/tsl/distributed_runtime/coordination/coordination_service.h:519] /job:jax_worker/replica:0/task:0 has connected to coordination service. Incarnation: 17107208323083209839
2025-09-13 01:11:19.166960: I external/xla/xla/tsl/distributed_runtime/coordination/coordination_service_agent.cc:342] Coordination agent has successfully connected.
2025-09-13 01:11:19.167186: I external/xla/xla/tsl/distributed_runtime/coordination/coordination_service_agent.cc:414] Polling for error from coordination service. This is a long-running RPC that will return only if an error is encountered or cancelled (e.g. due to shutdown).
2025-09-13 01:11:19.167333: I external/xla/xla/pjrt/distributed/client.cc:121] Connected to distributed JAX controller
Jax distributed system initialized!
2025-09-13 01:11:19.194272: I external/xla/xla/pjrt/pjrt_api.cc:115] GetPjrtApi was found for tpu at /usr/local/lib/python3.10/site-packages/libtpu/libtpu.so
2025-09-13 01:11:19.194290: I external/xla/xla/pjrt/pjrt_api.cc:93] PJRT_Api is set for device type tpu
2025-09-13 01:11:19.194309: I external/xla/xla/pjrt/pjrt_api.cc:161] The PJRT plugin has PJRT API version 0.68. The framework PJRT API version is 0.68.
I0913 01:11:19.195346     141 b295d63588a.cc:761] Linux version 6.6.93+ (builder@ca6874c171ac) (Chromium OS 17.0_pre498229-r33 clang version 17.0.0 (/mnt/host/source/src/third_party/llvm-project 14f0776550b5a49e1c42f49a00213f7f3fa047bf), LLD 17.0.0) #1 SMP Thu Jul  3 10:14:34 UTC 2025
I0913 01:11:19.195462     141 b295d63588a.cc:843] Process id 141
I0913 01:11:19.195476     141 b295d63588a.cc:848] Current working directory /deps
I0913 01:11:19.195478     141 b295d63588a.cc:850] Current timezone is UTC (currently UTC +00:00)
I0913 01:11:19.195481     141 b295d63588a.cc:854] Built on May 15 2025 08:22:47 (1747322567)
I0913 01:11:19.195482     141 b295d63588a.cc:855]  at rbex-enqueue-targets@iybca6.prod.google.com:/google/src/cloud/buildrabbit-username/buildrabbit-client/g3     
I0913 01:11:19.195484     141 b295d63588a.cc:856]  as //learning/45eac/tfrc/executor:_libtpu.so.native
I0913 01:11:19.195486     141 b295d63588a.cc:857]  for gcc-4.X.Y-crosstool-v18-llvm-grtev4-k8.k8
I0913 01:11:19.195487     141 b295d63588a.cc:860]  from changelist 759148519 with baseline 758471328 in a mint client based on __ar56t/branches/libtpu_lts_release_branch/758471328.2/g3     
I0913 01:11:19.195493     141 b295d63588a.cc:864] Build label: libtpu_lts_20250515_b_RC00
I0913 01:11:19.195495     141 b295d63588a.cc:866] Build tool: Bazel, release r4rca-2025.04.26-1 (mainline @751384015)
I0913 01:11:19.195496     141 b295d63588a.cc:867] Build target: 
I0913 01:11:19.195498     141 b295d63588a.cc:874] Command line arguments:
I0913 01:11:19.195499     141 b295d63588a.cc:876] argv[0]: './tpu_driver'
I0913 01:11:19.195502     141 b295d63588a.cc:876] argv[1]: '--minloglevel=0'
I0913 01:11:19.195504     141 b295d63588a.cc:876] argv[2]: '--stderrthreshold=0'
I0913 01:11:19.195506     141 b295d63588a.cc:876] argv[3]: '--v=0'
I0913 01:11:19.195508     141 b295d63588a.cc:876] argv[4]: '--vmodule='
I0913 01:11:19.195509     141 b295d63588a.cc:876] argv[5]: '--log_dir=/tmp/tpu_logs'
I0913 01:11:19.195511     141 b295d63588a.cc:876] argv[6]: '--max_log_size=1024'
I0913 01:11:19.195512     141 b295d63588a.cc:876] argv[7]: '--enforce_kernel_ipv6_support=0'
I0913 01:11:19.195514     141 b295d63588a.cc:876] argv[8]: '--next_pluggable_device_use_c_api=0'
I0913 01:11:19.195515     141 b295d63588a.cc:876] argv[9]: '--2a886c8_wrap=false,false,false'
I0913 01:11:19.195517     141 b295d63588a.cc:876] argv[10]: '--2a886c8_chip_config_name=megachip_tccontrol'
I0913 01:11:19.195519     141 b295d63588a.cc:876] argv[11]: '--2a886c8_chips_per_host_bounds=2,2,1'
I0913 01:11:19.195520     141 b295d63588a.cc:876] argv[12]: '--2a886c8_host_bounds=2,2,1'
I0913 01:11:19.195522     141 b295d63588a.cc:876] argv[13]: '--2a886c8_slice_builder_worker_port=8471'
I0913 01:11:19.195524     141 b295d63588a.cc:876] argv[14]: '--2a886c8_slice_builder_worker_addresses=maxtext-vlp16-default-slice-0-0.maxtext-vlp16-default:8471,maxtext-vlp16-default-slice-0-1.maxtext-vlp16-default:8471,maxtext-vlp16-default-slice-0-2.maxtext-vlp16-default:8471,maxtext-vlp16-default-slice-0-3.maxtext-vlp16-default:8471'
I0913 01:11:19.195525     141 b295d63588a.cc:876] argv[15]: '--tpu_slice_builder_dump_chip=false'
I0913 01:11:19.195527     141 b295d63588a.cc:876] argv[16]: '--tpu_slice_builder_dump_chip_force=false'
I0913 01:11:19.195529     141 b295d63588a.cc:876] argv[17]: '--tpu_slice_builder_dump_to_localhost=1'
I0913 01:11:19.195530     141 b295d63588a.cc:876] argv[18]: '--vbar_control_service_url=10.128.0.132:8353'
I0913 01:11:19.195532     141 b295d63588a.cc:876] argv[19]: '--bypass_vbar_control_service=0'
I0913 01:11:19.195533     141 b295d63588a.cc:876] argv[20]: '--runtime_metric_service_port=8431'
I0913 01:11:19.195535     141 b295d63588a.cc:876] argv[21]: '--tpu_hbm_report_enable=1'
I0913 01:11:19.195536     141 b295d63588a.cc:876] argv[22]: '--tpu_hbm_report_frequency=5s'
I0913 01:11:19.195538     141 b295d63588a.cc:876] argv[23]: '--enable_runtime_uptime_telemetry=true'
I0913 01:11:19.195540     141 b295d63588a.cc:876] argv[24]: '--xla_enable_async_all_gather=true'
I0913 01:11:19.195541     141 b295d63588a.cc:876] argv[25]: 'TPU_MEGACORE=MEGACORE_DENSE'
I0913 01:11:19.195543     141 b295d63588a.cc:876] argv[26]: '--xla_tpu_use_enhanced_launch_barrier=true'
I0913 01:11:19.195544     141 b295d63588a.cc:876] argv[27]: '--xla_tpu_spmd_rng_bit_generator_unsafe=true'
I0913 01:11:19.195722     141 init.cc:78] Remote crash gathering hook installed.
I0913 01:11:19.195744     141 tpu_runtime_type_flags.cc:79] --tpu_use_tfrt not specified. Using default value: true
I0913 01:11:19.207148     141 tpu_hal.cc:452] Registered plugin from module: breakpoint_debugger_server
I0913 01:11:19.208773     141 tf_tpu_flags.cc:60] 2a886c8Platform is NOT registered.
I0913 01:11:19.208942     141 logger.cc:310] Enabling threaded logging for severity WARNING
I0913 01:11:19.209061     141 mlock.cc:219] mlock()-ed 4096 bytes for BuildID, using 1 syscalls.
I0913 01:11:19.209130     141 gce_instance_metadata_snapshot.cc:31] Skipping MDS query due to true
W0913 01:11:19.209307     141 uptime_telemetry.cc:187] UptimeMetric attributes are updated.
Previous Attributes: go/debugstr  
key: "uptime_attributes"
value {
  kvlist_attr {
    attributes {
      key: "ml_framework_name"
      value {
        string_attr: "tensorflow"
      }
    }
    attributes {
      key: "ml_framework_version"
      value {
        string_attr: "tensorflow-2.19.0"
      }
    }
  }
}

New Attributes: go/debugstr  
key: "uptime_attributes"
value {
  kvlist_attr {
    attributes {
      key: "ml_framework_name"
      value {
        string_attr: "jax"
      }
    }
    attributes {
      key: "ml_framework_version"
      value {
        string_attr: "jax-0.6.1"
      }
    }
  }
}
I0913 01:11:19.219699     141 singleton_tpu_states_manager.cc:73] TPU premapped buffer enabled. Size: 4294967296 Threshold: 4294967296
I0913 01:11:19.219718     141 singleton_tpu_states_manager.cc:96] TpuStatesManager::GetOrCreate(): no tpu system exists. Creating a new tpu system.
I0913 01:11:19.221035     141 device_util.cc:124] Found 4 TPU v6 lite chips.
I0913 01:11:19.221049     141 tpu_version_flag.cc:53] Using auto-detected TPU version TPU v6 lite
I0913 01:11:19.222091     141 device_util.cc:124] Found 4 TPU v6 lite chips.
I0913 01:11:19.223124     141 device_util.cc:124] Found 4 TPU v6 lite chips.
I0913 01:11:19.224960     508 device_util.cc:124] Found 4 TPU v6 lite chips.
I0913 01:11:19.225156     508 config.cc:265] gRPC experiments: event_engine_callback_cq:off; default-enabled: callv3_client_auth_filter, event_engine_dns, google_no_envelope_resolver, max_pings_wo_data_throttle, monitoring_experiment, posix_ee_skip_grpc_init, rq_fast_reject, rst_stream_fix
I0913 01:11:19.246273     508 flags_util.cc:315] Using 8471 from --2a886c8_slice_builder_worker_port as SliceBuilder worker service port.
I0913 01:11:19.246377     508 runtime_metric_service.cc:122] Successfully started Runtime Metric Service on port: 8431
I0913 01:11:19.247532     508 device_util.cc:124] Found 4 TPU v6 lite chips.
I0913 01:11:19.247547     508 tpu_network_factory.cc:69] Running in Cloud, using TpunetdClient
I0913 01:11:19.247553     508 tpunetd_client.cc:130] Creating TpunetdClient with topology go/debugstr  
x_dimension: 4
y_dimension: 4
x_wrapping: false
y_wrapping: false
I0913 01:11:19.252229     508 init-domain.cc:126] Fiber init: default domain = futex, concurrency = 198, prefix = futex-default
I0913 01:11:21.675040     534 async_driver.cc:452] [/dev/vfio/1 tpu26:pe2:0] Driver opened.
I0913 01:11:21.696225     533 async_driver.cc:452] [/dev/vfio/0 tpu26:pe2:1] Driver opened.
I0913 01:11:21.710670     536 async_driver.cc:452] [/dev/vfio/3 tpu26:pe2:2] Driver opened.
I0913 01:11:21.725152     535 async_driver.cc:452] [/dev/vfio/2 tpu26:pe2:3] Driver opened.
W0913 01:11:21.751941     533 tpu_vxc_driver.cc:738] Skipping initialization of PA bits on {type = TensorCore, index = 0}
W0913 01:11:21.762214     534 tpu_vxc_driver.cc:738] Skipping initialization of PA bits on {type = TensorCore, index = 0}
W0913 01:11:21.763457     535 tpu_vxc_driver.cc:738] Skipping initialization of PA bits on {type = TensorCore, index = 0}
W0913 01:11:21.763530     536 tpu_vxc_driver.cc:738] Skipping initialization of PA bits on {type = TensorCore, index = 0}
W0913 01:11:21.763815     533 tpu_vxc_driver.cc:738] Skipping initialization of PA bits on {type = SparseCore, index = 0}
W0913 01:11:21.765037     534 tpu_vxc_driver.cc:738] Skipping initialization of PA bits on {type = SparseCore, index = 0}
W0913 01:11:21.765890     536 tpu_vxc_driver.cc:738] Skipping initialization of PA bits on {type = SparseCore, index = 0}
W0913 01:11:21.765938     535 tpu_vxc_driver.cc:738] Skipping initialization of PA bits on {type = SparseCore, index = 0}
W0913 01:11:21.766097     533 tpu_vxc_driver.cc:738] Skipping initialization of PA bits on {type = SparseCore, index = 1}
W0913 01:11:21.766175     533 async_driver.cc:1701] All cores not supported.
W0913 01:11:21.766948     534 tpu_vxc_driver.cc:738] Skipping initialization of PA bits on {type = SparseCore, index = 1}
W0913 01:11:21.767047     534 async_driver.cc:1701] All cores not supported.
W0913 01:11:21.781124     536 tpu_vxc_driver.cc:738] Skipping initialization of PA bits on {type = SparseCore, index = 1}
W0913 01:11:21.781219     536 async_driver.cc:1701] All cores not supported.
W0913 01:11:21.781240     535 tpu_vxc_driver.cc:738] Skipping initialization of PA bits on {type = SparseCore, index = 1}
W0913 01:11:21.781324     535 async_driver.cc:1701] All cores not supported.
I0913 01:11:21.781405     508 tpunetd_client.cc:272] Connecting to vbar control service at 10.128.0.132:8353
I0913 01:11:21.784705     671 futex.cc:61] RAW: Futex::Swap(): using GFUTEX_SWAP
I0913 01:11:21.785156     743 futex.cc:61] RAW: Futex::Swap(): using GFUTEX_SWAP
I0913 01:11:22.958737     508 tpunetd_client.cc:236] Session manager starting a new session...
I0913 01:11:22.959641     674 broadcast_barrier.cc:115] All instances are ready for PRE_START_SESSION_BARRIER, broadcasting notification...
I0913 01:11:23.061687     508 vbar_control.cc:180] TPU backend connection test passed! 
I0913 01:11:24.165241     674 broadcast_barrier.cc:115] All instances are ready for POST_START_SESSION_BARRIER, broadcasting notification...
I0913 01:11:24.166006     508 tpunetd_client.cc:238] Session manager started the new session.
I0913 01:11:24.166025     508 tpunetd_client.cc:242] Session master starting a new session...
I0913 01:11:24.166028     508 session_master.cc:259] Starting a new ICI network session...
I0913 01:11:24.166031     508 session_master.cc:211] Worker Address: maxtext-vlp16-default-slice-0-2.maxtext-vlp16-default:8471
I0913 01:11:24.166033     508 session_master.cc:211] Worker Address: maxtext-vlp16-default-slice-0-0.maxtext-vlp16-default:8471
I0913 01:11:24.166035     508 session_master.cc:211] Worker Address: maxtext-vlp16-default-slice-0-1.maxtext-vlp16-default:8471
I0913 01:11:24.166037     508 session_master.cc:211] Worker Address: maxtext-vlp16-default-slice-0-3.maxtext-vlp16-default:8471
I0913 01:11:24.166252     745 session_worker_service.cc:106] Session master notifies the worker in a new session: 96b961ff5d126d8d
I0913 01:11:24.166652     508 session_master.cc:211] Worker Address: maxtext-vlp16-default-slice-0-2.maxtext-vlp16-default:8471
I0913 01:11:24.166664     508 session_master.cc:211] Worker Address: maxtext-vlp16-default-slice-0-0.maxtext-vlp16-default:8471
I0913 01:11:24.166666     508 session_master.cc:211] Worker Address: maxtext-vlp16-default-slice-0-1.maxtext-vlp16-default:8471
I0913 01:11:24.166667     508 session_master.cc:211] Worker Address: maxtext-vlp16-default-slice-0-3.maxtext-vlp16-default:8471
I0913 01:11:24.269884     508 session_master.cc:303] Successfully started ICI network session with session id: 96b961ff5d126d8d
I0913 01:11:24.269952     508 tpunetd_client.cc:244] Session master started the new session.
I0913 01:11:24.271081     508 tpu_hal.cc:213] Starting premapped memory manager initialization...
W0913 01:11:24.271817     838 libtpu_telemetry_utils.cc:44] Metric already exists: hlo.execution.timing.distribution.microseconds
W0913 01:11:24.271821     839 libtpu_telemetry_utils.cc:44] Metric already exists: hlo.execution.timing.distribution.microseconds
W0913 01:11:24.271865     838 libtpu_telemetry_utils.cc:44] Metric already exists: hlo.queue.size.gauge
W0913 01:11:24.271870     839 libtpu_telemetry_utils.cc:44] Metric already exists: hlo.queue.size.gauge
W0913 01:11:24.272393     837 libtpu_telemetry_utils.cc:44] Metric already exists: hlo.execution.timing.distribution.microseconds
W0913 01:11:24.272432     837 libtpu_telemetry_utils.cc:44] Metric already exists: hlo.queue.size.gauge
I0913 01:11:26.005753     843 tpu_debug_service_impl.cc:198] StartDebuggingSessionOnCore called on already initialized TpuDebugServiceImpl, Overwriting the existing state.
I0913 01:11:26.035988     844 tpu_debug_service_impl.cc:198] StartDebuggingSessionOnCore called on already initialized TpuDebugServiceImpl, Overwriting the existing state.
I0913 01:11:26.036324     845 tpu_debug_service_impl.cc:198] StartDebuggingSessionOnCore called on already initialized TpuDebugServiceImpl, Overwriting the existing state.
I0913 01:11:26.201498     508 tpu_hal.cc:464] Found 1 registered plugins. Going to initialize them.
I0913 01:11:26.201579     508 system.cc:1064] tpu::System initialized, current host id: 0, logical device ids: 0,1,4,5
I0913 01:11:26.201608     141 tfrt_tpu_system_state.cc:216] CreateTpuSystemState: TPU initialization is successful and it took 6.978041548s
I0913 01:11:26.201622     141 tfrt_tpu_system_state.cc:220] CreateTpuSystemState: using TPU host premapped buffer of size: 4294967296
I0913 01:11:26.201634     141 tpu_host_allocator.cc:39] Premapped buffer is using alignment 64
I0913 01:11:26.201890     141 allocator_stats_reporter.cc:117] Starting AllocatorStats Reporter with reporting interval: 5s
2025-09-13 01:11:26.202041: I external/xla/xla/pjrt/pjrt_c_api_client.cc:130] PjRtCApiClient created.
Not using emergency checkpoint, ignoring local_checkpoint_directory, local_checkpoint_period, use_replicator_service and replicator_backup_interval_minutes
dataset_type set to tfds, will use keys['dataset_path']='/gcs-dir' and keys['dataset_name']='c4/en:3.0.1'
Config param activations_in_float32: False
Config param adam_b1: 0.9
Config param adam_b2: 0.95
Config param adam_eps: 1e-08
Config param adam_eps_root: 0.0
Config param adam_weight_decay: 0.1
Config param add_bos: True
Config param add_eos: True
Config param allow_split_physical_axes: False
Config param ar_cache_axis_order: 1,2,0,3
Config param async_checkpointing: True
Config param attention: autoselected
Config param attention_type: global
Config param attn_logits_soft_cap: None
Config param autoregressive_decode_assert: 
Config param base_emb_dim: 4096
Config param base_mlp_dim: 14336
Config param base_moe_mlp_dim: 7168
Config param base_num_decoder_layers: 32
Config param base_num_kv_heads: 8
Config param base_num_query_heads: 32
Config param base_output_directory: /gcs-dir/maxtext-output
Config param beta_fast: 32
Config param beta_slow: 1
Config param capacity_factor: -1.0
Config param cast_logits_to_fp32: True
Config param checkpoint_dir: /gcs-dir/maxtext-output/runner_llama3.1_8b/checkpoints/
Config param checkpoint_is_quantized: False
Config param checkpoint_period: 10
Config param checkpoint_storage_concurrent_gb: 96
Config param checkpoint_storage_target_data_file_size_bytes: 2147483648
Config param checkpoint_storage_use_ocdbt: True
Config param checkpoint_storage_use_zarr3: True
Config param chunk_attn_window_size: 0
Config param collect_stack_trace: False
Config param colocated_python_data_input: False
Config param compile_topology: 
Config param compile_topology_num_slices: -1
Config param compiled_trainstep_file: 
Config param compute_axis_order: 0,1,2,3
Config param constant_bound_config: []
Config param context: remat
Config param context_parallel_load_balance: True
Config param cosine_learning_rate_final_fraction: 0.1
Config param custom_mesh: 
Config param data_sharding: (('data', 'stage', 'fsdp', 'fsdp_transpose', 'sequence', 'context', 'context_autoregressive', 'tensor', 'tensor_transpose', 'tensor_sequence', 'expert', 'autoregressive'),)
Config param data_shuffle_seed: 0
Config param dataset_name: c4/en:3.0.1
Config param dataset_path: /gcs-dir
Config param dataset_type: tfds
Config param dcn_autoregressive_parallelism: 1
Config param dcn_context_autoregressive_parallelism: 1
Config param dcn_context_parallelism: 1
Config param dcn_data_parallelism: -1
Config param dcn_expert_parallelism: 1
Config param dcn_fsdp_parallelism: 1
Config param dcn_fsdp_transpose_parallelism: 1
Config param dcn_parallelism: [-1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]
Config param dcn_pipeline_parallelism: 1
Config param dcn_sequence_parallelism: 1
Config param dcn_tensor_parallelism: 1
Config param dcn_tensor_sequence_parallelism: 1
Config param dcn_tensor_transpose_parallelism: 1
Config param decode_sampling_nucleus_p: -1
Config param decode_sampling_strategy: greedy
Config param decode_sampling_temperature: 1.0
Config param decode_sampling_top_k: 0
Config param decoder_block: DecoderBlockType.LLAMA2
Config param decoder_layer_input: device
Config param dpo_beta: 0.1
Config param dpo_label_smoothing: 0.0
Config param dropout_rate: 0.0
Config param dtype: bfloat16
Config param dtype_mm: float32
Config param dump_hlo: False
Config param dump_hlo_delete_local_after: True
Config param dump_hlo_gcs_dir: 
Config param dump_hlo_local_dir: /tmp/xla_dump/
Config param dump_hlo_module_name: jit_train_step
Config param dump_hlo_upload_all: False
Config param dump_hlo_xla_flags: 
Config param dump_step: -1
Config param emb_dim: 4096
Config param enable_checkpoint_cloud_logger: False
Config param enable_checkpointing: True
Config param enable_data_shuffling: True
Config param enable_dropout: False
Config param enable_emergency_checkpoint: False
Config param enable_gcp_goodput_metrics: True
Config param enable_gcp_step_deviation_metrics: True
Config param enable_goodput_recording: False
Config param enable_jax_profiler: False
Config param enable_llm_inference_pool: False
Config param enable_model_warmup: False
Config param enable_padding_causal_mask: True
Config param enable_pathways_goodput: False
Config param enable_prefix_caching: False
Config param enable_single_controller: False
Config param enable_single_replica_ckpt_restoring: False
Config param enable_tensorboard: True
Config param eval_data_columns: ['text']
Config param eval_dataset_name: c4/en:3.0.1
Config param eval_interval: -1
Config param eval_per_device_batch_size: 1.0
Config param eval_split: validation
Config param eval_steps: -1
Config param expansion_factor_real_data: -1
Config param final_logits_soft_cap: None
Config param first_num_dense_layers: 0
Config param float32_logits: False
Config param float32_qk_product: False
Config param force_unroll: False
Config param freeze_vision_encoder_params: True
Config param fused_mlp: False
Config param fused_qkv: False
Config param gcs_metrics: False
Config param generate_slice: v5e-16
Config param global_batch_size_to_eval_on: 16
Config param global_batch_size_to_load: 16
Config param global_batch_size_to_load_eval: 16
Config param global_batch_size_to_train_on: 16
Config param global_parameter_scale: 1
Config param goodput_upload_interval_seconds: 30
Config param gradient_accumulation_steps: 1
Config param gradient_clipping_threshold: 1.0
Config param grain_eval_files: 
Config param grain_file_type: arrayrecord
Config param grain_train_files: 
Config param grain_worker_count: 1
Config param grain_worker_count_eval: 1
Config param hardware: tpu
Config param head_dim: 128
Config param heartbeat_reporting_interval_in_seconds: 5
Config param hf_data_dir: 
Config param hf_eval_files: 
Config param hf_eval_split: 
Config param hf_path: 
Config param hf_train_files: 
Config param hidden_size_for_vit: 1408
Config param ici_autoregressive_parallelism: 1
Config param ici_context_autoregressive_parallelism: 1
Config param ici_context_parallelism: 1
Config param ici_data_parallelism: 1
Config param ici_expert_parallelism: 1
Config param ici_fsdp_parallelism: -1
Config param ici_fsdp_transpose_parallelism: 1
Config param ici_parallelism: [1, 1, -1, 1, 1, 1, 1, 1, 1, 1, 1, 1]
Config param ici_pipeline_parallelism: 1
Config param ici_sequence_parallelism: 1
Config param ici_tensor_parallelism: 1
Config param ici_tensor_sequence_parallelism: 1
Config param ici_tensor_transpose_parallelism: 1
Config param image_path: 
Config param image_size_for_vit: 896
Config param inference_benchmark_test: False
Config param inference_metadata_file: 
Config param inference_microbenchmark_log_file_path: 
Config param inference_microbenchmark_loop_iters: 10
Config param inference_microbenchmark_num_samples: [1, 2, 3, 4, 5]
Config param inference_microbenchmark_prefill_lengths: 64,128,256,512,1024
Config param inference_microbenchmark_stages: prefill,generate
Config param inference_server: MaxtextInterleavedServer
Config param inhomogeneous_layer_cycle_interval: 1
Config param init_weights_seed: 0
Config param input_data_sharding_logical_axes: ['activation_embed_and_logits_batch', 'activation_norm_length']
Config param interleave_moe_layer_step: 1
Config param intermediate_size_for_vit: 5632
Config param jax_cache_dir: ~/jax_cache
Config param jax_debug_log_modules: 
Config param jax_distributed_initialization_timeout: 300
Config param jax_profiler_port: 9999
Config param key_proj: remat
Config param kv_lora_rank: 512
Config param kv_quant_axis: heads_and_dkv
Config param kv_quant_dtype: int8
Config param learning_rate: 3e-05
Config param learning_rate_schedule_steps: 50
Config param load_balance_loss_weight: 0.01
Config param load_from_prefill_dir: False
Config param load_full_state_path: 
Config param load_parameters_path: /gcs-dir/llama3.1-8b-it-maxtext/0/items
Config param local_checkpoint_directory: 
Config param local_checkpoint_period: 0
Config param local_rope_max_timescale: -1
Config param log_config: True
Config param log_period: 100
Config param logical_axis_rules: (('activation_batch', ('data', 'fsdp', 'fsdp_transpose', 'expert')), ('activation_batch_no_exp', ('data', 'fsdp', 'fsdp_transpose')), ('activation_embed_and_logits_batch', ('data', 'stage', 'fsdp', 'fsdp_transpose', 'expert')), ('activation_heads', ('tensor', 'tensor_transpose', 'sequence', 'tensor_sequence', 'autoregressive')), ('activation_kv_heads', ('tensor', 'tensor_transpose', 'sequence', 'tensor_sequence')), ('activation_length', ('sequence', 'context')), ('prefill_activation_length', ('sequence', 'context')), ('activation_length', ('context',)), ('activation_norm_length', ('tensor_sequence', 'context', 'sequence')), ('prefill_activation_norm_length', ('tensor_sequence', 'context', 'sequence')), ('activation_q_length', ('context',)), ('activation_kv_length', ()), ('activation_embed', ('tensor', 'tensor_transpose')), ('activation_mlp', ('tensor', 'tensor_transpose', 'tensor_sequence')), ('activation_kv', ('tensor', 'tensor_transpose', 'tensor_sequence')), ('activation_prefill_kv_batch', ('data', 'fsdp', 'fsdp_transpose', 'expert')), ('activation_kv_batch', ('data', 'fsdp', 'fsdp_transpose', 'expert')), ('activation_kv_head_dim', ('tensor', 'tensor_transpose', 'tensor_sequence')), ('activation_vocab', ('tensor', 'tensor_transpose', 'sequence', 'tensor_sequence')), ('activation_vocab', ('tensor', 'tensor_transpose')), ('activation_vocab', 'tensor_sequence'), ('activation_vocab', ('sequence', 'context')), ('activation_stage', 'stage'), ('activation_exp', ('expert',)), ('decode_batch', ('data', 'fsdp', 'fsdp_transpose', 'expert')), ('decode_length', ('sequence',)), ('mlp', ('fsdp_transpose', 'tensor', 'tensor_sequence', 'autoregressive')), ('vocab', ('tensor', 'tensor_transpose', 'tensor_sequence', 'autoregressive')), ('heads', ('tensor', 'tensor_transpose', 'tensor_sequence', 'autoregressive')), ('q_heads', ('tensor', 'tensor_transpose', 'tensor_sequence', 'autoregressive')), ('kv_heads', ('tensor', 'tensor_transpose', 'tensor_sequence', 'autoregressive')), ('embed', ('fsdp', 'fsdp_transpose', 'sequence', 'tensor_transpose', 'context', 'expert')), ('embed', ('fsdp', 'sequence', 'tensor_transpose', 'context', 'expert')), ('embed', ('fsdp', 'fsdp_transpose', 'sequence', 'context', 'expert')), ('embed', ('fsdp', 'sequence', 'context', 'expert')), ('embed_no_exp', ('fsdp', 'fsdp_transpose', 'sequence', 'tensor_transpose', 'context')), ('embed_no_exp', ('fsdp', 'sequence', 'tensor_transpose', 'context')), ('embed_no_exp', ('fsdp', 'fsdp_transpose', 'sequence', 'context')), ('embed_no_exp', ('fsdp', 'sequence', 'context')), ('q_lora', ('fsdp', 'fsdp_transpose', 'sequence', 'context', 'tensor_transpose', 'expert')), ('q_lora', ('fsdp', 'sequence', 'context', 'tensor_transpose', 'expert')), ('q_lora', ('fsdp', 'fsdp_transpose', 'sequence', 'context', 'expert')), ('q_lora', ('fsdp', 'sequence', 'context', 'expert')), ('kv_lora', ('fsdp', 'fsdp_transpose', 'sequence', 'context', 'tensor_transpose', 'expert')), ('kv_lora', ('fsdp', 'sequence', 'context', 'tensor_transpose', 'expert')), ('kv_lora', ('fsdp', 'fsdp_transpose', 'sequence', 'context', 'expert')), ('kv_lora', ('fsdp', 'sequence', 'context', 'expert')), ('norm', ('tensor', 'tensor_transpose', 'tensor_sequence')), ('layers', 'stage'), ('kv', ()), ('kv_head_dim', ()), ('cache_batch_prefill', ()), ('cache_batch', ()), ('cache_heads_none', ()), ('cache_heads', ('autoregressive', 'tensor', 'tensor_transpose', 'tensor_sequence')), ('cache_heads', ('autoregressive', 'tensor', 'tensor_sequence')), ('cache_kv', ()), ('cache_sequence', ()), ('exp', 'expert'), ('paged_kv_heads', ('tensor',)), ('num_pages', ()), ('tokens_per_page', ()), ('paged_kv_head_dim_size', ()))
Config param logits_dot_in_fp32: False
Config param logits_via_embedding: False
Config param lora_input_adapters_path: 
Config param matmul_precision: default
Config param max_checkify: False
Config param max_corpus_chars: 10000000
Config param max_position_embeddings: 163840
Config param max_prefill_predict_length: 64
Config param max_target_length: 2048
Config param megablox: True
Config param mesh_axes: ['data', 'stage', 'fsdp', 'fsdp_transpose', 'sequence', 'context', 'context_autoregressive', 'tensor', 'tensor_transpose', 'tensor_sequence', 'expert', 'autoregressive']
Config param metrics_dir: /gcs-dir/maxtext-output/runner_llama3.1_8b/metrics/
Config param metrics_file: 
Config param micro_batch_size_to_eval_on: 16
Config param micro_batch_size_to_train_on: 16
Config param mla_naive_kvcache: True
Config param mlp_activations: ['silu', 'linear']
Config param mlp_dim: 14336
Config param mlpwi: remat
Config param mlpwi_0: remat
Config param mlpwi_1: remat
Config param mlpwo: remat
Config param model_call_mode: 
Config param model_fsdp_ag_once: False
Config param model_name: llama3.1-8b
Config param moe_mlp_dim: 7168
Config param monitor_goodput: False
Config param monitor_step_time_deviation: True
Config param mscale: 1.0
Config param mu_dtype: float32
Config param multi_sampling: False
Config param n_routing_groups: -1
Config param nope_layer_interval: -1
Config param normalization_layer_epsilon: 1e-05
Config param normalize_embedding_logits: True
Config param num_attention_heads_for_vit: 16
Config param num_channels_for_vit: 3
Config param num_decoder_layers: 32
Config param num_epoch: 1
Config param num_experts: 1
Config param num_experts_per_tok: 1
Config param num_hidden_layers_for_vit: 34
Config param num_kv_heads: 8
Config param num_layers_per_pipeline_stage: 1
Config param num_pipeline_microbatches: -1
Config param num_pipeline_repeats: -1
Config param num_query_heads: 32
Config param num_slices: 1
Config param opt_type: adamw
Config param optimize_mesh_for_tpu_v6e: False
Config param optimizer_memory_host_offload: False
Config param original_max_position_embeddings: 4096
Config param out_proj: remat
Config param override_model_config: False
Config param packing: True
Config param pagedattn_head_dim_alignment: 128
Config param pagedattn_max_pages_per_group: 64
Config param pagedattn_num_pages: 64
Config param pagedattn_pages_per_compute_block: 4
Config param pagedattn_tokens_per_page: 32
Config param param_scan_axis: 1
Config param parameter_memory_host_offload: False
Config param patch_size_for_vit: 14
Config param per_device_batch_size: 1.0
Config param pipeline_delay_activation_forwarding: False
Config param pipeline_fsdp_ag_once: False
Config param pipeline_parallel_layers: -1
Config param pixel_shuffle_ratio_for_vit: 0.5
Config param prefill_cache_axis_order: 1,2,0,3
Config param prefill_cache_dir: 
Config param prefill_chunk_size: 256
Config param prefill_slice: v5e-16
Config param prefix_caching_dram_byte: 100000000000
Config param prefix_caching_hbm_byte: 10000000000
Config param profile_cleanly: True
Config param profile_periodically_period: -1
Config param profiler: 
Config param profiler_steps: 5
Config param projector_dropout_for_vit: 0.0
Config param projector_input_dim_for_vit: 4096
Config param projector_output_dim_for_vit: 4096
Config param prometheus_port: 0
Config param prompt: I love to
Config param q_lora_rank: 0
Config param qk_nope_head_dim: 128
Config param qk_rope_head_dim: 64
Config param qkv_proj: remat
Config param quant_cfg_path: 
Config param quantization: 
Config param quantization_local_shard_count: 1
Config param quantize_kvcache: False
Config param query_proj: remat
Config param ragged_block_size: 256
Config param record_internal_nn_metrics: 0
Config param remat_policy: full
Config param remat_policy_for_vit: minimal
Config param replicate_quant_scale: False
Config param replicator_backup_interval_minutes: 0
Config param report_heartbeat_metric_for_gcp_monitoring: False
Config param report_performance_metric_for_gcp_monitoring: False
Config param reshape_q: False
Config param return_log_prob: False
Config param reuse_example_batch: 0
Config param rope_factor: 40
Config param rope_max_timescale: 500000
Config param rope_min_timescale: 1
Config param rope_theta_for_vit: 10000
Config param rope_type: default
Config param rope_use_scale: True
Config param routed_bias: False
Config param routed_scaling_factor: 1.0
Config param routed_score_func: 
Config param run_name: runner_llama3.1_8b
Config param sa_block_kv: 512
Config param sa_block_kv_compute: 512
Config param sa_block_kv_dkv: 512
Config param sa_block_kv_dkv_compute: 512
Config param sa_block_kv_dq: 512
Config param sa_block_q: 512
Config param sa_block_q_dkv: 512
Config param sa_block_q_dq: 512
Config param sa_k_layout: HEAD_DIM_MINOR
Config param sa_q_layout: HEAD_DIM_MINOR
Config param sa_use_fused_bwd_kernel: False
Config param sa_v_layout: HEAD_DIM_MINOR
Config param save_config_to_gcs: False
Config param save_quantized_params_path: 
Config param scan_layers: True
Config param scan_layers_per_stage: False
Config param scan_pipeline_iterations: True
Config param set_remat_policy_on_layers_per_stage: False
Config param set_remat_policy_on_pipeline_iterations: True
Config param sft_train_on_completion_only: False
Config param sharding_tolerance: 0.02
Config param shared_experts: 1
Config param skip_first_n_steps_for_profiler: 1
Config param skip_jax_distributed_system: False
Config param sliding_window_size: 0
Config param sparse_matmul: True
Config param stack_prefill_result_cache: False
Config param stack_trace_interval_seconds: 600
Config param stack_trace_to_cloud: False
Config param step_deviation_interval_seconds: 30
Config param steps: 50
Config param subslice_shape: 
Config param target_eval_loss: 0.0
Config param temperature_tuning: False
Config param tensorboard_dir: /gcs-dir/maxtext-output/runner_llama3.1_8b/tensorboard/
Config param tile_activation_dim: 1024
Config param tile_batch_seq: 512
Config param tile_size_for_vit: 336
Config param tile_weight_dim: 1024
Config param tokenize_eval_data: True
Config param tokenize_train_data: True
Config param tokenizer_path: assets/tokenizer_llama3.tiktoken
Config param tokenizer_type: tiktoken
Config param topk_routing_group: -1
Config param train_data_columns: ['text']
Config param train_split: train
Config param trainable_position_size: -1
Config param upload_all_profiler_results: False
Config param use_chat_template: False
Config param use_chunked_prefill: False
Config param use_dpo: False
Config param use_iota_embed: False
Config param use_multimodal: False
Config param use_post_attn_norm: False
Config param use_post_ffw_norm: False
Config param use_qk_norm: False
Config param use_ragged_attention: False
Config param use_random_routing: False
Config param use_replicator_service: False
Config param use_sft: False
Config param use_untrainable_positional_embedding: False
Config param use_vertex_tensorboard: False
Config param using_pipeline_parallelism: False
Config param v_head_dim: 128
Config param value_proj: remat
Config param vertex_tensorboard_project: 
Config param vertex_tensorboard_region: 
Config param vision_output_dim_for_vit: 4096
Config param vocab_size: 128256
Config param warmup_steps_fraction: 0.1
Config param weight_dtype: float32
System Information: Jax Version: 0.6.1
System Information: Jaxlib Version: 0.6.1
System Information: Jax Backend: PJRT C API
TFRT TPU v6 lite
Built on May 15 2025 08:22:47 (1747322567) cl/759148519
WARNING: 'dataset_path' might be pointing your local file system
WARNING: 'base_output_directory' might be pointing your local file system
Num_devices: 16, shape (1, 1, 16, 1, 1, 1, 1, 1, 1, 1, 1, 1)
I0913 01:11:26.274639     141 autofdo_agent.cc:203] xla_tpu_autofdo_profile_dir updated to 
W0913 01:11:26.274657     141 autofdo_agent.cc:206] xla_tpu_autofdo_use_remote_repo is overridden to false because xla_tpu_autofdo_profile_dir is not set.
I0913 01:11:26.277189     141 2a886c8_compiler_base.cc:7068] HLO_PASSES stage duration: 3.8875975ms
I0913 01:11:26.302821    1435 memory_space_assignment_util.cc:632] MSA Vmem breakdown: default scoped vmem (from flag): 33554432; does_msa_directly_allocate_scoped_vmem: F; bytes_for_msa_to_allocate: 100663296
I0913 01:11:26.306251     532 2a886c8_compiler_base.cc:10004] BACKEND_PASSES stage duration: 4.12710675ms
I0913 01:11:26.310117     532 2a886c8_compiler_base.cc:3644] CODE_GENERATION stage duration: 3.83468775ms
I0913 01:11:26.310173     532 isa_program_util_common.cc:486] (HLO module jit_convert_element_type): Executable fingerprint:70c9ba63bbb4f0ab4683501f9fae65f10d3935a066915cf01bc1104116c83913
I0913 01:11:26.310179     532 isa_program_util_common.cc:490] (HLO module jit_convert_element_type): Executable fingerprint (including data segments):7204f387665061bd2ee0accce392d62ae0a05c9c49f78c36ffb00f7ddf50acf0
I0913 01:11:26.310181     532 isa_program_util_common.cc:493] (HLO module jit_convert_element_type): Host transfer fingerprint:e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855
I0913 01:11:26.310248     141 2a886c8_compiler_base.cc:7452] END_TO_END stage duration: 37.0013715ms
I0913 01:11:26.324664     141 2a886c8_compiler_base.cc:6877] XLA::TPU running hlo passes for 8 instructions, modules: jit__threefry_seed
I0913 01:11:26.324681     141 2a886c8_compiler_base.cc:6934] Initial HLO module: jit__threefry_seed instructions: 8 fingerprint: 
I0913 01:11:26.324798     141 2a886c8_compiler_base.cc:6997] HLO optimizing module: jit__threefry_seed instructions: 8
I0913 01:11:26.324804     141 2a886c8_compiler_base.cc:7012] XLA::TPU HLO optimization
I0913 01:11:26.326555     141 2a886c8_compiler_base.cc:6063] XLA::TPU HLO PostOptimizationPipeline
I0913 01:11:26.327075     141 2a886c8_compiler_base.cc:7068] HLO_PASSES stage duration: 3.2678595ms
I0913 01:11:26.327484    1436 memory_space_assignment_util.cc:632] MSA Vmem breakdown: default scoped vmem (from flag): 33554432; does_msa_directly_allocate_scoped_vmem: F; bytes_for_msa_to_allocate: 100663296
I0913 01:11:26.331451     532 2a886c8_compiler_base.cc:10004] BACKEND_PASSES stage duration: 4.092077ms
I0913 01:11:26.331961     532 2a886c8_compiler_base.cc:3124] final program bundle count: 151 note this count does not reflect cycles spent executing delays.
I0913 01:11:26.334046     532 2a886c8_compiler_base.cc:3124] final program bundle count: 147 note this count does not reflect cycles spent executing delays.
I0913 01:11:26.334698     532 2a886c8_compiler_base.cc:3356] Program divided into 2 overlays without HLO functions (35.5K).
I0913 01:11:26.334874     532 2a886c8_compiler_base.cc:3535] XLA::TPU module name: jit__threefry_seed
I0913 01:11:26.334891     532 2a886c8_compiler_base.cc:3537] XLA::TPU program HBM usage: 35.5K / 31.25G
I0913 01:11:26.334894     532 2a886c8_compiler_base.cc:3587] XLA::TPU program VMEM usage: 4.0K / 128.00M
I0913 01:11:26.334901     532 2a886c8_compiler_base.cc:3598] Total hbm usage >= 260.04M:
I0913 01:11:26.334903     532 2a886c8_compiler_base.cc:3598]     reserved        260.01M 
I0913 01:11:26.334904     532 2a886c8_compiler_base.cc:3598]     program           35.5K 
I0913 01:11:26.334905     532 2a886c8_compiler_base.cc:3598]     arguments          512B 
I0913 01:11:26.334907     532 2a886c8_compiler_base.cc:3598] 
I0913 01:11:26.334908     532 2a886c8_compiler_base.cc:3598] Output size 512B; shares 0B with arguments.
I0913 01:11:26.334909     532 2a886c8_compiler_base.cc:3598] 
I0913 01:11:26.334915     532 2a886c8_compiler_base.cc:3602] Program sflag requirement 216B:
I0913 01:11:26.334917     532 2a886c8_compiler_base.cc:3602]     reserved           204B
I0913 01:11:26.334918     532 2a886c8_compiler_base.cc:3602]     scoped              12B
I0913 01:11:26.334920     532 2a886c8_compiler_base.cc:3602] Program vmem requirement 4.0K:
I0913 01:11:26.334921     532 2a886c8_compiler_base.cc:3602]     scoped             4.0K
I0913 01:11:26.334922     532 2a886c8_compiler_base.cc:3602] Program smem requirement 32B:
I0913 01:11:26.334923     532 2a886c8_compiler_base.cc:3602]     scoped              32B
I0913 01:11:26.334925     532 2a886c8_compiler_base.cc:3602] Program hbm requirement 35.5K:
I0913 01:11:26.334926     532 2a886c8_compiler_base.cc:3602]     overlays          35.5K
I0913 01:11:26.334927     532 2a886c8_compiler_base.cc:3610] XLA::TPU program SMEM usage: 1.9K / 1.00M (1 parameters)
I0913 01:11:26.334935     532 2a886c8_compiler_base.cc:3644] CODE_GENERATION stage duration: 3.455019ms
I0913 01:11:26.334996     532 isa_program_util_common.cc:486] (HLO module jit__threefry_seed): Executable fingerprint:f4ffc227e695c8b8c874ae7cb2c0a96e875763d4caf2f548d4c3eeded212f966
I0913 01:11:26.335000     532 isa_program_util_common.cc:490] (HLO module jit__threefry_seed): Executable fingerprint (including data segments):8fd846ece719e7362d1ffad2635176377df42c57ea9e3cb59373829aed4ae154
I0913 01:11:26.335002     532 isa_program_util_common.cc:493] (HLO module jit__threefry_seed): Host transfer fingerprint:e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855
I0913 01:11:26.335190     141 2a886c8_compiler_base.cc:7452] END_TO_END stage duration: 11.4264335ms
I0913 01:11:26.347303     141 2a886c8_compiler_base.cc:7068] HLO_PASSES stage duration: 2.6513015ms
I0913 01:11:26.347665    1435 memory_space_assignment_util.cc:632] MSA Vmem breakdown: default scoped vmem (from flag): 33554432; does_msa_directly_allocate_scoped_vmem: F; bytes_for_msa_to_allocate: 100663296
I0913 01:11:26.350638     532 2a886c8_compiler_base.cc:10004] BACKEND_PASSES stage duration: 3.05541025ms
I0913 01:11:26.353892     532 2a886c8_compiler_base.cc:3644] CODE_GENERATION stage duration: 3.22926975ms
I0913 01:11:26.353951     532 isa_program_util_common.cc:486] (HLO module jit_concatenate): Executable fingerprint:9ccc5da64a50a8db9bc97ba43becf74b767538eb7cc4d2645d3099e765a06103
I0913 01:11:26.353956     532 isa_program_util_common.cc:490] (HLO module jit_concatenate): Executable fingerprint (including data segments):d47bb6f447ed82ab7d602ace81f403951ebeeb16b2cee5c026ef7f295867af48
I0913 01:11:26.353958     532 isa_program_util_common.cc:493] (HLO module jit_concatenate): Host transfer fingerprint:e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855
I0913 01:11:26.354101     141 2a886c8_compiler_base.cc:7452] END_TO_END stage duration: 9.48011975ms
Setting up checkpoint logger...
Creating checkpoint manager with ocdbt=True and zarr3=True
I0913 01:11:26.460271 140416767584064 base_pytree_checkpoint_handler.py:334] Created BasePyTreeCheckpointHandler: use_ocdbt=True, use_zarr3=True, pytree_metadata_options=PyTreeMetadataOptions(support_rich_types=False), array_metadata_store=<orbax.checkpoint._src.metadata.array_metadata_store.Store object at 0x7fb4a01aad40>
I0913 01:11:26.460513 140416767584064 checkpoint_manager.py:620] [process=0][thread=MainThread] CheckpointManager init: checkpointers=None, item_names=('items',), item_handlers={'items': <orbax.checkpoint._src.handlers.pytree_checkpoint_handler.PyTreeCheckpointHandler object at 0x7fa144102500>}, handler_registry=None
I0913 01:11:26.460896 140416767584064 composite_checkpoint_handler.py:234] Deferred registration for item: "items". Adding handler `<orbax.checkpoint._src.handlers.pytree_checkpoint_handler.PyTreeCheckpointHandler object at 0x7fa144102500>` for item "items" and save args `<class 'orbax.checkpoint._src.handlers.pytree_checkpoint_handler.PyTreeSaveArgs'>` and restore args `<class 'orbax.checkpoint._src.handlers.pytree_checkpoint_handler.PyTreeRestoreArgs'>` to `_handler_registry`.
I0913 01:11:26.460951 140416767584064 composite_checkpoint_handler.py:234] Deferred registration for item: "metrics". Adding handler `<orbax.checkpoint._src.handlers.json_checkpoint_handler.JsonCheckpointHandler object at 0x7fa144102c20>` for item "metrics" and save args `<class 'orbax.checkpoint._src.handlers.json_checkpoint_handler.JsonSaveArgs'>` and restore args `<class 'orbax.checkpoint._src.handlers.json_checkpoint_handler.JsonRestoreArgs'>` to `_handler_registry`.
I0913 01:11:26.461014 140416767584064 composite_checkpoint_handler.py:502] Initialized registry DefaultCheckpointHandlerRegistry({('items', <class 'orbax.checkpoint._src.handlers.pytree_checkpoint_handler.PyTreeSaveArgs'>): <orbax.checkpoint._src.handlers.pytree_checkpoint_handler.PyTreeCheckpointHandler object at 0x7fa144102500>, ('items', <class 'orbax.checkpoint._src.handlers.pytree_checkpoint_handler.PyTreeRestoreArgs'>): <orbax.checkpoint._src.handlers.pytree_checkpoint_handler.PyTreeCheckpointHandler object at 0x7fa144102500>, ('metrics', <class 'orbax.checkpoint._src.handlers.json_checkpoint_handler.JsonSaveArgs'>): <orbax.checkpoint._src.handlers.json_checkpoint_handler.JsonCheckpointHandler object at 0x7fa144102c20>, ('metrics', <class 'orbax.checkpoint._src.handlers.json_checkpoint_handler.JsonRestoreArgs'>): <orbax.checkpoint._src.handlers.json_checkpoint_handler.JsonCheckpointHandler object at 0x7fa144102c20>}).
I0913 01:11:26.461327 140416767584064 abstract_checkpointer.py:35] orbax-checkpoint version: 0.11.13
I0913 01:11:26.461403 140416767584064 async_checkpointer.py:170] [process=0][thread=MainThread] Using barrier_sync_fn: <function get_barrier_sync_fn.<locals>._fn at 0x7fa1440e9510> timeout: 600 secs and primary_host=0 for async checkpoint writes
W0913 01:11:26.473358     532 tpu_spmd_partitioner_util.cc:151] GSPMD sharding propagation is going to be deprecated and not supported in the future. Please migrate to go/shardy and reach out on go/shardy-friends-chat for any questions. JAX users can enable it via `jax.config.update('jax_use_shardy_partitioner', True)`.
I0913 01:11:26.475551     141 2a886c8_compiler_base.cc:7068] HLO_PASSES stage duration: 3.52967875ms
I0913 01:11:26.476021    1436 memory_space_assignment_util.cc:632] MSA Vmem breakdown: default scoped vmem (from flag): 33554432; does_msa_directly_allocate_scoped_vmem: F; bytes_for_msa_to_allocate: 100663296
I0913 01:11:26.476372    1436 enhanced_barrier_util.cc:755] Using enhanced global barrier with 16 cores and 16 partitions
I0913 01:11:26.483105     532 2a886c8_compiler_base.cc:10004] BACKEND_PASSES stage duration: 7.23273675ms
I0913 01:11:26.487335     532 2a886c8_compiler_base.cc:3644] CODE_GENERATION stage duration: 4.1945265ms
I0913 01:11:26.487425     532 isa_program_util_common.cc:486] (HLO module jit__psum): Executable fingerprint:9869f7f66cdc40fbf3c453db98ce5731c3488a2cfe25b41cf1da22afb58a6881
I0913 01:11:26.487430     532 isa_program_util_common.cc:490] (HLO module jit__psum): Executable fingerprint (including data segments):92809b63bc99a6bbb68681e3cb2d8fe6407d2fcf03abd4019f4b4e7f664a77b6
I0913 01:11:26.487432     532 isa_program_util_common.cc:493] (HLO module jit__psum): Host transfer fingerprint:e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855
I0913 01:11:26.487808     141 2a886c8_compiler_base.cc:7452] END_TO_END stage duration: 15.84942925ms
I0913 01:11:26.555275 140416767584064 checkpoint_manager.py:1701] Found 0 checkpoint steps in /gcs-dir/maxtext-output/runner_llama3.1_8b/checkpoints
Checkpoint manager created!
I0913 01:11:26.558554 140416767584064 checkpoint_manager.py:801] [process=0][thread=MainThread] CheckpointManager created,  primary_host=0, CheckpointManagerOptions=CheckpointManagerOptions(save_interval_steps=10, max_to_keep=None, keep_time_interval=None, keep_period=None, should_keep_fn=None, best_fn=None, best_mode='max', keep_checkpoints_without_metrics=True, step_prefix=None, step_format_fixed_length=None, step_name_format=None, create=True, cleanup_tmp_directories=False, save_on_steps=frozenset(), single_host_load_and_broadcast=False, todelete_subdir=None, enable_background_delete=False, read_only=False, enable_async_checkpointing=True, async_options=None, multiprocessing_options=MultiprocessingOptions(primary_host=0, active_processes=None, barrier_sync_key_prefix=None), should_save_fn=None, file_options=FileOptions(path_permission_mode=None), save_root_metadata=True, temporary_path_class=None, save_decision_policy=None, prevent_write_metrics=False), root_directory=/gcs-dir/maxtext-output/runner_llama3.1_8b/checkpoints: <orbax.checkpoint.checkpoint_manager.CheckpointManager object at 0x7fa144102800>
I0913 01:11:26.807603 140416767584064 dataset_info.py:690] Load dataset info from /gcs-dir/c4/en/3.0.1
I0913 01:11:27.133056 140416767584064 dataset_info.py:780] For 'c4/en/3.0.1': fields info.[splits] differ on disk and in the code. Keeping the one from code.
I0913 01:11:27.147277 140416767584064 reader.py:261] Creating a tf.data.Dataset reading 1024 files located in folders: /gcs-dir/c4/en/3.0.1.
I0913 01:11:27.218739 140416767584064 logging_logger.py:49] Constructing tf.data.Dataset c4 for split train, from /gcs-dir/c4/en/3.0.1
Tokenizer path: assets/tokenizer_llama3.tiktoken
Reloaded tiktoken model from assets/tokenizer_llama3.tiktoken
#words: 128256 - BOS ID: 128000 - EOS ID: 128001
checkpoint manager exists so trying to load this run's existing checkpoint
restoring params from /gcs-dir/llama3.1-8b-it-maxtext/0/items
Creating checkpoint manager with ocdbt=True and zarr3=True
I0913 01:11:28.531749 140416767584064 base_pytree_checkpoint_handler.py:334] Created BasePyTreeCheckpointHandler: use_ocdbt=True, use_zarr3=True, pytree_metadata_options=PyTreeMetadataOptions(support_rich_types=False), array_metadata_store=<orbax.checkpoint._src.metadata.array_metadata_store.Store object at 0x7fb4a01aad40>
I0913 01:11:28.613662 140416767584064 checkpointer.py:298] Restoring checkpoint from /gcs-dir/llama3.1-8b-it-maxtext/0/items.
W0913 01:11:32.741011 140416767584064 transform_utils.py:230] The transformations API will eventually be replaced by an upgraded design. The current API will not be removed until this point, but it will no longer be actively worked on.
I0913 01:11:36.480235 140416767584064 checkpointer.py:309] Finished restoring checkpoint in 7.95 seconds from /gcs-dir/llama3.1-8b-it-maxtext/0/items.
I0913 01:11:36.755669     141 2a886c8_compiler_base.cc:6877] XLA::TPU running hlo passes for 1,842 instructions, modules: jit_initialize_state
I0913 01:11:36.755707     141 2a886c8_compiler_base.cc:6934] Initial HLO module: jit_initialize_state instructions: 1,842 fingerprint: 
I0913 01:11:36.767709     141 2a886c8_compiler_base.cc:6997] HLO optimizing module: jit_initialize_state instructions: 1,652
I0913 01:11:36.767749     141 2a886c8_compiler_base.cc:7012] XLA::TPU HLO optimization
W0913 01:11:36.868442     532 tpu_spmd_partitioner_util.cc:151] GSPMD sharding propagation is going to be deprecated and not supported in the future. Please migrate to go/shardy and reach out on go/shardy-friends-chat for any questions. JAX users can enable it via `jax.config.update('jax_use_shardy_partitioner', True)`.
I0913 01:11:37.357026     141 2a886c8_compiler_base.cc:6063] XLA::TPU HLO PostOptimizationPipeline
I0913 01:11:37.392851     141 2a886c8_compiler_base.cc:7068] HLO_PASSES stage duration: 638.09348725ms
I0913 01:11:37.399226    1435 memory_space_assignment_util.cc:632] MSA Vmem breakdown: default scoped vmem (from flag): 33554432; does_msa_directly_allocate_scoped_vmem: F; bytes_for_msa_to_allocate: 100663296
I0913 01:11:37.424414    1435 enhanced_barrier_util.cc:755] Using enhanced global barrier with 16 cores and 16 partitions
I0913 01:11:39.675345     532 2a886c8_compiler_base.cc:10004] BACKEND_PASSES stage duration: 2.27647453225s
I0913 01:11:39.794802     532 2a886c8_compiler_base.cc:3124] final program bundle count: 86,652 note this count does not reflect cycles spent executing delays.
I0913 01:11:39.798901     532 2a886c8_compiler_base.cc:3124] final program bundle count: 147 note this count does not reflect cycles spent executing delays.
I0913 01:11:39.851111     532 2a886c8_compiler_base.cc:3356] Program divided into 5 overlays without HLO functions (5.32M).
I0913 01:11:39.888388     532 2a886c8_compiler_base.cc:3535] XLA::TPU module name: jit_initialize_state
I0913 01:11:39.888407     532 2a886c8_compiler_base.cc:3537] XLA::TPU program HBM usage: 5.47M / 31.25G
I0913 01:11:39.888412     532 2a886c8_compiler_base.cc:3587] XLA::TPU program VMEM usage: 57.53M / 128.00M
I0913 01:11:39.888420     532 2a886c8_compiler_base.cc:3598] Total hbm usage >= 265.48M:
I0913 01:11:39.888422     532 2a886c8_compiler_base.cc:3598]     reserved        260.01M 
I0913 01:11:39.888423     532 2a886c8_compiler_base.cc:3598]     program           5.47M 
I0913 01:11:39.888424     532 2a886c8_compiler_base.cc:3598]     arguments          512B 
I0913 01:11:39.888426     532 2a886c8_compiler_base.cc:3598] 
I0913 01:11:39.888427     532 2a886c8_compiler_base.cc:3598] Output size 5.61G; shares 0B with arguments.
I0913 01:11:39.888428     532 2a886c8_compiler_base.cc:3598] 
I0913 01:11:39.888438     532 2a886c8_compiler_base.cc:3602] Program sflag requirement 264B:
I0913 01:11:39.888439     532 2a886c8_compiler_base.cc:3602]     reserved           204B
I0913 01:11:39.888441     532 2a886c8_compiler_base.cc:3602]     scoped              52B
I0913 01:11:39.888442     532 2a886c8_compiler_base.cc:3602]     HLO temp             8B (100.0% utilization: Unpadded (8B) Padded (8B), 0.0% fragmentation (0B))
I0913 01:11:39.888443     532 2a886c8_compiler_base.cc:3602] Program vmem requirement 57.53M:
I0913 01:11:39.888444     532 2a886c8_compiler_base.cc:3602]     scoped           29.50M
I0913 01:11:39.888446     532 2a886c8_compiler_base.cc:3602]     HLO temp         28.03M (0.0% utilization: Unpadded (0B) Padded (0B), 100.0% fragmentation (28.03M))
I0913 01:11:39.888447     532 2a886c8_compiler_base.cc:3602] Program hbm requirement 5.47M:
I0913 01:11:39.888448     532 2a886c8_compiler_base.cc:3602]     global           160.5K
I0913 01:11:39.888450     532 2a886c8_compiler_base.cc:3602]     overlays          5.32M
I0913 01:11:39.888451     532 2a886c8_compiler_base.cc:3602] Program smem requirement 436B:
I0913 01:11:39.888452     532 2a886c8_compiler_base.cc:3602]     scoped             436B
I0913 01:11:39.888453     532 2a886c8_compiler_base.cc:3610] XLA::TPU program SMEM usage: 2.3K / 1.00M (1 parameters)
I0913 01:11:39.888466     532 2a886c8_compiler_base.cc:3644] CODE_GENERATION stage duration: 213.045848ms
I0913 01:11:39.892392     532 isa_program_util_common.cc:486] (HLO module jit_initialize_state): Executable fingerprint:0dd2b0f316670bae27c9996444178700ee68c7e0b2b6087a218f5e21ce9921ef
I0913 01:11:39.892400     532 isa_program_util_common.cc:490] (HLO module jit_initialize_state): Executable fingerprint (including data segments):974bae5537b29bf76ff51504223bf4767d379e8385ffe82ac97f2ae0d889cdce
I0913 01:11:39.892402     532 isa_program_util_common.cc:493] (HLO module jit_initialize_state): Host transfer fingerprint:e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855
I0913 01:11:39.954637     141 2a886c8_compiler_base.cc:7452] END_TO_END stage duration: 3.2016972405s
I0913 01:11:39.959601     141 tfrt_tpu_pjrt_compiler.cc:394] Source URI is : googlefile:/google_src/files/759148519/depot/branches/libtpu_lts_release_branch/758471328.2/OVERLAY_READONLY/g3     
I0913 01:11:40.928062     141 2a886c8_compiler_base.cc:6877] XLA::TPU running hlo passes for 2,405 instructions, modules: jit_train_step
I0913 01:11:40.928090     141 2a886c8_compiler_base.cc:6934] Initial HLO module: jit_train_step instructions: 2,405 fingerprint: 
I0913 01:11:40.936289     141 2a886c8_compiler_base.cc:6997] HLO optimizing module: jit_train_step instructions: 1,813
I0913 01:11:40.936328     141 2a886c8_compiler_base.cc:7012] XLA::TPU HLO optimization
W0913 01:11:41.043018     532 tpu_spmd_partitioner_util.cc:151] GSPMD sharding propagation is going to be deprecated and not supported in the future. Please migrate to go/shardy and reach out on go/shardy-friends-chat for any questions. JAX users can enable it via `jax.config.update('jax_use_shardy_partitioner', True)`.
I0913 01:11:41.265638     532 tpu_layout_assignment.cc:3499] Ran 3 additional passes of layout assignment to assign all layouts.
I0913 01:11:44.201512     141 2a886c8_compiler_base.cc:6063] XLA::TPU HLO PostOptimizationPipeline
I0913 01:11:44.306203     141 latency_hiding_scheduler.cc:3011] [latency-hiding-scheduler] LatencyHidingScheduler current memory usage: 4671560704 bytes. Current limit: 25793408716
W0913 01:11:44.359085     141 barrier_assignment.cc:1110] Number of unique slow barriers: 1
W0913 01:11:44.359113     141 barrier_assignment.cc:1112] Number of times slow barrier appeared: 2
I0913 01:11:44.365714     141 2a886c8_compiler_base.cc:7068] HLO_PASSES stage duration: 3.43857293225s
I0913 01:11:44.383591    5211 memory_space_assignment_util.cc:632] MSA Vmem breakdown: default scoped vmem (from flag): 33554432; does_msa_directly_allocate_scoped_vmem: F; bytes_for_msa_to_allocate: 100663296
I0913 01:11:44.512776    5211 enhanced_barrier_util.cc:755] Using enhanced global barrier with 16 cores and 16 partitions
W0913 01:11:45.618569   25508 lowering_emitter.cc:4621] Successful retry compilation of multiply_reduce_fusion.7 = (f32[]{:T(128)}, f32[256,32,32,128]{3,2,1,0:T(8,128)}, f32[256,32,32,128]{3,2,1,0:T(8,128)}, f32[256,32,32,128]{3,2,1,0:T(8,128)}, f32[]{:T(128)}) fusion(param.48, subtract.88, subtract.87, multiply.466, param.73, sqrt.0, get-tuple-element.557, compare.214, param.72), kind=kLoop, calls=
{
  param_0.1985 = f32[256,32,32,128]{3,2,1,0:T(8,128)} parameter(0)
  param_3.1368 = f32[]{:T(128)S(6)} parameter(3)
  broadcast.2604.clone.1 = f32[256,32,32,128]{3,2,1,0:T(8,128)} broadcast(param_3.1368), dimensions={}
  param_7.261 = pred[]{:T(512)S(6)} parameter(7)
  broadcast.2612.clone.1 = pred[256,32,32,128]{3,2,1,0:T(8,128)(4,1)} broadcast(param_7.261), dimensions={}
  param_6.365 = f32[32,256,32,128]{3,2,0,1:T(8,128)} parameter(6)
  bitcast.1258.clone.1 = f32[256,32,32,128]{3,2,1,0:T(8,128)} bitcast(param_6.365)
  param_5.651 = f32[]{:T(128)} parameter(5)
  broadcast.2611.clone.1 = f32[256,32,32,128]{3,2,1,0:T(8,128)} broadcast(param_5.651), dimensions={}
  divide.405.clone.1 = f32[256,32,32,128]{3,2,1,0:T(8,128)} divide(bitcast.1258.clone.1, broadcast.2611.clone.1)
  select.373.clone.1 = f32[256,32,32,128]{3,2,1,0:T(8,128)} select(broadcast.2612.clone.1, bitcast.1258.clone.1, divide.405.clone.1)
  constant.3412.clone.1 = f32[]{:T(128)} constant(0.1)
  broadcast.2610.clone.1 = f32[256,32,32,128]{3,2,1,0:T(8,128)} broadcast(constant.3412.clone.1), dimensions={}
  multiply.1546.clone.1 = f32[256,32,32,128]{3,2,1,0:T(8,128)} multiply(select.373.clone.1, broadcast.2610.clone.1)
  param_8.176 = f32[256,32,32,128]{3,2,1,0:T(8,128)} parameter(8)
  constant.3416.clone.1 = f32[]{:T(128)} constant(0.9)
  broadcast.2609.clone.1 = f32[256,32,32,128]{3,2,1,0:T(8,128)} broadcast(constant.3416.clone.1), dimensions={}
  multiply.1545.clone.1 = f32[256,32,32,128]{3,2,1,0:T(8,128)} multiply(param_8.176, broadcast.2609.clone.1)
  add.1254.clone.1 = f32[256,32,32,128]{3,2,1,0:T(8,128)} add(multiply.1546.clone.1, multiply.1545.clone.1)
  param_2.1773 = f32[]{:T(128)S(6)} parameter(2)
  broadcast.2602.clone.1 = f32[256,32,32,128]{3,2,1,0:T(8,128)} broadcast(param_2.1773), dimensions={}
  multiply.1544.clone.1 = f32[256,32,32,128]{3,2,1,0:T(8,128)} multiply(select.373.clone.1, select.373.clone.1)
  constant.3415.clone.1 = f32[]{:T(128)} constant(0.05)
  broadcast.2606.clone.1 = f32[256,32,32,128]{3,2,1,0:T(8,128)} broadcast(constant.3415.clone.1), dimensions={}
  multiply.1543.clone.1 = f32[256,32,32,128]{3,2,1,0:T(8,128)} multiply(multiply.1544.clone.1, broadcast.2606.clone.1)
  param_4.889 = f32[256,32,32,128]{3,2,1,0:T(8,128)} parameter(4)
  constant.3414.clone.1 = f32[]{:T(128)} constant(0.95)
  broadcast.2605.clone.1 = f32[256,32,32,128]{3,2,1,0:T(8,128)} broadcast(constant.3414.clone.1), dimensions={}
  multiply.1542.clone.1 = f32[256,32,32,128]{3,2,1,0:T(8,128)} multiply(param_4.889, broadcast.2605.clone.1)
  add.1253.clone.1 = f32[256,32,32,128]{3,2,1,0:T(8,128)} add(multiply.1543.clone.1, multiply.1542.clone.1)
  param_1.2318 = f32[]{:T(128)S(6)} parameter(1)
  broadcast.2601.clone.1 = f32[256,32,32,128]{3,2,1,0:T(8,128)} broadcast(param_1.2318), dimensions={}
  divide.403.clone.1 = f32[256,32,32,128]{3,2,1,0:T(8,128)} divide(add.1253.clone.1, broadcast.2601.clone.1)
  sqrt.33.clone.1 = f32[256,32,32,128]{3,2,1,0:T(8,128)} sqrt(divide.403.clone.1)
  constant.3413.clone.1 = f32[]{:T(128)} constant(1e-08)
  broadcast.2600.clone.1 = f32[256,32,32,128]{3,2,1,0:T(8,128)} broadcast(constant.3413.clone.1), dimensions={}
  add.1252.clone.1 = f32[256,32,32,128]{3,2,1,0:T(8,128)} add(sqrt.33.clone.1, broadcast.2600.clone.1)
  multiply.1541.clone.1 = f32[256,32,32,128]{3,2,1,0:T(8,128)} multiply(broadcast.2602.clone.1, add.1252.clone.1)
  divide.402.clone.1 = f32[256,32,32,128]{3,2,1,0:T(8,128)} divide(add.1254.clone.1, multiply.1541.clone.1)
  multiply.1540.clone.1 = f32[256,32,32,128]{3,2,1,0:T(8,128)} multiply(param_0.1985, broadcast.2610.clone.1)
  add.1251.clone.1 = f32[256,32,32,128]{3,2,1,0:T(8,128)} add(divide.402.clone.1, multiply.1540.clone.1)
  multiply.1539.clone.1 = f32[256,32,32,128]{3,2,1,0:T(8,128)} multiply(broadcast.2604.clone.1, add.1251.clone.1)
  add.1250.clone.1 = f32[256,32,32,128]{3,2,1,0:T(8,128)} add(param_0.1985, multiply.1539.clone.1)
  multiply.1292 = f32[256,32,32,128]{3,2,1,0:T(8,128)} multiply(add.1250.clone.1, add.1250.clone.1)
  constant.3457 = f32[]{:T(128)} constant(0)
  reduce.143 = f32[]{:T(128)} reduce(multiply.1292, constant.3457), dimensions={0,1,2,3}, to_apply=
  {
    Arg_0.2439 = f32[]{:T(128)} parameter(0)
    Arg_1.2440 = f32[]{:T(128)} parameter(1)
    ROOT add.2441 = f32[]{:T(128)} add(Arg_0.2439, Arg_1.2440)
  }
  reduce.149.clone.1 = f32[]{:T(128)} reduce(multiply.1544.clone.1, constant.3457), dimensions={0,1,2,3}, to_apply=
  {
    Arg_0.2271 = f32[]{:T(128)} parameter(0)
    Arg_1.2272 = f32[]{:T(128)} parameter(1)
    ROOT add.2273 = f32[]{:T(128)} add(Arg_0.2271, Arg_1.2272)
  }
  ROOT tuple.358 = (f32[]{:T(128)}, f32[256,32,32,128]{3,2,1,0:T(8,128)}, f32[256,32,32,128]{3,2,1,0:T(8,128)}, f32[256,32,32,128]{3,2,1,0:T(8,128)}, f32[]{:T(128)}) tuple(reduce.143, add.1250.clone.1, add.1253.clone.1, add.1254.clone.1, reduce.149.clone.1)
} after 1 retry
W0913 01:11:45.651125   25510 lowering_emitter.cc:4621] Successful retry compilation of multiply_reduce_fusion.8 = (f32[]{:T(128)}, f32[32,32,128,256]{3,2,1,0:T(8,128)}, f32[32,32,128,256]{3,2,1,0:T(8,128)}, f32[32,32,128,256]{3,2,1,0:T(8,128)}, f32[]{:T(128)}) fusion(param.47, subtract.88, subtract.87, multiply.466, param.71, sqrt.0, get-tuple-element.556, compare.214, param.70), kind=kLoop, calls=
{
  param_0.1986 = f32[32,32,128,256]{3,2,1,0:T(8,128)} parameter(0)
  param_3.1369 = f32[]{:T(128)S(6)} parameter(3)
  broadcast.2617.clone.1 = f32[32,32,128,256]{3,2,1,0:T(8,128)} broadcast(param_3.1369), dimensions={}
  param_7.262 = pred[]{:T(512)S(6)} parameter(7)
  broadcast.2625.clone.1 = pred[32,32,128,256]{3,2,1,0:T(8,128)(4,1)} broadcast(param_7.262), dimensions={}
  param_6.366 = f32[32,32,128,256]{3,2,0,1:T(8,128)} parameter(6)
  bitcast.1260.clone.1 = f32[32,32,128,256]{3,2,1,0:T(8,128)} bitcast(param_6.366)
  param_5.652 = f32[]{:T(128)} parameter(5)
  broadcast.2624.clone.1 = f32[32,32,128,256]{3,2,1,0:T(8,128)} broadcast(param_5.652), dimensions={}
  divide.409.clone.1 = f32[32,32,128,256]{3,2,1,0:T(8,128)} divide(bitcast.1260.clone.1, broadcast.2624.clone.1)
  select.375.clone.1 = f32[32,32,128,256]{3,2,1,0:T(8,128)} select(broadcast.2625.clone.1, bitcast.1260.clone.1, divide.409.clone.1)
  constant.3418.clone.1 = f32[]{:T(128)} constant(0.1)
  broadcast.2623.clone.1 = f32[32,32,128,256]{3,2,1,0:T(8,128)} broadcast(constant.3418.clone.1), dimensions={}
  multiply.1554.clone.1 = f32[32,32,128,256]{3,2,1,0:T(8,128)} multiply(select.375.clone.1, broadcast.2623.clone.1)
  param_8.177 = f32[32,32,128,256]{3,2,1,0:T(8,128)} parameter(8)
  constant.3422.clone.1 = f32[]{:T(128)} constant(0.9)
  broadcast.2622.clone.1 = f32[32,32,128,256]{3,2,1,0:T(8,128)} broadcast(constant.3422.clone.1), dimensions={}
  multiply.1553.clone.1 = f32[32,32,128,256]{3,2,1,0:T(8,128)} multiply(param_8.177, broadcast.2622.clone.1)
  add.1259.clone.1 = f32[32,32,128,256]{3,2,1,0:T(8,128)} add(multiply.1554.clone.1, multiply.1553.clone.1)
  param_2.1774 = f32[]{:T(128)S(6)} parameter(2)
  broadcast.2615.clone.1 = f32[32,32,128,256]{3,2,1,0:T(8,128)} broadcast(param_2.1774), dimensions={}
  multiply.1552.clone.1 = f32[32,32,128,256]{3,2,1,0:T(8,128)} multiply(select.375.clone.1, select.375.clone.1)
  constant.3421.clone.1 = f32[]{:T(128)} constant(0.05)
  broadcast.2619.clone.1 = f32[32,32,128,256]{3,2,1,0:T(8,128)} broadcast(constant.3421.clone.1), dimensions={}
  multiply.1551.clone.1 = f32[32,32,128,256]{3,2,1,0:T(8,128)} multiply(multiply.1552.clone.1, broadcast.2619.clone.1)
  param_4.890 = f32[32,32,128,256]{3,2,1,0:T(8,128)} parameter(4)
  constant.3420.clone.1 = f32[]{:T(128)} constant(0.95)
  broadcast.2618.clone.1 = f32[32,32,128,256]{3,2,1,0:T(8,128)} broadcast(constant.3420.clone.1), dimensions={}
  multiply.1550.clone.1 = f32[32,32,128,256]{3,2,1,0:T(8,128)} multiply(param_4.890, broadcast.2618.clone.1)
  add.1258.clone.1 = f32[32,32,128,256]{3,2,1,0:T(8,128)} add(multiply.1551.clone.1, multiply.1550.clone.1)
  param_1.2319 = f32[]{:T(128)S(6)} parameter(1)
  broadcast.2614.clone.1 = f32[32,32,128,256]{3,2,1,0:T(8,128)} broadcast(param_1.2319), dimensions={}
  divide.407.clone.1 = f32[32,32,128,256]{3,2,1,0:T(8,128)} divide(add.1258.clone.1, broadcast.2614.clone.1)
  sqrt.34.clone.1 = f32[32,32,128,256]{3,2,1,0:T(8,128)} sqrt(divide.407.clone.1)
  constant.3419.clone.1 = f32[]{:T(128)} constant(1e-08)
  broadcast.2613.clone.1 = f32[32,32,128,256]{3,2,1,0:T(8,128)} broadcast(constant.3419.clone.1), dimensions={}
  add.1257.clone.1 = f32[32,32,128,256]{3,2,1,0:T(8,128)} add(sqrt.34.clone.1, broadcast.2613.clone.1)
  multiply.1549.clone.1 = f32[32,32,128,256]{3,2,1,0:T(8,128)} multiply(broadcast.2615.clone.1, add.1257.clone.1)
  divide.406.clone.1 = f32[32,32,128,256]{3,2,1,0:T(8,128)} divide(add.1259.clone.1, multiply.1549.clone.1)
  multiply.1548.clone.1 = f32[32,32,128,256]{3,2,1,0:T(8,128)} multiply(param_0.1986, broadcast.2623.clone.1)
  add.1256.clone.1 = f32[32,32,128,256]{3,2,1,0:T(8,128)} add(divide.406.clone.1, multiply.1548.clone.1)
  multiply.1547.clone.1 = f32[32,32,128,256]{3,2,1,0:T(8,128)} multiply(broadcast.2617.clone.1, add.1256.clone.1)
  add.1255.clone.1 = f32[32,32,128,256]{3,2,1,0:T(8,128)} add(param_0.1986, multiply.1547.clone.1)
  multiply.1293 = f32[32,32,128,256]{3,2,1,0:T(8,128)} multiply(add.1255.clone.1, add.1255.clone.1)
  constant.3458 = f32[]{:T(128)} constant(0)
  reduce.144 = f32[]{:T(128)} reduce(multiply.1293, constant.3458), dimensions={0,1,2,3}, to_apply=
  {
    Arg_0.2432 = f32[]{:T(128)} parameter(0)
    Arg_1.2433 = f32[]{:T(128)} parameter(1)
    ROOT add.2434 = f32[]{:T(128)} add(Arg_0.2432, Arg_1.2433)
  }
  reduce.150.clone.1 = f32[]{:T(128)} reduce(multiply.1552.clone.1, constant.3458), dimensions={0,1,2,3}, to_apply=
  {
    Arg_0.2264 = f32[]{:T(128)} parameter(0)
    Arg_1.2265 = f32[]{:T(128)} parameter(1)
    ROOT add.2266 = f32[]{:T(128)} add(Arg_0.2264, Arg_1.2265)
  }
  ROOT tuple.359 = (f32[]{:T(128)}, f32[32,32,128,256]{3,2,1,0:T(8,128)}, f32[32,32,128,256]{3,2,1,0:T(8,128)}, f32[32,32,128,256]{3,2,1,0:T(8,128)}, f32[]{:T(128)}) tuple(reduce.144, add.1255.clone.1, add.1258.clone.1, add.1259.clone.1, reduce.150.clone.1)
} after 1 retry
W0913 01:11:45.655218   25514 lowering_emitter.cc:4621] Successful retry compilation of multiply_reduce_fusion.3 = (f32[]{:T(128)}, f32[256,32,14336]{2,1,0:T(8,128)}, f32[256,32,14336]{2,1,0:T(8,128)}, f32[256,32,14336]{2,1,0:T(8,128)}, f32[]{:T(128)}) fusion(param.41, subtract.88, subtract.87, multiply.466, param.59, sqrt.0, get-tuple-element.550, compare.214, param.58), kind=kLoop, calls=
{
  param_0.1992 = f32[256,32,14336]{2,1,0:T(8,128)} parameter(0)
  param_3.1375 = f32[]{:T(128)S(6)} parameter(3)
  broadcast.2669.clone.1 = f32[256,32,14336]{2,1,0:T(8,128)} broadcast(param_3.1375), dimensions={}
  param_7.268 = pred[]{:T(512)S(6)} parameter(7)
  broadcast.2677.clone.1 = pred[256,32,14336]{2,1,0:T(8,128)(4,1)} broadcast(param_7.268), dimensions={}
  param_6.372 = f32[32,256,14336]{2,0,1:T(8,128)} parameter(6)
  bitcast.1268.clone.1 = f32[256,32,14336]{2,1,0:T(8,128)} bitcast(param_6.372)
  param_5.658 = f32[]{:T(128)} parameter(5)
  broadcast.2676.clone.1 = f32[256,32,14336]{2,1,0:T(8,128)} broadcast(param_5.658), dimensions={}
  divide.425.clone.1 = f32[256,32,14336]{2,1,0:T(8,128)} divide(bitcast.1268.clone.1, broadcast.2676.clone.1)
  select.383.clone.1 = f32[256,32,14336]{2,1,0:T(8,128)} select(broadcast.2677.clone.1, bitcast.1268.clone.1, divide.425.clone.1)
  constant.3442.clone.1 = f32[]{:T(128)} constant(0.1)
  broadcast.2675.clone.1 = f32[256,32,14336]{2,1,0:T(8,128)} broadcast(constant.3442.clone.1), dimensions={}
  multiply.1589.clone.1 = f32[256,32,14336]{2,1,0:T(8,128)} multiply(select.383.clone.1, broadcast.2675.clone.1)
  param_8.183 = f32[256,32,14336]{2,1,0:T(8,128)} parameter(8)
  constant.3446.clone.1 = f32[]{:T(128)} constant(0.9)
  broadcast.2674.clone.1 = f32[256,32,14336]{2,1,0:T(8,128)} broadcast(constant.3446.clone.1), dimensions={}
  multiply.1588.clone.1 = f32[256,32,14336]{2,1,0:T(8,128)} multiply(param_8.183, broadcast.2674.clone.1)
  add.1280.clone.1 = f32[256,32,14336]{2,1,0:T(8,128)} add(multiply.1589.clone.1, multiply.1588.clone.1)
  param_2.1780 = f32[]{:T(128)S(6)} parameter(2)
  broadcast.2667.clone.1 = f32[256,32,14336]{2,1,0:T(8,128)} broadcast(param_2.1780), dimensions={}
  multiply.1587.clone.1 = f32[256,32,14336]{2,1,0:T(8,128)} multiply(select.383.clone.1, select.383.clone.1)
  constant.3445.clone.1 = f32[]{:T(128)} constant(0.05)
  broadcast.2671.clone.1 = f32[256,32,14336]{2,1,0:T(8,128)} broadcast(constant.3445.clone.1), dimensions={}
  multiply.1586.clone.1 = f32[256,32,14336]{2,1,0:T(8,128)} multiply(multiply.1587.clone.1, broadcast.2671.clone.1)
  param_4.896 = f32[256,32,14336]{2,1,0:T(8,128)} parameter(4)
  constant.3444.clone.1 = f32[]{:T(128)} constant(0.95)
  broadcast.2670.clone.1 = f32[256,32,14336]{2,1,0:T(8,128)} broadcast(constant.3444.clone.1), dimensions={}
  multiply.1584.clone.1 = f32[256,32,14336]{2,1,0:T(8,128)} multiply(param_4.896, broadcast.2670.clone.1)
  add.1279.clone.1 = f32[256,32,14336]{2,1,0:T(8,128)} add(multiply.1586.clone.1, multiply.1584.clone.1)
  param_1.2325 = f32[]{:T(128)S(6)} parameter(1)
  broadcast.2666.clone.1 = f32[256,32,14336]{2,1,0:T(8,128)} broadcast(param_1.2325), dimensions={}
  divide.423.clone.1 = f32[256,32,14336]{2,1,0:T(8,128)} divide(add.1279.clone.1, broadcast.2666.clone.1)
  sqrt.38.clone.1 = f32[256,32,14336]{2,1,0:T(8,128)} sqrt(divide.423.clone.1)
  constant.3443.clone.1 = f32[]{:T(128)} constant(1e-08)
  broadcast.2665.clone.1 = f32[256,32,14336]{2,1,0:T(8,128)} broadcast(constant.3443.clone.1), dimensions={}
  add.1278.clone.1 = f32[256,32,14336]{2,1,0:T(8,128)} add(sqrt.38.clone.1, broadcast.2665.clone.1)
  multiply.1583.clone.1 = f32[256,32,14336]{2,1,0:T(8,128)} multiply(broadcast.2667.clone.1, add.1278.clone.1)
  divide.422.clone.1 = f32[256,32,14336]{2,1,0:T(8,128)} divide(add.1280.clone.1, multiply.1583.clone.1)
  multiply.1582.clone.1 = f32[256,32,14336]{2,1,0:T(8,128)} multiply(param_0.1992, broadcast.2675.clone.1)
  add.1277.clone.1 = f32[256,32,14336]{2,1,0:T(8,128)} add(divide.422.clone.1, multiply.1582.clone.1)
  multiply.1581.clone.1 = f32[256,32,14336]{2,1,0:T(8,128)} multiply(broadcast.2669.clone.1, add.1277.clone.1)
  add.1276.clone.1 = f32[256,32,14336]{2,1,0:T(8,128)} add(param_0.1992, multiply.1581.clone.1)
  multiply.1254 = f32[256,32,14336]{2,1,0:T(8,128)} multiply(add.1276.clone.1, add.1276.clone.1)
  constant.3464 = f32[]{:T(128)} constant(0)
  reduce.137 = f32[]{:T(128)} reduce(multiply.1254, constant.3464), dimensions={0,1,2}, to_apply=
  {
    Arg_0.2390 = f32[]{:T(128)} parameter(0)
    Arg_1.2391 = f32[]{:T(128)} parameter(1)
    ROOT add.2392 = f32[]{:T(128)} add(Arg_0.2390, Arg_1.2391)
  }
  reduce.140.clone.1 = f32[]{:T(128)} reduce(multiply.1587.clone.1, constant.3464), dimensions={0,1,2}, to_apply=
  {
    Arg_0.2222 = f32[]{:T(128)} parameter(0)
    Arg_1.2223 = f32[]{:T(128)} parameter(1)
    ROOT add.2224 = f32[]{:T(128)} add(Arg_0.2222, Arg_1.2223)
  }
  ROOT tuple.357 = (f32[]{:T(128)}, f32[256,32,14336]{2,1,0:T(8,128)}, f32[256,32,14336]{2,1,0:T(8,128)}, f32[256,32,14336]{2,1,0:T(8,128)}, f32[]{:T(128)}) tuple(reduce.137, add.1276.clone.1, add.1279.clone.1, add.1280.clone.1, reduce.140.clone.1)
} after 1 retry
I0913 01:11:49.740544     532 2a886c8_compiler_base.cc:10004] BACKEND_PASSES stage duration: 5.3577423785s
I0913 01:11:50.652100     532 2a886c8_compiler_base.cc:3124] final program bundle count: 670,454 note this count does not reflect cycles spent executing delays.
I0913 01:11:50.687415     532 2a886c8_compiler_base.cc:3124] final program bundle count: 147 note this count does not reflect cycles spent executing delays.
I0913 01:11:50.841176     532 2a886c8_compiler_base.cc:3356] Program divided into 38 overlays without HLO functions (40.98M).
I0913 01:11:51.098601     532 2a886c8_compiler_base.cc:3535] XLA::TPU module name: jit_train_step
I0913 01:11:51.098627     532 2a886c8_compiler_base.cc:3537] XLA::TPU program HBM usage: 4.25G / 31.25G
I0913 01:11:51.098633     532 2a886c8_compiler_base.cc:3587] XLA::TPU program VMEM usage: 127.40M / 128.00M
I0913 01:11:51.098640     532 2a886c8_compiler_base.cc:3598] Total hbm usage >= 10.12G:
I0913 01:11:51.098642     532 2a886c8_compiler_base.cc:3598]     reserved        260.01M 
I0913 01:11:51.098643     532 2a886c8_compiler_base.cc:3598]     program           4.25G 
I0913 01:11:51.098644     532 2a886c8_compiler_base.cc:3598]     arguments         5.61G 
I0913 01:11:51.098645     532 2a886c8_compiler_base.cc:3598] 
I0913 01:11:51.098647     532 2a886c8_compiler_base.cc:3598] Output size 5.61G; shares 5.61G with arguments.
I0913 01:11:51.098648     532 2a886c8_compiler_base.cc:3598] 
I0913 01:11:51.098663     532 2a886c8_compiler_base.cc:3602] Program sflag requirement 384B:
I0913 01:11:51.098664     532 2a886c8_compiler_base.cc:3602]     reserved           204B
I0913 01:11:51.098665     532 2a886c8_compiler_base.cc:3602]     scoped              52B
I0913 01:11:51.098667     532 2a886c8_compiler_base.cc:3602]     HLO temp           128B (100.0% utilization: Unpadded (128B) Padded (128B), 0.0% fragmentation (0B))
I0913 01:11:51.098668     532 2a886c8_compiler_base.cc:3602] Program hbm requirement 4.25G:
I0913 01:11:51.098669     532 2a886c8_compiler_base.cc:3602]     global           720.5K
I0913 01:11:51.098671     532 2a886c8_compiler_base.cc:3602]     HLO temp          4.21G (100.0% utilization: Unpadded (3.08G) Padded (3.08G), 26.8% fragmentation (1.13G))
I0913 01:11:51.098672     532 2a886c8_compiler_base.cc:3602]     overlays         40.98M
I0913 01:11:51.098673     532 2a886c8_compiler_base.cc:3602] Program vmem requirement 127.40M:
I0913 01:11:51.098674     532 2a886c8_compiler_base.cc:3602]     scoped           31.40M
I0913 01:11:51.098676     532 2a886c8_compiler_base.cc:3602]     HLO temp         96.00M (0.0% utilization: Unpadded (0B) Padded (0B), 100.0% fragmentation (96.00M))
I0913 01:11:51.098677     532 2a886c8_compiler_base.cc:3602] Program smem requirement 12.2K:
I0913 01:11:51.098678     532 2a886c8_compiler_base.cc:3602]     scoped             8.2K
I0913 01:11:51.098680     532 2a886c8_compiler_base.cc:3602]     HLO temp           4.0K (100.0% utilization: Unpadded (8B) Padded (8B), 99.8% fragmentation (4.0K))
I0913 01:11:51.098681     532 2a886c8_compiler_base.cc:3610] XLA::TPU program SMEM usage: 14.2K / 1.00M (44 parameters)
I0913 01:11:51.098697     532 2a886c8_compiler_base.cc:3644] CODE_GENERATION stage duration: 1.3580351325s
I0913 01:11:51.127875     532 isa_program_util_common.cc:486] (HLO module jit_train_step): Executable fingerprint:7102305d9a13a7afa016d87fee479465cfec5c423f7eed11bc4768a0408beaaf
I0913 01:11:51.127908     532 isa_program_util_common.cc:490] (HLO module jit_train_step): Executable fingerprint (including data segments):1993fc9b6d79222ee3c24ebfd7680ae5bfa9b66d75107bb0bcafffd50b78ddef
I0913 01:11:51.127911     532 isa_program_util_common.cc:493] (HLO module jit_train_step): Host transfer fingerprint:e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855
I0913 01:11:51.871073     141 2a886c8_compiler_base.cc:7452] END_TO_END stage duration: 10.94651308725s
I0913 01:11:51.884251     141 tfrt_tpu_pjrt_compiler.cc:394] Source URI is : googlefile:/google_src/files/759148519/depot/branches/libtpu_lts_release_branch/758471328.2/OVERLAY_READONLY/g3     
Total memory size: 11.0 GB, Output size: 5.6 GB, Temp size: 5.3 GB, Argument size: 5.6 GB, Host temp size: 0.0 GB.
Per train step:
 Total TFLOPs: 98.81 
 split as 93.32% learnable weight flops and 6.68% attention flops
number parameters: 8.030 billion
2025-09-13 01:11:53.871151: I tensorflow/core/kernels/data/tf_record_dataset_op.cc:387] The default buffer size is 262144, which is overridden by the user specified `buffer_size` of 8388608
I0913 01:11:54.293130     792 session_master.cc:211] Worker Address: maxtext-vlp16-default-slice-0-2.maxtext-vlp16-default:8471
I0913 01:11:54.293191     792 session_master.cc:211] Worker Address: maxtext-vlp16-default-slice-0-0.maxtext-vlp16-default:8471
I0913 01:11:54.293196     792 session_master.cc:211] Worker Address: maxtext-vlp16-default-slice-0-1.maxtext-vlp16-default:8471
I0913 01:11:54.293198     792 session_master.cc:211] Worker Address: maxtext-vlp16-default-slice-0-3.maxtext-vlp16-default:8471
I0913 01:11:59.396072     141 2a886c8_compiler_base.cc:6877] XLA::TPU running hlo passes for 17 instructions, modules: jit_fold_in
I0913 01:11:59.396109     141 2a886c8_compiler_base.cc:6934] Initial HLO module: jit_fold_in instructions: 17 fingerprint: 
I0913 01:11:59.396583     141 2a886c8_compiler_base.cc:6997] HLO optimizing module: jit_fold_in instructions: 154
I0913 01:11:59.396598     141 2a886c8_compiler_base.cc:7012] XLA::TPU HLO optimization
I0913 01:11:59.404252     141 2a886c8_compiler_base.cc:6063] XLA::TPU HLO PostOptimizationPipeline
I0913 01:11:59.405841     141 2a886c8_compiler_base.cc:7068] HLO_PASSES stage duration: 10.659116ms
I0913 01:11:59.406698   25450 memory_space_assignment_util.cc:632] MSA Vmem breakdown: default scoped vmem (from flag): 33554432; does_msa_directly_allocate_scoped_vmem: F; bytes_for_msa_to_allocate: 100663296
I0913 01:11:59.420295     532 2a886c8_compiler_base.cc:10004] BACKEND_PASSES stage duration: 13.763106ms
I0913 01:11:59.421661     532 2a886c8_compiler_base.cc:3124] final program bundle count: 525 note this count does not reflect cycles spent executing delays.
I0913 01:11:59.424080     532 2a886c8_compiler_base.cc:3124] final program bundle count: 147 note this count does not reflect cycles spent executing delays.
I0913 01:11:59.425225     532 2a886c8_compiler_base.cc:3356] Program divided into 2 overlays without HLO functions (59.0K).
I0913 01:11:59.425525     532 2a886c8_compiler_base.cc:3535] XLA::TPU module name: jit_fold_in
I0913 01:11:59.425561     532 2a886c8_compiler_base.cc:3537] XLA::TPU program HBM usage: 59.0K / 31.25G
I0913 01:11:59.425564     532 2a886c8_compiler_base.cc:3587] XLA::TPU program VMEM usage: 22.5K / 128.00M
I0913 01:11:59.425570     532 2a886c8_compiler_base.cc:3598] Total hbm usage >= 260.07M:
I0913 01:11:59.425572     532 2a886c8_compiler_base.cc:3598]     reserved        260.01M 
I0913 01:11:59.425573     532 2a886c8_compiler_base.cc:3598]     program           59.0K 
I0913 01:11:59.425575     532 2a886c8_compiler_base.cc:3598]     arguments          1.0K 
I0913 01:11:59.425576     532 2a886c8_compiler_base.cc:3598] 
I0913 01:11:59.425577     532 2a886c8_compiler_base.cc:3598] Output size 512B; shares 0B with arguments.
I0913 01:11:59.425579     532 2a886c8_compiler_base.cc:3598] 
I0913 01:11:59.425587     532 2a886c8_compiler_base.cc:3602] Program sflag requirement 220B:
I0913 01:11:59.425590     532 2a886c8_compiler_base.cc:3602]     reserved           204B
I0913 01:11:59.425592     532 2a886c8_compiler_base.cc:3602]     scoped              12B
I0913 01:11:59.425593     532 2a886c8_compiler_base.cc:3602]     HLO temp             4B (100.0% utilization: Unpadded (4B) Padded (4B), 0.0% fragmentation (0B))
I0913 01:11:59.425594     532 2a886c8_compiler_base.cc:3602] Program vmem requirement 22.5K:
I0913 01:11:59.425595     532 2a886c8_compiler_base.cc:3602]     scoped            10.0K
I0913 01:11:59.425597     532 2a886c8_compiler_base.cc:3602]     HLO temp          12.5K (0.0% utilization: Unpadded (0B) Padded (0B), 100.0% fragmentation (12.5K))
I0913 01:11:59.425598     532 2a886c8_compiler_base.cc:3602] Program smem requirement 36B:
I0913 01:11:59.425599     532 2a886c8_compiler_base.cc:3602]     scoped              36B
I0913 01:11:59.425600     532 2a886c8_compiler_base.cc:3602] Program hbm requirement 59.0K:
I0913 01:11:59.425602     532 2a886c8_compiler_base.cc:3602]     overlays          59.0K
I0913 01:11:59.425603     532 2a886c8_compiler_base.cc:3610] XLA::TPU program SMEM usage: 1.9K / 1.00M (2 parameters)
I0913 01:11:59.425613     532 2a886c8_compiler_base.cc:3644] CODE_GENERATION stage duration: 5.274213ms
I0913 01:11:59.425699     532 isa_program_util_common.cc:486] (HLO module jit_fold_in): Executable fingerprint:6f1f242684d0b1d42187c2a361d8454167f5d6f20e0e106f2a9cd1c8aa91f5c3
I0913 01:11:59.425703     532 isa_program_util_common.cc:490] (HLO module jit_fold_in): Executable fingerprint (including data segments):7d494a8ce6cc6d8741b1647c05fc1c5d27364fa60ab6f067d0db9011c3cb4f87
I0913 01:11:59.425705     532 isa_program_util_common.cc:493] (HLO module jit_fold_in): Host transfer fingerprint:e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855
I0913 01:11:59.426323     141 2a886c8_compiler_base.cc:7452] END_TO_END stage duration: 31.20068ms
Waiting for step 0 to finish before checkpoint...
Waited 9.603873491287231 seconds for step 0 to finish before starting checkpointing.
I0913 01:12:15.600711 140416767584064 checkpoint_manager.py:1987] [process=0][thread=MainThread][wait_until_finished] No Save Finalize thread to wait for. Returning.
I0913 01:12:15.600983 140416767584064 checkpoint_manager.py:1408] [process=0] Saving checkpoint at step 0
I0913 01:12:15.929537 140416767584064 async_checkpointer.py:439] [process=0] Started async saving checkpoint to /gcs-dir/maxtext-output/runner_llama3.1_8b/checkpoints/0.
I0913 01:12:16.075292 140416767584064 signaling_client.py:323] Using JaxDistributedSignalingClient
I0913 01:12:16.161760 140258465281792 atomicity.py:144] Creating tmp directory /gcs-dir/maxtext-output/runner_llama3.1_8b/checkpoints/0.orbax-checkpoint-tmp-0
I0913 01:12:16.665167 140258448496384 checkpoint.py:186] Wrote Metadata={'item_handlers': None, 'metrics': {}, 'performance_metrics': {}, 'init_timestamp_nsecs': 1757725936353229830, 'commit_timestamp_nsecs': None, 'custom_metadata': {}}, json={"item_handlers": null, "metrics": {}, "performance_metrics": {}, "init_timestamp_nsecs": 1757725936353229830, "commit_timestamp_nsecs": null, "custom_metadata": {}} to /gcs-dir/maxtext-output/runner_llama3.1_8b/checkpoints/0.orbax-checkpoint-tmp-0/_CHECKPOINT_METADATA
I0913 01:12:16.669086 140258465281792 atomicity.py:144] Creating tmp directory /gcs-dir/maxtext-output/runner_llama3.1_8b/checkpoints/0.orbax-checkpoint-tmp-0/items.orbax-checkpoint-tmp-1
I0913 01:12:16.766734 140416767584064 replica_slices.py:341] Transferring arrays to host memory with options: use_replica_parallel=True, enable_pinned_host_transfer=False
I0913 01:12:16.928682     141 2a886c8_compiler_base.cc:7068] HLO_PASSES stage duration: 5.53526225ms
I0913 01:12:16.929237   25450 memory_space_assignment_util.cc:632] MSA Vmem breakdown: default scoped vmem (from flag): 33554432; does_msa_directly_allocate_scoped_vmem: F; bytes_for_msa_to_allocate: 100663296
I0913 01:12:16.931897     532 2a886c8_compiler_base.cc:10004] BACKEND_PASSES stage duration: 2.802981ms
I0913 01:12:16.935557     532 2a886c8_compiler_base.cc:3644] CODE_GENERATION stage duration: 3.6271185ms
I0913 01:12:16.935633     532 isa_program_util_common.cc:486] (HLO module jit_slice): Executable fingerprint:9b2e629303e9900c42ea4cfe93d28b4b0103c2d8348204058f551990d343ec04
I0913 01:12:16.935639     532 isa_program_util_common.cc:490] (HLO module jit_slice): Executable fingerprint (including data segments):aee87293033e1909bf15d263f96016b3f847d2c8cc05802cedfe50c80f1d59a7
I0913 01:12:16.935641     532 isa_program_util_common.cc:493] (HLO module jit_slice): Host transfer fingerprint:e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855
I0913 01:12:16.935775     141 2a886c8_compiler_base.cc:7452] END_TO_END stage duration: 12.6726595ms
I0913 01:12:17.108128     141 2a886c8_compiler_base.cc:7068] HLO_PASSES stage duration: 2.91015075ms
I0913 01:12:17.108660   25451 memory_space_assignment_util.cc:632] MSA Vmem breakdown: default scoped vmem (from flag): 33554432; does_msa_directly_allocate_scoped_vmem: F; bytes_for_msa_to_allocate: 100663296
I0913 01:12:17.111415     532 2a886c8_compiler_base.cc:10004] BACKEND_PASSES stage duration: 2.92320075ms
I0913 01:12:17.115304     532 2a886c8_compiler_base.cc:3644] CODE_GENERATION stage duration: 3.83991775ms
I0913 01:12:17.115397     532 isa_program_util_common.cc:486] (HLO module jit_slice): Executable fingerprint:94ce0e58a201aab95237d86504001cbfad35966356162416d2abbb8defd68a5f
I0913 01:12:17.115405     532 isa_program_util_common.cc:490] (HLO module jit_slice): Executable fingerprint (including data segments):5545beaa1f9ce1c836c52809923e8459f9cce8b1219ef6fa2d82234157b0a93c
I0913 01:12:17.115407     532 isa_program_util_common.cc:493] (HLO module jit_slice): Host transfer fingerprint:e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855
I0913 01:12:17.115618     141 2a886c8_compiler_base.cc:7452] END_TO_END stage duration: 10.4388065ms
I0913 01:12:17.277248     141 2a886c8_compiler_base.cc:7068] HLO_PASSES stage duration: 2.9958205ms
I0913 01:12:17.277743   25451 memory_space_assignment_util.cc:632] MSA Vmem breakdown: default scoped vmem (from flag): 33554432; does_msa_directly_allocate_scoped_vmem: F; bytes_for_msa_to_allocate: 100663296
I0913 01:12:17.280463     532 2a886c8_compiler_base.cc:10004] BACKEND_PASSES stage duration: 2.86825075ms
I0913 01:12:17.284360     532 2a886c8_compiler_base.cc:3644] CODE_GENERATION stage duration: 3.84942775ms
I0913 01:12:17.284441     532 isa_program_util_common.cc:486] (HLO module jit_slice): Executable fingerprint:ff07458a7e77a76dfea6922e4c1f162b6770ca62ce45b98e9bc2007d30e867fb
I0913 01:12:17.284447     532 isa_program_util_common.cc:490] (HLO module jit_slice): Executable fingerprint (including data segments):c8cef4c1d5804ddc4de00f4d0546ee8f3f6c55c708bb0fbf289e915ebe596fe8
I0913 01:12:17.284449     532 isa_program_util_common.cc:493] (HLO module jit_slice): Host transfer fingerprint:e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855
I0913 01:12:17.284632     141 2a886c8_compiler_base.cc:7452] END_TO_END stage duration: 10.41726675ms
I0913 01:12:17.440346     141 2a886c8_compiler_base.cc:7068] HLO_PASSES stage duration: 2.812241ms
I0913 01:12:17.440829   25450 memory_space_assignment_util.cc:632] MSA Vmem breakdown: default scoped vmem (from flag): 33554432; does_msa_directly_allocate_scoped_vmem: F; bytes_for_msa_to_allocate: 100663296
I0913 01:12:17.443597     532 2a886c8_compiler_base.cc:10004] BACKEND_PASSES stage duration: 2.90456075ms
I0913 01:12:17.447273     532 2a886c8_compiler_base.cc:3644] CODE_GENERATION stage duration: 3.64350825ms
I0913 01:12:17.447339     532 isa_program_util_common.cc:486] (HLO module jit_slice): Executable fingerprint:43a369a6f81b985796a0ad949114f912d894fe6646fd12ebf66a2e6fbc1af4ed
I0913 01:12:17.447345     532 isa_program_util_common.cc:490] (HLO module jit_slice): Executable fingerprint (including data segments):a79434610766b9ced2afb268d9e66a887f8ea6e63eed734104086f4ff35fb92a
I0913 01:12:17.447347     532 isa_program_util_common.cc:493] (HLO module jit_slice): Host transfer fingerprint:e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855
I0913 01:12:17.447483     141 2a886c8_compiler_base.cc:7452] END_TO_END stage duration: 9.987898ms
I0913 01:12:17.638948     141 2a886c8_compiler_base.cc:7068] HLO_PASSES stage duration: 8.8685315ms
I0913 01:12:17.639647   25451 memory_space_assignment_util.cc:632] MSA Vmem breakdown: default scoped vmem (from flag): 33554432; does_msa_directly_allocate_scoped_vmem: F; bytes_for_msa_to_allocate: 100663296
I0913 01:12:17.642913     532 2a886c8_compiler_base.cc:10004] BACKEND_PASSES stage duration: 3.470259ms
I0913 01:12:17.647013     532 2a886c8_compiler_base.cc:3644] CODE_GENERATION stage duration: 4.045547ms
I0913 01:12:17.647094     532 isa_program_util_common.cc:486] (HLO module jit_slice): Executable fingerprint:8f16f602aec93950fc80dbbd8c1c94782c1c149ed29cac6e518bd5a91a9bcaea
I0913 01:12:17.647100     532 isa_program_util_common.cc:490] (HLO module jit_slice): Executable fingerprint (including data segments):808994731d01df7ecb943a8ec207d7c9b5a44a7bca40d13e7bbc38ac87a3d3d8
I0913 01:12:17.647102     532 isa_program_util_common.cc:493] (HLO module jit_slice): Host transfer fingerprint:e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855
I0913 01:12:17.647283     141 2a886c8_compiler_base.cc:7452] END_TO_END stage duration: 17.3146845ms
I0913 01:12:17.806312     141 2a886c8_compiler_base.cc:7068] HLO_PASSES stage duration: 2.829761ms
I0913 01:12:17.806801   25451 memory_space_assignment_util.cc:632] MSA Vmem breakdown: default scoped vmem (from flag): 33554432; does_msa_directly_allocate_scoped_vmem: F; bytes_for_msa_to_allocate: 100663296
I0913 01:12:17.809799     532 2a886c8_compiler_base.cc:10004] BACKEND_PASSES stage duration: 3.14333ms
I0913 01:12:17.813379     532 2a886c8_compiler_base.cc:3644] CODE_GENERATION stage duration: 3.53489875ms
I0913 01:12:17.813457     532 isa_program_util_common.cc:486] (HLO module jit_slice): Executable fingerprint:28d94b5d36c0c2fb45f30ef1e5fd8820903b34f567ce5b8e523fa0255c606f77
I0913 01:12:17.813462     532 isa_program_util_common.cc:490] (HLO module jit_slice): Executable fingerprint (including data segments):4797c8fb2d3857eb005141279257e1f8a7342ad7914e8ddfc7938a70f0bdc5e4
I0913 01:12:17.813464     532 isa_program_util_common.cc:493] (HLO module jit_slice): Host transfer fingerprint:e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855
I0913 01:12:17.813633     141 2a886c8_compiler_base.cc:7452] END_TO_END stage duration: 10.1884875ms
I0913 01:12:18.035472     141 2a886c8_compiler_base.cc:7068] HLO_PASSES stage duration: 2.835201ms
I0913 01:12:18.036021   25451 memory_space_assignment_util.cc:632] MSA Vmem breakdown: default scoped vmem (from flag): 33554432; does_msa_directly_allocate_scoped_vmem: F; bytes_for_msa_to_allocate: 100663296
I0913 01:12:18.038983     532 2a886c8_compiler_base.cc:10004] BACKEND_PASSES stage duration: 3.13133ms
I0913 01:12:18.042544     532 2a886c8_compiler_base.cc:3644] CODE_GENERATION stage duration: 3.51597875ms
I0913 01:12:18.042619     532 isa_program_util_common.cc:486] (HLO module jit_slice): Executable fingerprint:7e7a0655bd39a325b742ff168c32e4c3b68376afaa4a9095b784c25cf37aee49
I0913 01:12:18.042625     532 isa_program_util_common.cc:490] (HLO module jit_slice): Executable fingerprint (including data segments):2e22d1b02880b02d6d875d17fe87df9f7de7008a643f3c2a0d5f5c6dc617760d
I0913 01:12:18.042627     532 isa_program_util_common.cc:493] (HLO module jit_slice): Host transfer fingerprint:e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855
I0913 01:12:18.042795     141 2a886c8_compiler_base.cc:7452] END_TO_END stage duration: 10.19598725ms
I0913 01:12:18.226793     141 2a886c8_compiler_base.cc:7068] HLO_PASSES stage duration: 2.804621ms
I0913 01:12:18.227365   25451 memory_space_assignment_util.cc:632] MSA Vmem breakdown: default scoped vmem (from flag): 33554432; does_msa_directly_allocate_scoped_vmem: F; bytes_for_msa_to_allocate: 100663296
I0913 01:12:18.230404     532 2a886c8_compiler_base.cc:10004] BACKEND_PASSES stage duration: 3.22609975ms
I0913 01:12:18.233918     532 2a886c8_compiler_base.cc:3644] CODE_GENERATION stage duration: 3.470239ms
I0913 01:12:18.234001     532 isa_program_util_common.cc:486] (HLO module jit_slice): Executable fingerprint:0bfcb974311afeb5f0a2d4012da16716c0ad035a63c20a55c5dc5a48990793fb
I0913 01:12:18.234007     532 isa_program_util_common.cc:490] (HLO module jit_slice): Executable fingerprint (including data segments):f78d993df04010ee96695dfaced52590288e770fa53ac0c68626122272e38e5c
I0913 01:12:18.234009     532 isa_program_util_common.cc:493] (HLO module jit_slice): Host transfer fingerprint:e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855
I0913 01:12:18.234181     141 2a886c8_compiler_base.cc:7452] END_TO_END stage duration: 10.24555725ms
I0913 01:12:20.710858 140416767584064 base_pytree_checkpoint_handler.py:114] [process=0] /jax/checkpoint/write/blocking_bytes_per_sec: 5.7 GiB/s (total bytes: 22.4 GiB) (time elapsed: 3 seconds) (per-host)
I0913 01:12:20.880826 140243807389440 async_checkpointer.py:77] [process=0][thread=async_save] Background save thread started.
I0913 01:12:20.886720 140416767584064 async_checkpointer.py:548] Finished blocking save in 5.29 seconds. Continuing to save asynchronously to /gcs-dir/maxtext-output/runner_llama3.1_8b/checkpoints/0.
I0913 01:12:20.984899 140416767584064 checkpoint_manager.py:1453] [process=0][thread=MainThread][step=0] Starting CheckpointManager Save Finalize thread=save_finalize
I0913 01:12:20.985327 140242414888704 async_checkpointer.py:258] [process=0][thread=save_finalize] Waiting for background save thread=async_save.
I0913 01:12:20.990394 140416767584064 standard_logger.py:34] {'step': 0, 'event_type': 'save', 'directory': '/gcs-dir/maxtext-output/runner_llama3.1_8b/checkpoints', 'reached_preemption': False, 'preemption_received_at': None, 'synchronous': False, 'wait_for_prev_start_time': 1757725935.6006818, 'wait_for_prev_duration_secs': 0.0001499652862548828, 'checkpointer_blocking_start_time': 1757725935.6010206, 'checkpointer_blocking_duration_secs': 5.285836219787598, 'get_old_steps_start_time': 1757725940.8868742, 'get_old_steps_duration_secs': 4.0531158447265625e-06, 'checkpoint_manager_blocking_start_time': 1757725935.5178032, 'checkpoint_manager_blocking_duration_secs': 5.472520112991333}
Started an asynchronous checkpoint save for step 0

Memstats: After params initialized:
	Using (GB) 5.65 / 31.25 (18.080000%) on TPU_0(process=0,(0,0,0,0))
	Using (GB) 5.65 / 31.25 (18.080000%) on TPU_1(process=0,(1,0,0,0))
	Using (GB) 5.65 / 31.25 (18.080000%) on TPU_4(process=0,(0,1,0,0))
	Using (GB) 5.65 / 31.25 (18.080000%) on TPU_5(process=0,(1,1,0,0))
I0913 01:12:21.078810     141 2a886c8_compiler_base.cc:7068] HLO_PASSES stage duration: 3.08095025ms
I0913 01:12:21.079406   25451 memory_space_assignment_util.cc:632] MSA Vmem breakdown: default scoped vmem (from flag): 33554432; does_msa_directly_allocate_scoped_vmem: F; bytes_for_msa_to_allocate: 100663296
I0913 01:12:21.083182     532 2a886c8_compiler_base.cc:10004] BACKEND_PASSES stage duration: 3.94816725ms
I0913 01:12:21.086934     532 2a886c8_compiler_base.cc:3644] CODE_GENERATION stage duration: 3.70347825ms
I0913 01:12:21.087004     532 isa_program_util_common.cc:486] (HLO module jit_clip): Executable fingerprint:0b300ac6cee40d2c8fe60b0cc6527c9580a7c59e5986cf164f304ac1971eff5a
I0913 01:12:21.087010     532 isa_program_util_common.cc:490] (HLO module jit_clip): Executable fingerprint (including data segments):55722cfa349603c3db438de1922955dd4bb3b883f08120071ac9a335975c27e3
I0913 01:12:21.087012     532 isa_program_util_common.cc:493] (HLO module jit_clip): Host transfer fingerprint:e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855
I0913 01:12:21.087164     141 2a886c8_compiler_base.cc:7452] END_TO_END stage duration: 11.47713325ms
I0913 01:12:21.358460 140258465281792 array_metadata_store.py:198] [process=0][thread=array_type_handler] Wrote 39 array_metadata.ArrayMetadata to /gcs-dir/maxtext-output/runner_llama3.1_8b/checkpoints/0.orbax-checkpoint-tmp-0/items.orbax-checkpoint-tmp-1/array_metadatas/process_0
I0913 01:12:21.568438     141 2a886c8_compiler_base.cc:7068] HLO_PASSES stage duration: 3.05285025ms
I0913 01:12:21.569022   25451 memory_space_assignment_util.cc:632] MSA Vmem breakdown: default scoped vmem (from flag): 33554432; does_msa_directly_allocate_scoped_vmem: F; bytes_for_msa_to_allocate: 100663296
I0913 01:12:21.572715     532 2a886c8_compiler_base.cc:10004] BACKEND_PASSES stage duration: 3.9152775ms
I0913 01:12:21.576401     532 2a886c8_compiler_base.cc:3644] CODE_GENERATION stage duration: 3.63584825ms
I0913 01:12:21.576478     532 isa_program_util_common.cc:486] (HLO module jit_true_divide): Executable fingerprint:d40b6db142dfa09d44d0c5033857e0107c9b55b927481ef52a1a4d39078fbf7b
I0913 01:12:21.576483     532 isa_program_util_common.cc:490] (HLO module jit_true_divide): Executable fingerprint (including data segments):c9925b9746a872952c48785c6ac5ace98a957ab4383d54e3c15177701420e094
I0913 01:12:21.576485     532 isa_program_util_common.cc:493] (HLO module jit_true_divide): Host transfer fingerprint:e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855
I0913 01:12:21.576628     141 2a886c8_compiler_base.cc:7452] END_TO_END stage duration: 11.28919375ms
I0913 01:12:21.706457     141 2a886c8_compiler_base.cc:7068] HLO_PASSES stage duration: 2.9367105ms
I0913 01:12:21.707054   25451 memory_space_assignment_util.cc:632] MSA Vmem breakdown: default scoped vmem (from flag): 33554432; does_msa_directly_allocate_scoped_vmem: F; bytes_for_msa_to_allocate: 100663296
I0913 01:12:21.710592     532 2a886c8_compiler_base.cc:10004] BACKEND_PASSES stage duration: 3.767528ms
I0913 01:12:21.714237     532 2a886c8_compiler_base.cc:3644] CODE_GENERATION stage duration: 3.6003085ms
I0913 01:12:21.714313     532 isa_program_util_common.cc:486] (HLO module jit_subtract): Executable fingerprint:2741262b517dbde11313e86a85a7954c03fe8d5fdf298ea334ab45e4518e9fd1
I0913 01:12:21.714319     532 isa_program_util_common.cc:490] (HLO module jit_subtract): Executable fingerprint (including data segments):b5a1d2556ca3ea0d9977ed74df65149c7762d96cdaa6fcd5edf6abd2a864eeb1
I0913 01:12:21.714321     532 isa_program_util_common.cc:493] (HLO module jit_subtract): Host transfer fingerprint:e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855
I0913 01:12:21.714460     141 2a886c8_compiler_base.cc:7452] END_TO_END stage duration: 10.98218475ms
I0913 01:12:21.956272     141 2a886c8_compiler_base.cc:7068] HLO_PASSES stage duration: 2.75614125ms
I0913 01:12:21.956717   25450 memory_space_assignment_util.cc:632] MSA Vmem breakdown: default scoped vmem (from flag): 33554432; does_msa_directly_allocate_scoped_vmem: F; bytes_for_msa_to_allocate: 100663296
I0913 01:12:21.959845     532 2a886c8_compiler_base.cc:10004] BACKEND_PASSES stage duration: 3.23145975ms
I0913 01:12:21.963116     532 2a886c8_compiler_base.cc:3644] CODE_GENERATION stage duration: 3.23621975ms
I0913 01:12:21.963182     532 isa_program_util_common.cc:486] (HLO module jit_integer_pow): Executable fingerprint:70c9ba63bbb4f0ab4683501f9fae65f10d3935a066915cf01bc1104116c83913
I0913 01:12:21.963194     532 isa_program_util_common.cc:490] (HLO module jit_integer_pow): Executable fingerprint (including data segments):7204f387665061bd2ee0accce392d62ae0a05c9c49f78c36ffb00f7ddf50acf0
I0913 01:12:21.963197     532 isa_program_util_common.cc:493] (HLO module jit_integer_pow): Host transfer fingerprint:e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855
I0913 01:12:21.963307     141 2a886c8_compiler_base.cc:7452] END_TO_END stage duration: 9.8250485ms
I0913 01:12:22.048347     141 2a886c8_compiler_base.cc:7068] HLO_PASSES stage duration: 2.845761ms
I0913 01:12:22.048886   25451 memory_space_assignment_util.cc:632] MSA Vmem breakdown: default scoped vmem (from flag): 33554432; does_msa_directly_allocate_scoped_vmem: F; bytes_for_msa_to_allocate: 100663296
I0913 01:12:22.052437     532 2a886c8_compiler_base.cc:10004] BACKEND_PASSES stage duration: 3.759648ms
I0913 01:12:22.056147     532 2a886c8_compiler_base.cc:3644] CODE_GENERATION stage duration: 3.66425825ms
I0913 01:12:22.056224     532 isa_program_util_common.cc:486] (HLO module jit_multiply): Executable fingerprint:7383f999b7521bbb7c2d2feb5a87995ebd4c856d378f9ad8e1981a6d6e21f03d
I0913 01:12:22.056229     532 isa_program_util_common.cc:490] (HLO module jit_multiply): Executable fingerprint (including data segments):135ff3fff5eb10f49d4c1b3285aa4da56551f28259015f24157308fdaa43b35c
I0913 01:12:22.056231     532 isa_program_util_common.cc:493] (HLO module jit_multiply): Host transfer fingerprint:e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855
I0913 01:12:22.056381     141 2a886c8_compiler_base.cc:7452] END_TO_END stage duration: 10.920335ms
I0913 01:12:22.214503     141 2a886c8_compiler_base.cc:7068] HLO_PASSES stage duration: 2.86300075ms
I0913 01:12:22.215032   25450 memory_space_assignment_util.cc:632] MSA Vmem breakdown: default scoped vmem (from flag): 33554432; does_msa_directly_allocate_scoped_vmem: F; bytes_for_msa_to_allocate: 100663296
I0913 01:12:22.218471     532 2a886c8_compiler_base.cc:10004] BACKEND_PASSES stage duration: 3.5754285ms
I0913 01:12:22.221775     532 2a886c8_compiler_base.cc:3644] CODE_GENERATION stage duration: 3.2734595ms
I0913 01:12:22.221841     532 isa_program_util_common.cc:486] (HLO module jit_add): Executable fingerprint:7b9fe1cc59a47b013d46dc01380c53856ad6dc42a9c99284eeaeab378be57ba0
I0913 01:12:22.221846     532 isa_program_util_common.cc:490] (HLO module jit_add): Executable fingerprint (including data segments):a5fb3e5ed7286c5866fabf56bfe5a61c4ebdac5ba03e5232f1456b303ad392ab
I0913 01:12:22.221848     532 isa_program_util_common.cc:493] (HLO module jit_add): Host transfer fingerprint:e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855
I0913 01:12:22.221923     141 2a886c8_compiler_base.cc:7452] END_TO_END stage duration: 10.321557ms
I0913 01:12:22.410261     141 2a886c8_compiler_base.cc:7068] HLO_PASSES stage duration: 2.76699125ms
I0913 01:12:22.410810   25451 memory_space_assignment_util.cc:632] MSA Vmem breakdown: default scoped vmem (from flag): 33554432; does_msa_directly_allocate_scoped_vmem: F; bytes_for_msa_to_allocate: 100663296
I0913 01:12:22.415250     532 2a886c8_compiler_base.cc:10004] BACKEND_PASSES stage duration: 4.650355ms
I0913 01:12:22.419039     532 2a886c8_compiler_base.cc:3644] CODE_GENERATION stage duration: 3.746398ms
I0913 01:12:22.419117     532 isa_program_util_common.cc:486] (HLO module jit_cos): Executable fingerprint:abebf6469639272b66f279b4afc77bf294d683f9a8b3356c1e46ad1e83096b46
I0913 01:12:22.419122     532 isa_program_util_common.cc:490] (HLO module jit_cos): Executable fingerprint (including data segments):1bab66d57c54876e1a528ac21fc3aa38a244479c6bab22c3879a9a3a41e59dd0
I0913 01:12:22.419124     532 isa_program_util_common.cc:493] (HLO module jit_cos): Host transfer fingerprint:e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855
I0913 01:12:22.419313     141 2a886c8_compiler_base.cc:7452] END_TO_END stage duration: 11.856312ms
I0913 01:12:22.541203     141 2a886c8_compiler_base.cc:7068] HLO_PASSES stage duration: 2.87313075ms
I0913 01:12:22.541712   25450 memory_space_assignment_util.cc:632] MSA Vmem breakdown: default scoped vmem (from flag): 33554432; does_msa_directly_allocate_scoped_vmem: F; bytes_for_msa_to_allocate: 100663296
I0913 01:12:22.545409     532 2a886c8_compiler_base.cc:10004] BACKEND_PASSES stage duration: 3.8735975ms
I0913 01:12:22.548708     532 2a886c8_compiler_base.cc:3644] CODE_GENERATION stage duration: 3.2645395ms
I0913 01:12:22.548775     532 isa_program_util_common.cc:486] (HLO module jit_add): Executable fingerprint:78465c85b284bf96a10df0b01994c30cf1e4dc5def0c0f8e9cc351d9daac30c9
I0913 01:12:22.548780     532 isa_program_util_common.cc:490] (HLO module jit_add): Executable fingerprint (including data segments):065577814f102b490d83a70d251faa8304a068abc3836129f34644a965300a4a
I0913 01:12:22.548782     532 isa_program_util_common.cc:493] (HLO module jit_add): Host transfer fingerprint:e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855
I0913 01:12:22.548864     141 2a886c8_compiler_base.cc:7452] END_TO_END stage duration: 10.57460625ms
I0913 01:12:22.835397     141 2a886c8_compiler_base.cc:7068] HLO_PASSES stage duration: 2.796821ms
I0913 01:12:22.835933   25451 memory_space_assignment_util.cc:632] MSA Vmem breakdown: default scoped vmem (from flag): 33554432; does_msa_directly_allocate_scoped_vmem: F; bytes_for_msa_to_allocate: 100663296
I0913 01:12:22.839447     532 2a886c8_compiler_base.cc:10004] BACKEND_PASSES stage duration: 3.721408ms
I0913 01:12:22.843033     532 2a886c8_compiler_base.cc:3644] CODE_GENERATION stage duration: 3.53942875ms
I0913 01:12:22.843104     532 isa_program_util_common.cc:486] (HLO module jit_add): Executable fingerprint:7b9fe1cc59a47b013d46dc01380c53856ad6dc42a9c99284eeaeab378be57ba0
I0913 01:12:22.843110     532 isa_program_util_common.cc:490] (HLO module jit_add): Executable fingerprint (including data segments):a5fb3e5ed7286c5866fabf56bfe5a61c4ebdac5ba03e5232f1456b303ad392ab
I0913 01:12:22.843112     532 isa_program_util_common.cc:493] (HLO module jit_add): Host transfer fingerprint:e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855
I0913 01:12:22.843259     141 2a886c8_compiler_base.cc:7452] END_TO_END stage duration: 10.69745575ms
I0913 01:12:23.042052     141 2a886c8_compiler_base.cc:7068] HLO_PASSES stage duration: 2.833731ms
I0913 01:12:23.042570   25450 memory_space_assignment_util.cc:632] MSA Vmem breakdown: default scoped vmem (from flag): 33554432; does_msa_directly_allocate_scoped_vmem: F; bytes_for_msa_to_allocate: 100663296
I0913 01:12:23.046241     532 2a886c8_compiler_base.cc:10004] BACKEND_PASSES stage duration: 3.86042775ms
I0913 01:12:23.049668     532 2a886c8_compiler_base.cc:3644] CODE_GENERATION stage duration: 3.39415925ms
I0913 01:12:23.049727     532 isa_program_util_common.cc:486] (HLO module jit__where): Executable fingerprint:bba8144e11df93bde7e6182551118e41be2b23a9d245ffb22c5ae292b9b8d114
I0913 01:12:23.049732     532 isa_program_util_common.cc:490] (HLO module jit__where): Executable fingerprint (including data segments):989ea404c1fb3ec56a51afc857ee2f25188fd910aaa9286d5a98de09eada576f
I0913 01:12:23.049734     532 isa_program_util_common.cc:493] (HLO module jit__where): Host transfer fingerprint:e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855
I0913 01:12:23.049820     141 2a886c8_compiler_base.cc:7452] END_TO_END stage duration: 10.642096ms
completed step: 0, seconds: 27.213, TFLOP/s/device: 3.631, Tokens/s/device: 75.258, total_weights: 24263, loss: 2.533
To see full metrics 'tensorboard --logdir=/gcs-dir/maxtext-output/runner_llama3.1_8b/tensorboard/'
I0913 01:12:24.422153     792 session_master.cc:211] Worker Address: maxtext-vlp16-default-slice-0-2.maxtext-vlp16-default:8471
I0913 01:12:24.422197     792 session_master.cc:211] Worker Address: maxtext-vlp16-default-slice-0-0.maxtext-vlp16-default:8471
I0913 01:12:24.422199     792 session_master.cc:211] Worker Address: maxtext-vlp16-default-slice-0-1.maxtext-vlp16-default:8471
I0913 01:12:24.422201     792 session_master.cc:211] Worker Address: maxtext-vlp16-default-slice-0-3.maxtext-vlp16-default:8471
completed step: 1, seconds: 3.937, TFLOP/s/device: 25.102, Tokens/s/device: 520.258, total_weights: 25961, loss: 2.367
completed step: 2, seconds: 1.823, TFLOP/s/device: 54.217, Tokens/s/device: 1123.692, total_weights: 26807, loss: 2.505
completed step: 3, seconds: 1.223, TFLOP/s/device: 80.816, Tokens/s/device: 1674.969, total_weights: 26793, loss: 2.279
completed step: 4, seconds: 1.831, TFLOP/s/device: 53.970, Tokens/s/device: 1118.570, total_weights: 27473, loss: 2.465
completed step: 5, seconds: 1.152, TFLOP/s/device: 85.765, Tokens/s/device: 1777.549, total_weights: 26763, loss: 2.339
completed step: 6, seconds: 0.509, TFLOP/s/device: 193.976, Tokens/s/device: 4020.290, total_weights: 26589, loss: 2.350
completed step: 7, seconds: 0.510, TFLOP/s/device: 193.909, Tokens/s/device: 4018.917, total_weights: 26809, loss: 2.755
completed step: 8, seconds: 0.511, TFLOP/s/device: 193.554, Tokens/s/device: 4011.549, total_weights: 25447, loss: 2.469
completed step: 9, seconds: 0.510, TFLOP/s/device: 193.912, Tokens/s/device: 4018.964, total_weights: 28017, loss: 2.477
Waiting for step 10 to finish before checkpoint...
Waited 0.5048656463623047 seconds for step 10 to finish before starting checkpointing.
I0913 01:12:40.579025 140416767584064 checkpoint_manager.py:1998] [process=0][thread=MainThread][step=0][wait_until_finished] Waiting for Save Finalize thread (save_finalize) to complete.
I0913 01:12:53.347390 140243807389440 base_pytree_checkpoint_handler.py:114] [process=0] /jax/checkpoint/write/bytes_per_sec: 627.9 MiB/s (total bytes: 22.4 GiB) (time elapsed: 36 seconds) (per-host)
I0913 01:12:53.347526 140243807389440 async_checkpointer.py:87] [process=0][thread=async_save] 3 Handler Commit operations completed.
I0913 01:12:54.548131     792 session_master.cc:211] Worker Address: maxtext-vlp16-default-slice-0-2.maxtext-vlp16-default:8471
I0913 01:12:54.548174     792 session_master.cc:211] Worker Address: maxtext-vlp16-default-slice-0-0.maxtext-vlp16-default:8471
I0913 01:12:54.548177     792 session_master.cc:211] Worker Address: maxtext-vlp16-default-slice-0-1.maxtext-vlp16-default:8471
I0913 01:12:54.548179     792 session_master.cc:211] Worker Address: maxtext-vlp16-default-slice-0-3.maxtext-vlp16-default:8471
I0913 01:13:03.134777 140243807389440 checkpoint.py:226] Read Metadata={'item_handlers': None, 'metrics': {}, 'performance_metrics': {}, 'init_timestamp_nsecs': 1757725936353229830, 'commit_timestamp_nsecs': None, 'custom_metadata': {}} from /gcs-dir/maxtext-output/runner_llama3.1_8b/checkpoints/0.orbax-checkpoint-tmp-0/_CHECKPOINT_METADATA
I0913 01:13:03.322151 140243807389440 array_metadata_store.py:406] [process=0][thread=async_save] Validated ArrayMetadata from all 4 hosts in 0.00017142295837402344 seconds.
I0913 01:13:03.503268 140258448496384 checkpoint.py:245] Updated Metadata={'item_handlers': {'items': 'orbax.checkpoint._src.handlers.pytree_checkpoint_handler.PyTreeCheckpointHandler'}, 'metrics': {}, 'performance_metrics': {}, 'init_timestamp_nsecs': 1757725936353229830, 'commit_timestamp_nsecs': None, 'custom_metadata': {}} to /gcs-dir/maxtext-output/runner_llama3.1_8b/checkpoints/0.orbax-checkpoint-tmp-0/_CHECKPOINT_METADATA
I0913 01:13:04.994209 140243807389440 type_handlers.py:292] Param validation support for Zarr3 will be added later (b/362328389).
I0913 01:13:04.995377 140243807389440 atomicity.py:289] Renaming /gcs-dir/maxtext-output/runner_llama3.1_8b/checkpoints/0.orbax-checkpoint-tmp-0/items.orbax-checkpoint-tmp-1 to /gcs-dir/maxtext-output/runner_llama3.1_8b/checkpoints/0.orbax-checkpoint-tmp-0/items
I0913 01:13:21.757342 140243807389440 atomicity.py:289] Renaming /gcs-dir/maxtext-output/runner_llama3.1_8b/checkpoints/0.orbax-checkpoint-tmp-0 to /gcs-dir/maxtext-output/runner_llama3.1_8b/checkpoints/0
I0913 01:13:24.674297     792 session_master.cc:211] Worker Address: maxtext-vlp16-default-slice-0-2.maxtext-vlp16-default:8471
I0913 01:13:24.674345     792 session_master.cc:211] Worker Address: maxtext-vlp16-default-slice-0-0.maxtext-vlp16-default:8471
I0913 01:13:24.674348     792 session_master.cc:211] Worker Address: maxtext-vlp16-default-slice-0-1.maxtext-vlp16-default:8471
I0913 01:13:24.674349     792 session_master.cc:211] Worker Address: maxtext-vlp16-default-slice-0-3.maxtext-vlp16-default:8471
I0913 01:13:37.024692 140243807389440 atomicity.py:573] [process=0][thread=async_save] Finished saving checkpoint (finalized tmp dir) to `/gcs-dir/maxtext-output/runner_llama3.1_8b/checkpoints/0`.
I0913 01:13:37.024841 140243807389440 async_checkpointer.py:412] Finished asynchronous save (blocking + background) in 81.42 seconds to /gcs-dir/maxtext-output/runner_llama3.1_8b/checkpoints/0
I0913 01:13:37.029332 140243807389440 async_checkpointer.py:143] [process=0][thread=async_save] Background save thread done.
I0913 01:13:37.029498 140242414888704 async_checkpointer.py:266] [process=0][thread=save_finalize] Done with waiting for background save thread=async_save.
I0913 01:13:37.029580 140242414888704 async_checkpointer.py:276] [process=0][thread=save_finalize] No errors found in background save thread=async_save.
I0913 01:13:37.029664 140242414888704 checkpoint_manager.py:2095] [process=0][thread=save_finalize][step=0] CheckpointManager Save Finalize is syncing with other hosts...
I0913 01:13:37.030001 140242414888704 checkpoint_manager.py:2110] [process=0][thread=save_finalize][step=0] CheckpointManager Save Finalize is done on all hosts.
I0913 01:13:37.030207 140416767584064 checkpoint_manager.py:2010] [process=0][thread=MainThread][step=0][wait_until_finished] Done waiting for Save Finalize thread (save_finalize) running at step=0.
I0913 01:13:37.030571 140416767584064 checkpoint_manager.py:1408] [process=0] Saving checkpoint at step 10
I0913 01:13:37.033451 140416767584064 async_checkpointer.py:439] [process=0] Started async saving checkpoint to /gcs-dir/maxtext-output/runner_llama3.1_8b/checkpoints/10.
I0913 01:13:37.074926 140416767584064 replica_slices.py:341] Transferring arrays to host memory with options: use_replica_parallel=True, enable_pinned_host_transfer=False
I0913 01:13:37.088661 140243807389440 atomicity.py:144] Creating tmp directory /gcs-dir/maxtext-output/runner_llama3.1_8b/checkpoints/10.orbax-checkpoint-tmp-2
I0913 01:13:37.304389 140283614320384 atomicity.py:144] Creating tmp directory /gcs-dir/maxtext-output/runner_llama3.1_8b/checkpoints/10.orbax-checkpoint-tmp-2/items.orbax-checkpoint-tmp-3
I0913 01:13:42.180196 140416767584064 base_pytree_checkpoint_handler.py:114] [process=0] /jax/checkpoint/write/blocking_bytes_per_sec: 4.4 GiB/s (total bytes: 22.4 GiB) (time elapsed: 5 seconds) (per-host)
I0913 01:13:42.194228 140259331499776 async_checkpointer.py:77] [process=0][thread=async_save] Background save thread started.
I0913 01:13:42.194554 140416767584064 async_checkpointer.py:548] Finished blocking save in 5.16 seconds. Continuing to save asynchronously to /gcs-dir/maxtext-output/runner_llama3.1_8b/checkpoints/10.
I0913 01:13:42.364880 140416767584064 checkpoint_manager.py:1453] [process=0][thread=MainThread][step=10] Starting CheckpointManager Save Finalize thread=save_finalize
I0913 01:13:42.365369 140259119552256 async_checkpointer.py:258] [process=0][thread=save_finalize] Waiting for background save thread=async_save.
I0913 01:13:42.365584 140416767584064 standard_logger.py:34] {'step': 10, 'event_type': 'save', 'directory': '/gcs-dir/maxtext-output/runner_llama3.1_8b/checkpoints', 'reached_preemption': False, 'preemption_received_at': None, 'synchronous': False, 'wait_for_prev_start_time': 1757725960.5789952, 'wait_for_prev_duration_secs': 56.45134973526001, 'checkpointer_blocking_start_time': 1757726017.030607, 'checkpointer_blocking_duration_secs': 5.1640846729278564, 'get_old_steps_start_time': 1757726022.194708, 'get_old_steps_duration_secs': 4.291534423828125e-06, 'checkpoint_manager_blocking_start_time': 1757725960.5773156, 'checkpoint_manager_blocking_duration_secs': 61.78820729255676}
Started an asynchronous checkpoint save for step 10
completed step: 10, seconds: 62.299, TFLOP/s/device: 1.586, Tokens/s/device: 32.874, total_weights: 26365, loss: 2.399
I0913 01:13:42.487922 140283614320384 array_metadata_store.py:198] [process=0][thread=array_type_handler] Wrote 39 array_metadata.ArrayMetadata to /gcs-dir/maxtext-output/runner_llama3.1_8b/checkpoints/10.orbax-checkpoint-tmp-2/items.orbax-checkpoint-tmp-3/array_metadatas/process_0
completed step: 11, seconds: 0.525, TFLOP/s/device: 188.385, Tokens/s/device: 3904.418, total_weights: 26522, loss: 2.466
completed step: 12, seconds: 0.512, TFLOP/s/device: 192.908, Tokens/s/device: 3998.157, total_weights: 27831, loss: 2.354
completed step: 13, seconds: 0.509, TFLOP/s/device: 194.099, Tokens/s/device: 4022.841, total_weights: 27820, loss: 2.531
completed step: 14, seconds: 0.512, TFLOP/s/device: 193.079, Tokens/s/device: 4001.704, total_weights: 28819, loss: 2.506
completed step: 15, seconds: 0.526, TFLOP/s/device: 187.940, Tokens/s/device: 3895.188, total_weights: 27769, loss: 2.556
completed step: 16, seconds: 0.510, TFLOP/s/device: 193.812, Tokens/s/device: 4016.907, total_weights: 26781, loss: 2.409
completed step: 17, seconds: 0.516, TFLOP/s/device: 191.642, Tokens/s/device: 3971.925, total_weights: 28372, loss: 2.660
completed step: 18, seconds: 0.511, TFLOP/s/device: 193.544, Tokens/s/device: 4011.337, total_weights: 28369, loss: 2.363
completed step: 19, seconds: 0.515, TFLOP/s/device: 191.884, Tokens/s/device: 3976.931, total_weights: 29418, loss: 2.382
Waiting for step 20 to finish before checkpoint...
Waited 0.504664421081543 seconds for step 20 to finish before starting checkpointing.
I0913 01:13:47.555780 140416767584064 checkpoint_manager.py:1998] [process=0][thread=MainThread][step=10][wait_until_finished] Waiting for Save Finalize thread (save_finalize) to complete.
I0913 01:13:54.800376     792 session_master.cc:211] Worker Address: maxtext-vlp16-default-slice-0-2.maxtext-vlp16-default:8471
I0913 01:13:54.800424     792 session_master.cc:211] Worker Address: maxtext-vlp16-default-slice-0-0.maxtext-vlp16-default:8471
I0913 01:13:54.800427     792 session_master.cc:211] Worker Address: maxtext-vlp16-default-slice-0-1.maxtext-vlp16-default:8471
I0913 01:13:54.800429     792 session_master.cc:211] Worker Address: maxtext-vlp16-default-slice-0-3.maxtext-vlp16-default:8471
I0913 01:14:15.581664 140259331499776 base_pytree_checkpoint_handler.py:114] [process=0] /jax/checkpoint/write/bytes_per_sec: 596.6 MiB/s (total bytes: 22.4 GiB) (time elapsed: 38 seconds) (per-host)
I0913 01:14:15.581799 140259331499776 async_checkpointer.py:87] [process=0][thread=async_save] 3 Handler Commit operations completed.
I0913 01:14:23.926585 140259331499776 array_metadata_store.py:406] [process=0][thread=async_save] Validated ArrayMetadata from all 4 hosts in 0.0001690387725830078 seconds.
I0913 01:14:24.947300     792 session_master.cc:211] Worker Address: maxtext-vlp16-default-slice-0-2.maxtext-vlp16-default:8471
I0913 01:14:24.947342     792 session_master.cc:211] Worker Address: maxtext-vlp16-default-slice-0-0.maxtext-vlp16-default:8471
I0913 01:14:24.947344     792 session_master.cc:211] Worker Address: maxtext-vlp16-default-slice-0-1.maxtext-vlp16-default:8471
I0913 01:14:24.947346     792 session_master.cc:211] Worker Address: maxtext-vlp16-default-slice-0-3.maxtext-vlp16-default:8471
I0913 01:14:25.550485 140259331499776 type_handlers.py:292] Param validation support for Zarr3 will be added later (b/362328389).
I0913 01:14:25.551621 140259331499776 atomicity.py:289] Renaming /gcs-dir/maxtext-output/runner_llama3.1_8b/checkpoints/10.orbax-checkpoint-tmp-2/items.orbax-checkpoint-tmp-3 to /gcs-dir/maxtext-output/runner_llama3.1_8b/checkpoints/10.orbax-checkpoint-tmp-2/items
I0913 01:14:43.317768 140259331499776 atomicity.py:289] Renaming /gcs-dir/maxtext-output/runner_llama3.1_8b/checkpoints/10.orbax-checkpoint-tmp-2 to /gcs-dir/maxtext-output/runner_llama3.1_8b/checkpoints/10
I0913 01:14:55.073196     792 session_master.cc:211] Worker Address: maxtext-vlp16-default-slice-0-2.maxtext-vlp16-default:8471
I0913 01:14:55.073241     792 session_master.cc:211] Worker Address: maxtext-vlp16-default-slice-0-0.maxtext-vlp16-default:8471
I0913 01:14:55.073244     792 session_master.cc:211] Worker Address: maxtext-vlp16-default-slice-0-1.maxtext-vlp16-default:8471
I0913 01:14:55.073246     792 session_master.cc:211] Worker Address: maxtext-vlp16-default-slice-0-3.maxtext-vlp16-default:8471
I0913 01:15:01.876613 140259331499776 atomicity.py:573] [process=0][thread=async_save] Finished saving checkpoint (finalized tmp dir) to `/gcs-dir/maxtext-output/runner_llama3.1_8b/checkpoints/10`.
I0913 01:15:01.876762 140259331499776 async_checkpointer.py:412] Finished asynchronous save (blocking + background) in 84.85 seconds to /gcs-dir/maxtext-output/runner_llama3.1_8b/checkpoints/10
I0913 01:15:01.877573 140259331499776 async_checkpointer.py:143] [process=0][thread=async_save] Background save thread done.
I0913 01:15:01.877815 140259119552256 async_checkpointer.py:266] [process=0][thread=save_finalize] Done with waiting for background save thread=async_save.
I0913 01:15:01.877955 140259119552256 async_checkpointer.py:276] [process=0][thread=save_finalize] No errors found in background save thread=async_save.
I0913 01:15:01.878047 140259119552256 checkpoint_manager.py:2095] [process=0][thread=save_finalize][step=10] CheckpointManager Save Finalize is syncing with other hosts...
I0913 01:15:01.890473 140259119552256 checkpoint_manager.py:2110] [process=0][thread=save_finalize][step=10] CheckpointManager Save Finalize is done on all hosts.
I0913 01:15:01.890677 140416767584064 checkpoint_manager.py:2010] [process=0][thread=MainThread][step=10][wait_until_finished] Done waiting for Save Finalize thread (save_finalize) running at step=10.
I0913 01:15:01.891048 140416767584064 checkpoint_manager.py:1408] [process=0] Saving checkpoint at step 20
I0913 01:15:01.903781 140416767584064 async_checkpointer.py:439] [process=0] Started async saving checkpoint to /gcs-dir/maxtext-output/runner_llama3.1_8b/checkpoints/20.
I0913 01:15:01.953143 140416767584064 replica_slices.py:341] Transferring arrays to host memory with options: use_replica_parallel=True, enable_pinned_host_transfer=False
I0913 01:15:01.972048 140259331499776 atomicity.py:144] Creating tmp directory /gcs-dir/maxtext-output/runner_llama3.1_8b/checkpoints/20.orbax-checkpoint-tmp-4
I0913 01:15:02.175189 140251995199232 atomicity.py:144] Creating tmp directory /gcs-dir/maxtext-output/runner_llama3.1_8b/checkpoints/20.orbax-checkpoint-tmp-4/items.orbax-checkpoint-tmp-5
I0913 01:15:06.215741 140416767584064 base_pytree_checkpoint_handler.py:114] [process=0] /jax/checkpoint/write/blocking_bytes_per_sec: 5.3 GiB/s (total bytes: 22.4 GiB) (time elapsed: 4 seconds) (per-host)
I0913 01:15:06.238196 140259331499776 async_checkpointer.py:77] [process=0][thread=async_save] Background save thread started.
I0913 01:15:06.239493 140416767584064 async_checkpointer.py:548] Finished blocking save in 4.35 seconds. Continuing to save asynchronously to /gcs-dir/maxtext-output/runner_llama3.1_8b/checkpoints/20.
I0913 01:15:06.556939 140251995199232 array_metadata_store.py:198] [process=0][thread=array_type_handler] Wrote 39 array_metadata.ArrayMetadata to /gcs-dir/maxtext-output/runner_llama3.1_8b/checkpoints/20.orbax-checkpoint-tmp-4/items.orbax-checkpoint-tmp-5/array_metadatas/process_0
I0913 01:15:25.199595     792 session_master.cc:211] Worker Address: maxtext-vlp16-default-slice-0-2.maxtext-vlp16-default:8471
I0913 01:15:25.199641     792 session_master.cc:211] Worker Address: maxtext-vlp16-default-slice-0-0.maxtext-vlp16-default:8471
I0913 01:15:25.199643     792 session_master.cc:211] Worker Address: maxtext-vlp16-default-slice-0-1.maxtext-vlp16-default:8471
I0913 01:15:25.199645     792 session_master.cc:211] Worker Address: maxtext-vlp16-default-slice-0-3.maxtext-vlp16-default:8471
I0913 01:15:50.384536 140259331499776 base_pytree_checkpoint_handler.py:114] [process=0] /jax/checkpoint/write/bytes_per_sec: 474.3 MiB/s (total bytes: 22.4 GiB) (time elapsed: 48 seconds) (per-host)
I0913 01:15:50.384657 140259331499776 async_checkpointer.py:87] [process=0][thread=async_save] 3 Handler Commit operations completed.
I0913 01:15:55.325863     792 session_master.cc:211] Worker Address: maxtext-vlp16-default-slice-0-2.maxtext-vlp16-default:8471
I0913 01:15:55.325909     792 session_master.cc:211] Worker Address: maxtext-vlp16-default-slice-0-0.maxtext-vlp16-default:8471
I0913 01:15:55.325912     792 session_master.cc:211] Worker Address: maxtext-vlp16-default-slice-0-1.maxtext-vlp16-default:8471
I0913 01:15:55.325913     792 session_master.cc:211] Worker Address: maxtext-vlp16-default-slice-0-3.maxtext-vlp16-default:8471
I0913 01:16:22.236349 140416767584064 checkpoint_manager.py:1453] [process=0][thread=MainThread][step=20] Starting CheckpointManager Save Finalize thread=save_finalize
I0913 01:16:22.246817 140283622713088 async_checkpointer.py:258] [process=0][thread=save_finalize] Waiting for background save thread=async_save.
I0913 01:16:22.247029 140416767584064 standard_logger.py:34] {'step': 20, 'event_type': 'save', 'directory': '/gcs-dir/maxtext-output/runner_llama3.1_8b/checkpoints', 'reached_preemption': False, 'preemption_received_at': None, 'synchronous': False, 'wait_for_prev_start_time': 1757726027.555752, 'wait_for_prev_duration_secs': 74.3350670337677, 'checkpointer_blocking_start_time': 1757726101.8910873, 'checkpointer_blocking_duration_secs': 4.3485424518585205, 'get_old_steps_start_time': 1757726106.2396472, 'get_old_steps_duration_secs': 4.5299530029296875e-06, 'checkpoint_manager_blocking_start_time': 1757726027.5541892, 'checkpoint_manager_blocking_duration_secs': 154.6927616596222}
Started an asynchronous checkpoint save for step 20
completed step: 20, seconds: 155.204, TFLOP/s/device: 0.637, Tokens/s/device: 13.196, total_weights: 28754, loss: 2.517
completed step: 21, seconds: 0.510, TFLOP/s/device: 193.876, Tokens/s/device: 4018.223, total_weights: 25329, loss: 2.428
completed step: 22, seconds: 0.512, TFLOP/s/device: 193.092, Tokens/s/device: 4001.985, total_weights: 28422, loss: 2.493
completed step: 23, seconds: 0.517, TFLOP/s/device: 191.300, Tokens/s/device: 3964.843, total_weights: 26259, loss: 2.321
completed step: 24, seconds: 0.510, TFLOP/s/device: 193.830, Tokens/s/device: 4017.270, total_weights: 28672, loss: 2.349
completed step: 25, seconds: 0.510, TFLOP/s/device: 193.873, Tokens/s/device: 4018.168, total_weights: 27960, loss: 2.429
completed step: 26, seconds: 0.510, TFLOP/s/device: 193.819, Tokens/s/device: 4017.041, total_weights: 25706, loss: 2.416
I0913 01:16:25.452078     792 session_master.cc:211] Worker Address: maxtext-vlp16-default-slice-0-2.maxtext-vlp16-default:8471
I0913 01:16:25.452122     792 session_master.cc:211] Worker Address: maxtext-vlp16-default-slice-0-0.maxtext-vlp16-default:8471
I0913 01:16:25.452124     792 session_master.cc:211] Worker Address: maxtext-vlp16-default-slice-0-1.maxtext-vlp16-default:8471
I0913 01:16:25.452126     792 session_master.cc:211] Worker Address: maxtext-vlp16-default-slice-0-3.maxtext-vlp16-default:8471
completed step: 27, seconds: 0.509, TFLOP/s/device: 194.189, Tokens/s/device: 4024.714, total_weights: 24095, loss: 2.442
completed step: 28, seconds: 0.510, TFLOP/s/device: 193.694, Tokens/s/device: 4014.458, total_weights: 25551, loss: 2.438
completed step: 29, seconds: 0.510, TFLOP/s/device: 193.762, Tokens/s/device: 4015.860, total_weights: 24515, loss: 2.486
Waiting for step 30 to finish before checkpoint...
Waited 0.5044188499450684 seconds for step 30 to finish before starting checkpointing.
I0913 01:16:27.385597 140416767584064 checkpoint_manager.py:1998] [process=0][thread=MainThread][step=20][wait_until_finished] Waiting for Save Finalize thread (save_finalize) to complete.
I0913 01:16:47.655937 140259331499776 array_metadata_store.py:406] [process=0][thread=async_save] Validated ArrayMetadata from all 4 hosts in 9.036064147949219e-05 seconds.
I0913 01:16:49.028567 140259331499776 type_handlers.py:292] Param validation support for Zarr3 will be added later (b/362328389).
I0913 01:16:49.029751 140259331499776 atomicity.py:289] Renaming /gcs-dir/maxtext-output/runner_llama3.1_8b/checkpoints/20.orbax-checkpoint-tmp-4/items.orbax-checkpoint-tmp-5 to /gcs-dir/maxtext-output/runner_llama3.1_8b/checkpoints/20.orbax-checkpoint-tmp-4/items
I0913 01:16:55.578112     792 session_master.cc:211] Worker Address: maxtext-vlp16-default-slice-0-2.maxtext-vlp16-default:8471
I0913 01:16:55.578162     792 session_master.cc:211] Worker Address: maxtext-vlp16-default-slice-0-0.maxtext-vlp16-default:8471
I0913 01:16:55.578164     792 session_master.cc:211] Worker Address: maxtext-vlp16-default-slice-0-1.maxtext-vlp16-default:8471
I0913 01:16:55.578166     792 session_master.cc:211] Worker Address: maxtext-vlp16-default-slice-0-3.maxtext-vlp16-default:8471
I0913 01:17:07.360764 140259331499776 atomicity.py:289] Renaming /gcs-dir/maxtext-output/runner_llama3.1_8b/checkpoints/20.orbax-checkpoint-tmp-4 to /gcs-dir/maxtext-output/runner_llama3.1_8b/checkpoints/20
I0913 01:17:25.479580 140259331499776 atomicity.py:573] [process=0][thread=async_save] Finished saving checkpoint (finalized tmp dir) to `/gcs-dir/maxtext-output/runner_llama3.1_8b/checkpoints/20`.
I0913 01:17:25.479725 140259331499776 async_checkpointer.py:412] Finished asynchronous save (blocking + background) in 143.59 seconds to /gcs-dir/maxtext-output/runner_llama3.1_8b/checkpoints/20
I0913 01:17:25.480493 140259331499776 async_checkpointer.py:143] [process=0][thread=async_save] Background save thread done.
I0913 01:17:25.480738 140283622713088 async_checkpointer.py:266] [process=0][thread=save_finalize] Done with waiting for background save thread=async_save.
I0913 01:17:25.480876 140283622713088 async_checkpointer.py:276] [process=0][thread=save_finalize] No errors found in background save thread=async_save.
I0913 01:17:25.480944 140283622713088 checkpoint_manager.py:2095] [process=0][thread=save_finalize][step=20] CheckpointManager Save Finalize is syncing with other hosts...
I0913 01:17:25.482096 140283622713088 checkpoint_manager.py:2110] [process=0][thread=save_finalize][step=20] CheckpointManager Save Finalize is done on all hosts.
I0913 01:17:25.482285 140416767584064 checkpoint_manager.py:2010] [process=0][thread=MainThread][step=20][wait_until_finished] Done waiting for Save Finalize thread (save_finalize) running at step=20.
I0913 01:17:25.482596 140416767584064 checkpoint_manager.py:1408] [process=0] Saving checkpoint at step 30
I0913 01:17:25.486082 140416767584064 async_checkpointer.py:439] [process=0] Started async saving checkpoint to /gcs-dir/maxtext-output/runner_llama3.1_8b/checkpoints/30.
I0913 01:17:25.523393 140416767584064 replica_slices.py:341] Transferring arrays to host memory with options: use_replica_parallel=True, enable_pinned_host_transfer=False
I0913 01:17:25.568205 140259331499776 atomicity.py:144] Creating tmp directory /gcs-dir/maxtext-output/runner_llama3.1_8b/checkpoints/30.orbax-checkpoint-tmp-6
I0913 01:17:25.704384     792 session_master.cc:211] Worker Address: maxtext-vlp16-default-slice-0-2.maxtext-vlp16-default:8471
I0913 01:17:25.704423     792 session_master.cc:211] Worker Address: maxtext-vlp16-default-slice-0-0.maxtext-vlp16-default:8471
I0913 01:17:25.704426     792 session_master.cc:211] Worker Address: maxtext-vlp16-default-slice-0-1.maxtext-vlp16-default:8471
I0913 01:17:25.704428     792 session_master.cc:211] Worker Address: maxtext-vlp16-default-slice-0-3.maxtext-vlp16-default:8471
I0913 01:17:25.773654 140259270428416 atomicity.py:144] Creating tmp directory /gcs-dir/maxtext-output/runner_llama3.1_8b/checkpoints/30.orbax-checkpoint-tmp-6/items.orbax-checkpoint-tmp-7
I0913 01:17:29.984020 140416767584064 base_pytree_checkpoint_handler.py:114] [process=0] /jax/checkpoint/write/blocking_bytes_per_sec: 5.0 GiB/s (total bytes: 22.4 GiB) (time elapsed: 4 seconds) (per-host)
I0913 01:17:30.004349 140259220072192 async_checkpointer.py:77] [process=0][thread=async_save] Background save thread started.
I0913 01:17:30.004593 140416767584064 async_checkpointer.py:548] Finished blocking save in 4.52 seconds. Continuing to save asynchronously to /gcs-dir/maxtext-output/runner_llama3.1_8b/checkpoints/30.
I0913 01:17:30.008279 140416767584064 checkpoint_manager.py:1453] [process=0][thread=MainThread][step=30] Starting CheckpointManager Save Finalize thread=save_finalize
I0913 01:17:30.008810 140259074094848 async_checkpointer.py:258] [process=0][thread=save_finalize] Waiting for background save thread=async_save.
I0913 01:17:30.009057 140416767584064 standard_logger.py:34] {'step': 30, 'event_type': 'save', 'directory': '/gcs-dir/maxtext-output/runner_llama3.1_8b/checkpoints', 'reached_preemption': False, 'preemption_received_at': None, 'synchronous': False, 'wait_for_prev_start_time': 1757726187.3855681, 'wait_for_prev_duration_secs': 58.09685134887695, 'checkpointer_blocking_start_time': 1757726245.4826312, 'checkpointer_blocking_duration_secs': 4.5220818519592285, 'get_old_steps_start_time': 1757726250.004729, 'get_old_steps_duration_secs': 3.5762786865234375e-06, 'checkpoint_manager_blocking_start_time': 1757726187.3840568, 'checkpoint_manager_blocking_duration_secs': 62.624950885772705}
Started an asynchronous checkpoint save for step 30
completed step: 30, seconds: 63.136, TFLOP/s/device: 1.565, Tokens/s/device: 32.438, total_weights: 24471, loss: 2.408
I0913 01:17:30.312252 140259270428416 array_metadata_store.py:198] [process=0][thread=array_type_handler] Wrote 39 array_metadata.ArrayMetadata to /gcs-dir/maxtext-output/runner_llama3.1_8b/checkpoints/30.orbax-checkpoint-tmp-6/items.orbax-checkpoint-tmp-7/array_metadatas/process_0
completed step: 31, seconds: 0.510, TFLOP/s/device: 193.830, Tokens/s/device: 4017.262, total_weights: 25508, loss: 2.453
completed step: 32, seconds: 0.510, TFLOP/s/device: 193.916, Tokens/s/device: 4019.043, total_weights: 27942, loss: 2.522
completed step: 33, seconds: 0.509, TFLOP/s/device: 194.131, Tokens/s/device: 4023.512, total_weights: 26939, loss: 2.349
completed step: 34, seconds: 0.509, TFLOP/s/device: 194.019, Tokens/s/device: 4021.190, total_weights: 26318, loss: 2.466
completed step: 35, seconds: 0.510, TFLOP/s/device: 193.856, Tokens/s/device: 4017.813, total_weights: 28178, loss: 2.333
completed step: 36, seconds: 0.510, TFLOP/s/device: 193.919, Tokens/s/device: 4019.114, total_weights: 29572, loss: 2.540
completed step: 37, seconds: 0.510, TFLOP/s/device: 193.845, Tokens/s/device: 4017.585, total_weights: 25801, loss: 2.402
completed step: 38, seconds: 0.510, TFLOP/s/device: 193.918, Tokens/s/device: 4019.099, total_weights: 27175, loss: 2.485
completed step: 39, seconds: 0.510, TFLOP/s/device: 193.591, Tokens/s/device: 4012.327, total_weights: 26242, loss: 2.623
Waiting for step 40 to finish before checkpoint...
Waited 0.5047757625579834 seconds for step 40 to finish before starting checkpointing.
I0913 01:17:35.138720 140416767584064 checkpoint_manager.py:1998] [process=0][thread=MainThread][step=30][wait_until_finished] Waiting for Save Finalize thread (save_finalize) to complete.
I0913 01:17:55.845274     792 session_master.cc:211] Worker Address: maxtext-vlp16-default-slice-0-2.maxtext-vlp16-default:8471
I0913 01:17:55.845331     792 session_master.cc:211] Worker Address: maxtext-vlp16-default-slice-0-0.maxtext-vlp16-default:8471
I0913 01:17:55.845333     792 session_master.cc:211] Worker Address: maxtext-vlp16-default-slice-0-1.maxtext-vlp16-default:8471
I0913 01:17:55.845335     792 session_master.cc:211] Worker Address: maxtext-vlp16-default-slice-0-3.maxtext-vlp16-default:8471
I0913 01:18:16.222126 140259220072192 base_pytree_checkpoint_handler.py:114] [process=0] /jax/checkpoint/write/bytes_per_sec: 453.1 MiB/s (total bytes: 22.4 GiB) (time elapsed: 50 seconds) (per-host)
I0913 01:18:16.222254 140259220072192 async_checkpointer.py:87] [process=0][thread=async_save] 3 Handler Commit operations completed.
I0913 01:18:16.450343 140259220072192 array_metadata_store.py:406] [process=0][thread=async_save] Validated ArrayMetadata from all 4 hosts in 0.00014066696166992188 seconds.
I0913 01:18:17.914306 140259220072192 type_handlers.py:292] Param validation support for Zarr3 will be added later (b/362328389).
I0913 01:18:17.915518 140259220072192 atomicity.py:289] Renaming /gcs-dir/maxtext-output/runner_llama3.1_8b/checkpoints/30.orbax-checkpoint-tmp-6/items.orbax-checkpoint-tmp-7 to /gcs-dir/maxtext-output/runner_llama3.1_8b/checkpoints/30.orbax-checkpoint-tmp-6/items
I0913 01:18:25.971473     792 session_master.cc:211] Worker Address: maxtext-vlp16-default-slice-0-2.maxtext-vlp16-default:8471
I0913 01:18:25.971517     792 session_master.cc:211] Worker Address: maxtext-vlp16-default-slice-0-0.maxtext-vlp16-default:8471
I0913 01:18:25.971519     792 session_master.cc:211] Worker Address: maxtext-vlp16-default-slice-0-1.maxtext-vlp16-default:8471
I0913 01:18:25.971521     792 session_master.cc:211] Worker Address: maxtext-vlp16-default-slice-0-3.maxtext-vlp16-default:8471
I0913 01:18:35.910518 140259220072192 atomicity.py:289] Renaming /gcs-dir/maxtext-output/runner_llama3.1_8b/checkpoints/30.orbax-checkpoint-tmp-6 to /gcs-dir/maxtext-output/runner_llama3.1_8b/checkpoints/30
I0913 01:18:54.309541 140259220072192 atomicity.py:573] [process=0][thread=async_save] Finished saving checkpoint (finalized tmp dir) to `/gcs-dir/maxtext-output/runner_llama3.1_8b/checkpoints/30`.
I0913 01:18:54.309690 140259220072192 async_checkpointer.py:412] Finished asynchronous save (blocking + background) in 88.83 seconds to /gcs-dir/maxtext-output/runner_llama3.1_8b/checkpoints/30
I0913 01:18:54.310319 140259220072192 async_checkpointer.py:143] [process=0][thread=async_save] Background save thread done.
I0913 01:18:54.310558 140259074094848 async_checkpointer.py:266] [process=0][thread=save_finalize] Done with waiting for background save thread=async_save.
I0913 01:18:54.310702 140259074094848 async_checkpointer.py:276] [process=0][thread=save_finalize] No errors found in background save thread=async_save.
I0913 01:18:54.310769 140259074094848 checkpoint_manager.py:2095] [process=0][thread=save_finalize][step=30] CheckpointManager Save Finalize is syncing with other hosts...
I0913 01:18:54.311793 140259074094848 checkpoint_manager.py:2110] [process=0][thread=save_finalize][step=30] CheckpointManager Save Finalize is done on all hosts.
I0913 01:18:54.311989 140416767584064 checkpoint_manager.py:2010] [process=0][thread=MainThread][step=30][wait_until_finished] Done waiting for Save Finalize thread (save_finalize) running at step=30.
I0913 01:18:54.312373 140416767584064 checkpoint_manager.py:1408] [process=0] Saving checkpoint at step 40
I0913 01:18:54.315498 140416767584064 async_checkpointer.py:439] [process=0] Started async saving checkpoint to /gcs-dir/maxtext-output/runner_llama3.1_8b/checkpoints/40.
I0913 01:18:54.352575 140416767584064 replica_slices.py:341] Transferring arrays to host memory with options: use_replica_parallel=True, enable_pinned_host_transfer=False
I0913 01:18:54.368505 140259220072192 atomicity.py:144] Creating tmp directory /gcs-dir/maxtext-output/runner_llama3.1_8b/checkpoints/40.orbax-checkpoint-tmp-8
I0913 01:18:54.574178 140248449263360 atomicity.py:144] Creating tmp directory /gcs-dir/maxtext-output/runner_llama3.1_8b/checkpoints/40.orbax-checkpoint-tmp-8/items.orbax-checkpoint-tmp-9
I0913 01:18:56.097850     792 session_master.cc:211] Worker Address: maxtext-vlp16-default-slice-0-2.maxtext-vlp16-default:8471
I0913 01:18:56.097890     792 session_master.cc:211] Worker Address: maxtext-vlp16-default-slice-0-0.maxtext-vlp16-default:8471
I0913 01:18:56.097892     792 session_master.cc:211] Worker Address: maxtext-vlp16-default-slice-0-1.maxtext-vlp16-default:8471
I0913 01:18:56.097894     792 session_master.cc:211] Worker Address: maxtext-vlp16-default-slice-0-3.maxtext-vlp16-default:8471
I0913 01:18:59.218778 140416767584064 base_pytree_checkpoint_handler.py:114] [process=0] /jax/checkpoint/write/blocking_bytes_per_sec: 4.6 GiB/s (total bytes: 22.4 GiB) (time elapsed: 4 seconds) (per-host)
I0913 01:18:59.227054 140283614320384 async_checkpointer.py:77] [process=0][thread=async_save] Background save thread started.
I0913 01:18:59.227262 140416767584064 async_checkpointer.py:548] Finished blocking save in 4.91 seconds. Continuing to save asynchronously to /gcs-dir/maxtext-output/runner_llama3.1_8b/checkpoints/40.
I0913 01:18:59.241540 140416767584064 checkpoint_manager.py:1453] [process=0][thread=MainThread][step=40] Starting CheckpointManager Save Finalize thread=save_finalize
I0913 01:18:59.241856 140259236869888 async_checkpointer.py:258] [process=0][thread=save_finalize] Waiting for background save thread=async_save.
I0913 01:18:59.242244 140416767584064 standard_logger.py:34] {'step': 40, 'event_type': 'save', 'directory': '/gcs-dir/maxtext-output/runner_llama3.1_8b/checkpoints', 'reached_preemption': False, 'preemption_received_at': None, 'synchronous': False, 'wait_for_prev_start_time': 1757726255.1386898, 'wait_for_prev_duration_secs': 79.17343163490295, 'checkpointer_blocking_start_time': 1757726334.3124096, 'checkpointer_blocking_duration_secs': 4.914987087249756, 'get_old_steps_start_time': 1757726339.2274146, 'get_old_steps_duration_secs': 3.5762786865234375e-06, 'checkpoint_manager_blocking_start_time': 1757726255.1370265, 'checkpoint_manager_blocking_duration_secs': 84.10515236854553}
Started an asynchronous checkpoint save for step 40
completed step: 40, seconds: 84.617, TFLOP/s/device: 1.168, Tokens/s/device: 24.203, total_weights: 27862, loss: 2.434
I0913 01:18:59.539491 140248449263360 array_metadata_store.py:198] [process=0][thread=array_type_handler] Wrote 39 array_metadata.ArrayMetadata to /gcs-dir/maxtext-output/runner_llama3.1_8b/checkpoints/40.orbax-checkpoint-tmp-8/items.orbax-checkpoint-tmp-9/array_metadatas/process_0
completed step: 41, seconds: 0.509, TFLOP/s/device: 193.952, Tokens/s/device: 4019.793, total_weights: 28290, loss: 2.406
completed step: 42, seconds: 0.511, TFLOP/s/device: 193.349, Tokens/s/device: 4007.310, total_weights: 27024, loss: 2.470
completed step: 43, seconds: 0.510, TFLOP/s/device: 193.761, Tokens/s/device: 4015.836, total_weights: 25737, loss: 2.433
completed step: 44, seconds: 0.507, TFLOP/s/device: 194.790, Tokens/s/device: 4037.162, total_weights: 26741, loss: 2.369
completed step: 45, seconds: 0.506, TFLOP/s/device: 195.124, Tokens/s/device: 4044.082, total_weights: 30206, loss: 2.429
completed step: 46, seconds: 0.509, TFLOP/s/device: 194.085, Tokens/s/device: 4022.556, total_weights: 27164, loss: 2.441
completed step: 47, seconds: 0.509, TFLOP/s/device: 193.984, Tokens/s/device: 4020.471, total_weights: 28741, loss: 2.415
completed step: 48, seconds: 0.509, TFLOP/s/device: 193.967, Tokens/s/device: 4020.108, total_weights: 23873, loss: 2.402
completed step: 49, seconds: 0.510, TFLOP/s/device: 193.843, Tokens/s/device: 4017.537, total_weights: 27271, loss: 2.401
Waiting for step 49 to finish before checkpoint...
Waited 0.0003788471221923828 seconds for step 49 to finish before starting checkpointing.
I0913 01:19:03.858654 140416767584064 checkpoint_manager.py:1998] [process=0][thread=MainThread][step=40][wait_until_finished] Waiting for Save Finalize thread (save_finalize) to complete.
I0913 01:19:26.224354     792 session_master.cc:211] Worker Address: maxtext-vlp16-default-slice-0-2.maxtext-vlp16-default:8471
I0913 01:19:26.224402     792 session_master.cc:211] Worker Address: maxtext-vlp16-default-slice-0-0.maxtext-vlp16-default:8471
I0913 01:19:26.224404     792 session_master.cc:211] Worker Address: maxtext-vlp16-default-slice-0-1.maxtext-vlp16-default:8471
I0913 01:19:26.224406     792 session_master.cc:211] Worker Address: maxtext-vlp16-default-slice-0-3.maxtext-vlp16-default:8471
I0913 01:19:28.933070 140283614320384 base_pytree_checkpoint_handler.py:114] [process=0] /jax/checkpoint/write/bytes_per_sec: 664.3 MiB/s (total bytes: 22.4 GiB) (time elapsed: 34 seconds) (per-host)
I0913 01:19:28.933205 140283614320384 async_checkpointer.py:87] [process=0][thread=async_save] 3 Handler Commit operations completed.
I0913 01:19:29.089944 140283614320384 array_metadata_store.py:406] [process=0][thread=async_save] Validated ArrayMetadata from all 4 hosts in 0.00015592575073242188 seconds.
I0913 01:19:30.488526 140283614320384 type_handlers.py:292] Param validation support for Zarr3 will be added later (b/362328389).
I0913 01:19:30.489716 140283614320384 atomicity.py:289] Renaming /gcs-dir/maxtext-output/runner_llama3.1_8b/checkpoints/40.orbax-checkpoint-tmp-8/items.orbax-checkpoint-tmp-9 to /gcs-dir/maxtext-output/runner_llama3.1_8b/checkpoints/40.orbax-checkpoint-tmp-8/items
I0913 01:19:48.050318 140283614320384 atomicity.py:289] Renaming /gcs-dir/maxtext-output/runner_llama3.1_8b/checkpoints/40.orbax-checkpoint-tmp-8 to /gcs-dir/maxtext-output/runner_llama3.1_8b/checkpoints/40
I0913 01:19:56.350655     792 session_master.cc:211] Worker Address: maxtext-vlp16-default-slice-0-2.maxtext-vlp16-default:8471
I0913 01:19:56.350701     792 session_master.cc:211] Worker Address: maxtext-vlp16-default-slice-0-0.maxtext-vlp16-default:8471
I0913 01:19:56.350703     792 session_master.cc:211] Worker Address: maxtext-vlp16-default-slice-0-1.maxtext-vlp16-default:8471
I0913 01:19:56.350705     792 session_master.cc:211] Worker Address: maxtext-vlp16-default-slice-0-3.maxtext-vlp16-default:8471
I0913 01:20:06.180943 140283614320384 atomicity.py:573] [process=0][thread=async_save] Finished saving checkpoint (finalized tmp dir) to `/gcs-dir/maxtext-output/runner_llama3.1_8b/checkpoints/40`.
I0913 01:20:06.181128 140283614320384 async_checkpointer.py:412] Finished asynchronous save (blocking + background) in 71.87 seconds to /gcs-dir/maxtext-output/runner_llama3.1_8b/checkpoints/40
I0913 01:20:06.181890 140283614320384 async_checkpointer.py:143] [process=0][thread=async_save] Background save thread done.
I0913 01:20:06.182169 140259236869888 async_checkpointer.py:266] [process=0][thread=save_finalize] Done with waiting for background save thread=async_save.
I0913 01:20:06.182337 140259236869888 async_checkpointer.py:276] [process=0][thread=save_finalize] No errors found in background save thread=async_save.
I0913 01:20:06.182406 140259236869888 checkpoint_manager.py:2095] [process=0][thread=save_finalize][step=40] CheckpointManager Save Finalize is syncing with other hosts...
I0913 01:20:06.183375 140259236869888 checkpoint_manager.py:2110] [process=0][thread=save_finalize][step=40] CheckpointManager Save Finalize is done on all hosts.
I0913 01:20:06.183624 140416767584064 checkpoint_manager.py:2010] [process=0][thread=MainThread][step=40][wait_until_finished] Done waiting for Save Finalize thread (save_finalize) running at step=40.
I0913 01:20:06.183992 140416767584064 checkpoint_manager.py:1408] [process=0] Saving checkpoint at step 49
I0913 01:20:06.186917 140416767584064 async_checkpointer.py:439] [process=0] Started async saving checkpoint to /gcs-dir/maxtext-output/runner_llama3.1_8b/checkpoints/49.
I0913 01:20:06.220684 140416767584064 replica_slices.py:341] Transferring arrays to host memory with options: use_replica_parallel=True, enable_pinned_host_transfer=False
I0913 01:20:06.249619 140283614320384 atomicity.py:144] Creating tmp directory /gcs-dir/maxtext-output/runner_llama3.1_8b/checkpoints/49.orbax-checkpoint-tmp-10
I0913 01:20:06.464222 140283622713088 atomicity.py:144] Creating tmp directory /gcs-dir/maxtext-output/runner_llama3.1_8b/checkpoints/49.orbax-checkpoint-tmp-10/items.orbax-checkpoint-tmp-11
I0913 01:20:09.498428 140416767584064 base_pytree_checkpoint_handler.py:114] [process=0] /jax/checkpoint/write/blocking_bytes_per_sec: 6.8 GiB/s (total bytes: 22.4 GiB) (time elapsed: 3 seconds) (per-host)
I0913 01:20:09.518919 140259228477184 async_checkpointer.py:77] [process=0][thread=async_save] Background save thread started.
I0913 01:20:09.519384 140416767584064 async_checkpointer.py:548] Finished blocking save in 3.34 seconds. Continuing to save asynchronously to /gcs-dir/maxtext-output/runner_llama3.1_8b/checkpoints/49.
I0913 01:20:09.805953 140283622713088 array_metadata_store.py:198] [process=0][thread=array_type_handler] Wrote 39 array_metadata.ArrayMetadata to /gcs-dir/maxtext-output/runner_llama3.1_8b/checkpoints/49.orbax-checkpoint-tmp-10/items.orbax-checkpoint-tmp-11/array_metadatas/process_0
I0913 01:20:10.254398 140416767584064 checkpoint_manager.py:1453] [process=0][thread=MainThread][step=49] Starting CheckpointManager Save Finalize thread=save_finalize
I0913 01:20:10.254868 140259074094848 async_checkpointer.py:258] [process=0][thread=save_finalize] Waiting for background save thread=async_save.
I0913 01:20:10.255105 140416767584064 standard_logger.py:34] {'step': 49, 'event_type': 'save', 'directory': '/gcs-dir/maxtext-output/runner_llama3.1_8b/checkpoints', 'reached_preemption': False, 'preemption_received_at': None, 'synchronous': False, 'wait_for_prev_start_time': 1757726343.8586078, 'wait_for_prev_duration_secs': 62.32514929771423, 'checkpointer_blocking_start_time': 1757726406.184029, 'checkpointer_blocking_duration_secs': 3.335477828979492, 'get_old_steps_start_time': 1757726409.5195234, 'get_old_steps_duration_secs': 3.5762786865234375e-06, 'checkpoint_manager_blocking_start_time': 1757726343.8568282, 'checkpoint_manager_blocking_duration_secs': 66.39821672439575}
Started an asynchronous checkpoint save for step 49
I0913 01:20:10.255265 140416767584064 checkpoint_manager.py:1998] [process=0][thread=MainThread][step=49][wait_until_finished] Waiting for Save Finalize thread (save_finalize) to complete.
I0913 01:20:26.476949     792 session_master.cc:211] Worker Address: maxtext-vlp16-default-slice-0-2.maxtext-vlp16-default:8471
I0913 01:20:26.477010     792 session_master.cc:211] Worker Address: maxtext-vlp16-default-slice-0-0.maxtext-vlp16-default:8471
I0913 01:20:26.477012     792 session_master.cc:211] Worker Address: maxtext-vlp16-default-slice-0-1.maxtext-vlp16-default:8471
I0913 01:20:26.477014     792 session_master.cc:211] Worker Address: maxtext-vlp16-default-slice-0-3.maxtext-vlp16-default:8471
I0913 01:20:37.999717 140259228477184 base_pytree_checkpoint_handler.py:114] [process=0] /jax/checkpoint/write/bytes_per_sec: 722.9 MiB/s (total bytes: 22.4 GiB) (time elapsed: 31 seconds) (per-host)
I0913 01:20:37.999834 140259228477184 async_checkpointer.py:87] [process=0][thread=async_save] 3 Handler Commit operations completed.
I0913 01:20:55.951422 140259228477184 array_metadata_store.py:406] [process=0][thread=async_save] Validated ArrayMetadata from all 4 hosts in 0.00015306472778320312 seconds.
I0913 01:20:56.602982     792 session_master.cc:211] Worker Address: maxtext-vlp16-default-slice-0-2.maxtext-vlp16-default:8471
I0913 01:20:56.603025     792 session_master.cc:211] Worker Address: maxtext-vlp16-default-slice-0-0.maxtext-vlp16-default:8471
I0913 01:20:56.603027     792 session_master.cc:211] Worker Address: maxtext-vlp16-default-slice-0-1.maxtext-vlp16-default:8471
I0913 01:20:56.603029     792 session_master.cc:211] Worker Address: maxtext-vlp16-default-slice-0-3.maxtext-vlp16-default:8471
I0913 01:20:57.422412 140259228477184 type_handlers.py:292] Param validation support for Zarr3 will be added later (b/362328389).
I0913 01:20:57.423591 140259228477184 atomicity.py:289] Renaming /gcs-dir/maxtext-output/runner_llama3.1_8b/checkpoints/49.orbax-checkpoint-tmp-10/items.orbax-checkpoint-tmp-11 to /gcs-dir/maxtext-output/runner_llama3.1_8b/checkpoints/49.orbax-checkpoint-tmp-10/items
I0913 01:21:15.114416 140259228477184 atomicity.py:289] Renaming /gcs-dir/maxtext-output/runner_llama3.1_8b/checkpoints/49.orbax-checkpoint-tmp-10 to /gcs-dir/maxtext-output/runner_llama3.1_8b/checkpoints/49
I0913 01:21:26.728932     792 session_master.cc:211] Worker Address: maxtext-vlp16-default-slice-0-2.maxtext-vlp16-default:8471
I0913 01:21:26.729007     792 session_master.cc:211] Worker Address: maxtext-vlp16-default-slice-0-0.maxtext-vlp16-default:8471
I0913 01:21:26.729010     792 session_master.cc:211] Worker Address: maxtext-vlp16-default-slice-0-1.maxtext-vlp16-default:8471
I0913 01:21:26.729012     792 session_master.cc:211] Worker Address: maxtext-vlp16-default-slice-0-3.maxtext-vlp16-default:8471
I0913 01:21:33.480635 140259228477184 atomicity.py:573] [process=0][thread=async_save] Finished saving checkpoint (finalized tmp dir) to `/gcs-dir/maxtext-output/runner_llama3.1_8b/checkpoints/49`.
I0913 01:21:33.480781 140259228477184 async_checkpointer.py:412] Finished asynchronous save (blocking + background) in 87.30 seconds to /gcs-dir/maxtext-output/runner_llama3.1_8b/checkpoints/49
I0913 01:21:33.481537 140259228477184 async_checkpointer.py:143] [process=0][thread=async_save] Background save thread done.
I0913 01:21:33.481775 140259074094848 async_checkpointer.py:266] [process=0][thread=save_finalize] Done with waiting for background save thread=async_save.
I0913 01:21:33.481916 140259074094848 async_checkpointer.py:276] [process=0][thread=save_finalize] No errors found in background save thread=async_save.
I0913 01:21:33.481998 140259074094848 checkpoint_manager.py:2095] [process=0][thread=save_finalize][step=49] CheckpointManager Save Finalize is syncing with other hosts...
I0913 01:21:33.482958 140259074094848 checkpoint_manager.py:2110] [process=0][thread=save_finalize][step=49] CheckpointManager Save Finalize is done on all hosts.
I0913 01:21:33.483174 140416767584064 checkpoint_manager.py:2010] [process=0][thread=MainThread][step=49][wait_until_finished] Done waiting for Save Finalize thread (save_finalize) running at step=49.
2025-09-13 01:21:33.822898: I external/xla/xla/tsl/distributed_runtime/preemption/preemption_sync_manager.cc:204] Shutting down PreemptionSyncManager...
2025-09-13 01:21:33.823034: I external/xla/xla/tsl/distributed_runtime/preemption/preemption_sync_manager.cc:212] PreemptionSyncManager shut down.
2025-09-13 01:21:33.823039: I external/xla/xla/tsl/distributed_runtime/preemption/preemption_sync_manager.cc:199] PreemptionSyncManager already shut down
2025-09-13 01:21:33.823055: I external/xla/xla/tsl/distributed_runtime/preemption/preemption_sync_manager.cc:144] Cancelled call to retrieve preemption notice. This is expected upon program shutdown.
2025-09-13 01:21:33.823129: I external/xla/xla/tsl/distributed_runtime/preemption/preemption_sync_manager.cc:117] Preemption sync protocol cancelled by notifier: CANCELLED: Preemption notifier is being deleted.. This is expected during program shutdown.
2025-09-13 01:21:33.823283: I external/xla/xla/pjrt/distributed/client.cc:139] Distributed task shutdown initiated.
2025-09-13 01:21:33.823290: I external/xla/xla/tsl/distributed_runtime/coordination/coordination_service_agent.cc:612] Coordination agent has initiated Shutdown().
2025-09-13 01:21:33.823556: I external/xla/xla/tsl/distributed_runtime/coordination/coordination_service.cc:1686] Shutdown barrier in coordination service has passed.
2025-09-13 01:21:33.823593: I external/xla/xla/tsl/distributed_runtime/coordination/coordination_service_agent.cc:633] Coordination agent has successfully shut down.
2025-09-13 01:21:33.823597: I external/xla/xla/tsl/distributed_runtime/coordination/coordination_service.cc:678] /job:jax_worker/replica:0/task:2 has disconnected from coordination service.
2025-09-13 01:21:33.823613: I external/xla/xla/tsl/distributed_runtime/coordination/coordination_service.cc:678] /job:jax_worker/replica:0/task:1 has disconnected from coordination service.
2025-09-13 01:21:33.823632: I external/xla/xla/tsl/distributed_runtime/coordination/coordination_service.cc:678] /job:jax_worker/replica:0/task:3 has disconnected from coordination service.
2025-09-13 01:21:33.823660: I external/xla/xla/tsl/distributed_runtime/coordination/coordination_service.cc:678] /job:jax_worker/replica:0/task:0 has disconnected from coordination service.
2025-09-13 01:21:33.823711: I external/xla/xla/tsl/distributed_runtime/coordination/coordination_service_agent.cc:421] Cancelling error polling because the service or the agent is shutting down.
2025-09-13 01:21:33.823816: I external/xla/xla/pjrt/distributed/client.cc:141] Distributed task shutdown result: OK
2025-09-13 01:21:33.823827: I external/xla/xla/pjrt/distributed/service.cc:121] Jax service shutting down
I0913 01:21:34.896327     141 allocator_stats_reporter.cc:147] Stopping AllocatorStatsReporter. Reporting one last time first.
I0913 01:21:34.898905     141 tpunetd_client.cc:356] Session master stopping the session...
I0913 01:21:34.898929     141 session_master.cc:211] Worker Address: maxtext-vlp16-default-slice-0-2.maxtext-vlp16-default:8471
I0913 01:21:34.898933     141 session_master.cc:211] Worker Address: maxtext-vlp16-default-slice-0-0.maxtext-vlp16-default:8471
I0913 01:21:34.898935     141 session_master.cc:211] Worker Address: maxtext-vlp16-default-slice-0-1.maxtext-vlp16-default:8471
I0913 01:21:34.898937     141 session_master.cc:211] Worker Address: maxtext-vlp16-default-slice-0-3.maxtext-vlp16-default:8471
I0913 01:21:34.899354     745 session_worker_service.cc:111] Session master notifies the worker to disconnect from session 96b961ff5d126d8d
I0913 01:21:34.899938     141 tpunetd_client.cc:358] Session master stopped the session.
I0913 01:21:34.899959     141 tpunetd_client.cc:363] Session manager stopping the session...
I0913 01:21:34.919384   26681 broadcast_barrier.cc:115] All instances are ready for PRE_STOP_SESSION_BARRIER, broadcasting notification...
I0913 01:21:35.021662     141 tpunetd_client.cc:365] Session manager stopped the session.
W0913 01:21:35.587207   26847 firmware_indirect_registers.cc:80] Released last reference with existing Open. Performing implicit close-on-destruction.
W0913 01:21:36.343922   26846 firmware_indirect_registers.cc:80] Released last reference with existing Open. Performing implicit close-on-destruction.
W0913 01:21:37.541401     516 firmware_indirect_registers.cc:80] Released last reference with existing Open. Performing implicit close-on-destruction.
W0913 01:21:38.207434     841 firmware_indirect_registers.cc:80] Released last reference with existing Open. Performing implicit close-on-destruction.
I0913 01:21:39.145923   26846 async_driver.cc:1049] [/dev/vfio/1 tpu26:pe2:0] Driver closed.
I0913 01:21:39.146119   26847 async_driver.cc:1049] [/dev/vfio/0 tpu26:pe2:1] Driver closed.
I0913 01:21:39.365084     516 async_driver.cc:1049] [/dev/vfio/3 tpu26:pe2:2] Driver closed.
I0913 01:21:39.366501     841 async_driver.cc:1049] [/dev/vfio/2 tpu26:pe2:3] Driver closed.
