apiVersion: jobset.x-k8s.io/v1alpha2
kind: JobSet
metadata:
  name: maxtext-vlp16-default  # JobSet name (<jobSetName>)
  annotations:
    alpha.jobset.sigs.k8s.io/exclusive-topology: cloud.google.com/gke-nodepool # 1:1 job replica to node pool assignment
spec:
  failurePolicy:
    maxRestarts: 3  # The set will be restarted on failures up to 4 times.
  replicatedJobs:
    - name: slice    # Part of the name of the child Jobs (<replicateJobName>)
      replicas: 1    # Number of slices
      template:
        spec:
          parallelism: 4   # Must be set to number of nodes in each node pool
          completions: 4   # Must be set to number of nodes in each node pool
          backoffLimit: 0   # Must be set to 0. Fail the job when any pod fails.
          template:
            metadata:
              annotations:
                #iam.gke.io/gcp-service-account: "${GCP_SERVICE_ACCOUNT}"
                gke-gcsfuse/volumes: "true"
            spec:
              hostNetwork: true
              dnsPolicy: ClusterFirstWithHostNet
              nodeSelector:
                cloud.google.com/gke-tpu-accelerator: tpu-v6e-slice
                cloud.google.com/gke-tpu-topology: 4x4
              serviceAccountName: storage-access
              volumes:
              - name: gcs-fuse-csi-ephemeral
                csi:
                  driver: gcsfuse.csi.storage.gke.io
                  readOnly: false
                  volumeAttributes:
                   bucketName: rick-maxdiffusion
                   mountOptions: "implicit-dirs"
                   fileCacheCapacity: "-1Mi"
                   fileCacheForRangeRead: "true"
                   metadataCacheTTLSeconds: "-1"
                   metadataNegativeCacheTTLSeconds: "0"
                   metadataStatCacheCapacity: "-1Mi"
                   metadataTypeCacheCapacity: "-1Mi"
              containers:
              - name: jax-tpu
                image: us-east4-docker.pkg.dev/diesel-patrol-382622/gke-llm/maxtext_base_image:latest
                
                imagePullPolicy: Always
                env:
                - name: JOBSET_NAME
                  value: "maxtext-vlp16-default"
                - name: LIBTPU_INIT_ARGS
                  value: "--xla_enable_async_all_gather=true TPU_MEGACORE=MEGACORE_DENSE"
                - name: TPU_STDERR_LOG_LEVEL
                  value: "0"
                - name: TPU_MIN_LOG_LEVEL
                  value: "0"
                - name: TF_CPP_MIN_LOG_LEVEL
                  value: "0"
                ports:
                - containerPort: 8471
                - containerPort: 8080 # Port for MXLA coordinator
                securityContext:
                  privileged: true
                command:
                - bash
                - -c
                - |
                  printenv
                  #cd maxtext
                  pip install -e . 
                  pip install torch 
                  pip install huggingface_hub[cli]
      
                  bash download_dataset.sh $PROJECT_ID /gcs-dir
                  hf auth login --with-token XXXXXX
                  huggingface-cli download meta-llama/Llama-3.1-8B-Instruct --local-dir /gcs-dir/llama3.1-8b-it-hf
                  python3 -m MaxText.llama_or_mistral_ckpt --base-model-path /gcs-dir/llama3.1-8b-it-hf/original \
                  --maxtext-model-path /gcs-dir/llama3.1-8b-it-maxtext --model-size llama3.1-8b            
                resources:
                  limits:
                    google.com/tpu: 4
                volumeMounts:
                - name: gcs-fuse-csi-ephemeral
                  mountPath: /gcs-dir